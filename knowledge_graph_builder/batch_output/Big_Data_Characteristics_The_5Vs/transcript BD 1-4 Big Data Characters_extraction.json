{
  "topic": "Big Data Characteristics: The 5Vs",
  "summary": "This session discusses the characteristics of big data, focusing on the 5Vs: volume, velocity, variety, veracity, and value. Initially, big data was defined by the 3Vs: volume, velocity, and variety. Data volume has increased significantly, transitioning from MBs in ERP systems to PBs in big data scopes, encompassing transactions, interactions, and observations. Variety has expanded from spreadsheets and databases to include photos, audio files, videos, and semi-structured data like XML. Velocity refers to the speed at which data is generated and processed, emphasizing the need for real-time analytics for timely decision-making. Veracity addresses the trustworthiness of data, highlighting the importance of filtering unnecessary information. Value emphasizes the need for data to be reliable and useful, as poor-quality data can lead to significant revenue loss. The lecture concludes by emphasizing the importance of these characteristics in big data analysis and decision-making.",
  "keywords": [
    "volume",
    "velocity",
    "variety",
    "veracity",
    "value",
    "big data",
    "real-time analytics",
    "data analysis",
    "data quality",
    "data volume"
  ],
  "concepts": [
    {
      "name": "Volume",
      "definition": "Refers to the huge amounts of data that is collected and generated every second in large organizations.",
      "text_evidence": "Volume refers to the huge amounts of data that is collected and generated every second in large organizations."
    },
    {
      "name": "Velocity",
      "definition": "This term refers to the speed at which the data is created or generated.",
      "text_evidence": "This term refers to the speed at which the data is created or generated."
    },
    {
      "name": "Variety",
      "definition": "It refers to the different sources of data and their nature.",
      "text_evidence": "Another one of the most important Big Data characteristics is its variety. It refers to the different sources of data and their nature."
    },
    {
      "name": "Veracity",
      "definition": "Uncertainty due to data inconsistency and incompleteness, ambiguities, latency, deception, model approximations.",
      "text_evidence": "Uncertainty due to data inconsistency and incompleteness, ambiguities, latency, deception, model approximations."
    },
    {
      "name": "Value",
      "definition": "No matter how fast the data is produced or its amount, it has to be reliable and useful.",
      "text_evidence": "Among the characteristics of Big Data, value is perhaps the most important. No matter how fast the data is produced or its amount, it has to be reliable and useful."
    },
    {
      "name": "Real-Time Analytics",
      "definition": "Real-Time Analytics is important, which can enable Realtime better decision, act when it is happening.",
      "text_evidence": "Real-Time Analytics is important, which can enable Realtime better decision, act when it is happening."
    }
  ],
  "original_text": "BD 1-3 Big Data Characters\nHello everyone, I am Haiying Che, from Institute of Data Science and knowledge Engineering\nSchool of Computer Science, in Beijing Institute of Technology, in this session, we will discuss about big data Characters, 5Vs, which are volume, velocity, variety, veracity and value.\nOriginally the Characters of Big data is 3 Vs, which are volume, velocity, variety\nAs the information technology developed, the data recorded by the system or devices expanded dramatically.\nShown in the diagram.\nAt the very beginning, the ERP (Enterprise resource planning) system record the purchase detail, purchase record and payment record, which is mainly transactions, data scale is MB.\nand then they expanded the content of customer, in CRM the segmentation, offer details, customer touches, supports contacts information have been recorded in system, which is transactions and interactions with the boundary of organization, data scale is GB.\nFurther with the help of Web, the web logs, offer history, A/B testing, dynamic Pricing, affiliated networks, search marketing, behavioral targeting, dynamic Funnel that useful information can also be recoded and stored. Which are transactions and interactions with the inside and outside of the organization, data scale is TB.\nIn the Big data scope, the sensors/RFID/Devices, user click stream, mobile web, sentiment analysis, user generated content, social interaction & feeds, spatial & GPS coordinates, external demographics, business data feeds, HD video, audio, images, speech to text, product/service logs, SMS/MMS and etc. the data scope is very comprehensive, which are transactions, interactions and observations, data scale is PB,\nSo, from this development, we can see, the data volume and variety, also the velocity is increased.\nLet’ s goes through these characters one by one.\nVolume refers to the huge amounts of data that is collected and generated every second in large organizations.\ndata scale has increased 44 times from 2009 to 2020，From 0.8 zettabytes to 35 zettabytes， The amount of data is growing exponentially\nThis data is generated from different sources such as IoT devices, social media, videos, financial transactions, and customer logs.\nData volume can vary. For example, a text file is a few kilobytes whereas a video file is a few megabytes.\nIDC's \"Data Era 2025\" report, by 2025, the global data will reach 175 ZB (218.75 times in 2009)\n4 The project Earth scope\nEarth scope is the largest scientific project in the world. The observatory aims to track the geological evolution of North America, recording more than 3.8 million square miles of data and accumulating 67 TB of data. It analyzes the seismic slip in the San Andreas fault, and of course, the magma plume below Yellowstone Park, and so on.\nAnother one of the most important Big Data characteristics is its variety. It refers to the different sources of data and their nature.\nThe sources of data have changed over the years. Earlier, it was only available in spreadsheets and databases.\nNowadays, data is present in photos, audio files, videos, text files, and PDFs.\nWhich includes\nRelational Data (Tables/Transaction/Legacy Data)\nText Data (Web)\nSemi-structured Data (XML)\nGraph Data\nSocial Network, Semantic Web (RDF), …\nStreaming Data\nThat you can only scan the data once\nA single application can be generating/collecting many types of data\nBig Public Data (online, weather, finance, etc.)\nIn order to extract knowledge, all these types of data need to be linked together\nThe variety of data is crucial for its storage and analysis.\nFor example, if you want to analyze your customer, you want to know all different aspects of him.\nIncluding his purchase preference, our known history in transaction system, banking, finance history, social media, gaming and entertainment and so on, with all these data you will know comprehensive information about your customer and provide better service.\nThis term refers to the speed at which the data is created or generated.\nData is generated fast and need to be processed fast\nThis speed of data producing is also related to how fast this data is going to be processed. This is because only after analysis and processing, the data can meet the demands of the clients/users.\nMassive amounts of data are produced from sensors, social media sites, and application logs – and all of it is continuous. If the data flow is not continuous, there is no point in investing time or effort on it.\nLate decisions will lead to miss opportunities\nFor Example,\nE-Promotions: Based on your current location, your purchase history to analyze what would you like and send promotions right now for store next to you, if the Promotion was sent when you already far from the store, it is no use.\nAnd Healthcare monitoring, sensors monitoring your activities and body, when any abnormal measurements happens, it requires immediate reaction\n8 Real-time/Fast Data\nA lot of fast data is real time.\nIn Social media and networks all of us are generating data.\nScientific instruments are collecting all sorts of data.\nMobile devices are tracking all objects all the time.\nSensor technology and networks are measuring all kinds of data.\nPeople and devices are all generating data.\nThe progress and innovation is no longer hindered by the ability to collect data\nBut, by the ability to manage, analyze, summarize, visualize, and discover knowledge from the collected data in a timely manner and in a scalable fashion.\n9 Real-Time Analytics/Decision Requirement\nReal-Time Analytics is important, which can enable Realtime better decision, act when it is happening.\nFor example:\nProduct Recommendations that are Relevant & Compelling.\nLearning why Customers Switch to competitors and their offers in time to Counter\nImproving the Marketing Effectiveness of a Promotion while it is still in Play.\nPreventing Fraud as it is Occurring & preventing more proactively.\nLet’s look at the 5Vs,\n1 volume, data at rest, terabytes to exabytes of existing data to process,\n2 velocity, data in motion, streaming data, milliseconds to seconds to respond.\n3 variety, data in many forms, structured, unstructured, text, multimedia and so on\nThe other two are veracity and value.\n4 Veracity: data in Doubt\nUncertainty due to data inconsistency and incompleteness, ambiguities, latency, deception, model approximations.\nThis feature of Big Data is connected to the previous one. It defines the degree of trustworthiness of the data.\nAs most of the data you encounter is unstructured, it is important to filter out the unnecessary information and use the rest for processing.\nAmong the characteristics of Big Data, value is perhaps the most important. No matter how fast the data is produced or its amount, it has to be reliable and useful. Otherwise, the data is not good enough for processing or analysis. Research says that poor quality data can lead to almost a 20% loss in a company’s revenue. Data scientists first convert raw data into information. Then this data set is cleaned to retrieve the most useful data. Analysis and pattern identification is done on this data set. If the process is a success, the data can be considered to be valuable.\nEven the valuable data, it is low value density, like panning for gold in the sand. A few seconds among a video of several house may be useful.\n11 conclusion\nBig Data is the driving force behind major sectors such as business, marketing, sales, analytics, and research. It has changed the business strategies of customer-based and product-based companies worldwide. Thus, all the Big Data characteristics have to be given equal importance when it comes to analysis and decision making. In this session we learned the Big Data characteristics, volume, velocity, variety, veracity and value, which are key factors you need to consider when you do big data analysis.\nThank you for your attention, if you have any question, feel free to connect me."
}