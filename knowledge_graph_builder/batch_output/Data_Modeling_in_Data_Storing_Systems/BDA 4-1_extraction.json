{
  "topic": "Data Modeling in Data Storing Systems",
  "summary": "This session introduces data storing systems and focuses on data modeling. Big data computing systems are categorized into data storing, data processing, and data application systems. The data storage architecture is crucial for big data computing, involving data collection, file systems, databases, data warehouses, and unified data access interfaces. Data is collected from various resources, cleaned, and converted into standard formats. The current architecture includes a data layer, distributed file system/NoSQL database, and a unified database reading interface, with some designs adding data mining. Data modeling, an important part of the data layer, establishes an abstract model of entity data, including metadata, structure, attributes, and relationships. The data model is defined in three levels: conceptual, logical, and physical. UML is a commonly used data modeling language, with tools like Power designer and ER/studio.",
  "keywords": [
    "data storing system",
    "data modeling",
    "data collection",
    "file system",
    "database",
    "data warehouse",
    "ETL",
    "conceptual model",
    "logical model",
    "physical model"
  ],
  "concepts": [
    {
      "name": "Data storing system",
      "definition": "In data storing system we collect the data and store the data, then support upper level data processing, after data has been well processed, it can support the big data application.",
      "text_evidence": "In data storing system we collect the data and store the data, then support upper level data processing, after data has been well processed, it can support the big data application."
    },
    {
      "name": "Data exhaust",
      "definition": "The trail of data left by the activities of an Internet or other computer system users during their online activity, behavior, and transactions.",
      "text_evidence": "Data exhaust or exhaust data is the trail of data left by the activities of an Internet or other computer system users during their online activity, behavior, and transactions."
    },
    {
      "name": "ETL",
      "definition": "Extract transform Load",
      "text_evidence": "ETL-Extract transform Load"
    },
    {
      "name": "Data modeling",
      "definition": "To establish an abstract model of entity data, including metadata, data structure, attributes, value range, association relationship, and consistency, Timeliness and other elements.",
      "text_evidence": "Data modeling is to establish an abstract model of entity data, including metadata, data structure, attributes, value range, association relationship, and consistency, Timeliness and other elements."
    },
    {
      "name": "Conceptual model",
      "definition": "Describes the semantics of a domain (the scope of the model). This consists of entity classes, representing kinds of things of significance in the domain, and relationships assertions about associations between pairs of entity classes.",
      "text_evidence": "Conceptual model schema describes the semantics of a domain (the scope of the model). This consists of entity classes, representing kinds of things of significance in the domain, and relationships assertions about associations between pairs of entity classes."
    },
    {
      "name": "Logical model",
      "definition": "More details of data entities, including primary keys, foreign keys, attributes, indexes, relationships, constraints, and even views, with data tables, data columns, value ranges, object-oriented classes, XML tags and other can be describe.",
      "text_evidence": "In logical model design, more details of data entities, including primary keys, foreign keys, attributes, indexes, relationships, constraints, and even views, with data tables, data columns, value ranges, object-oriented classes, XML tags and other can be describe."
    },
    {
      "name": "Physical model",
      "definition": "Describes the storage implementation of data, including data partition, data table space, and data integration. This is concerned with partitions, CPUs, tablespaces, and the like.",
      "text_evidence": "The physical model describes the storage implementation of data, including data partition, data table space, and data integration.This is concerned with partitions, CPUs, tablespaces, and the like."
    }
  ],
  "original_text": "Hello everyone, I am Haiying Che, from Institute of Data Science and knowledge Engineering\nSchool of Computer Science, in Beijing Institute of Technology, from this session,\nwe start to learn Data storing system, and in this session, we discuss about data modeling.\nThe big data computing system can be summarized into three categories: from bottom to top, they are\nData storing system, Data processing system, Data application system.\nIn data storing system we collect the data and store the data, then support upper level data processing,\nafter data has been well processed, it can support the big data application. Like data analysis, business intelligent, decision making and so on.\nThe data storage architecture is the foundation of big data computing. The upper-level analysis algorithms,\ncomputing models and computing performance all depend on the performance of the data storage system.\nTherefore, the data storage system is an important area of big data research.\nIn the data storing system, there are 4 parts to accomplish the different tasks, which are data collection and data modeling, File system, database, data warehouse and Unified data access interface.\nData collection collect data from multiple data resources, like System logs, Web Crawler, wireless sensor network, internet of things and all kinds of data resources.\nAnd after data has been collected, we need clean the data，delete dirty data like repeated data, empty data, wrong data etc.\nConvert various types of structured, unstructured, and heterogeneous data into standard storage format data, and define data attributes and value ranges.\nAnd We build the data model to organize the data.\nAbove the data collection, it is file system, which physically implement the data storing, it could be Centralized or distributed file system,\nthen database, which design the logical structure to store the data, include RDBMs and No SQL database.\nAll above file system and database is the unified data access interface, which is a data access interface, through which the data processing system can retrieve the data from data storing system.\nThe data can be collected from CRM, ERP, financials, social media, exhaust data, logs, files.\n(Data exhaust or exhaust data is the trail of data left by the activities of an Internet or other computer system users during their online activity, behavior, and transactions.\nDue to the characteristics of multiple data sources, data heterogeneity, unstructured data, distributed computing environment and others, which make the design of big data storage system is more complicated than before.\nThe current big data storage architecture is mainly composed of data layer, distributed file system/non-relational database (NoSQL), and unified database reading interface.\nSome designs will add a data mining and analysis function on top of NoSQL database. Warehouse layer\nThe data layer mainly includes the data acquisition system and provides data extraction, cleaning, and conversion ETL-Extract transform Load, data modeling functions,\n1）multiple data sources include enterprise data, business data, personal social data, government statistics, Internet data, Internet of Things data, System log data, Gene sequencing data, atmospheric physics monitoring data, earth satellite observation data, etc.\n2） heterogeneous data could be text, pictures, audio and video etc.\n3） The unstructured data includes medical imaging data, scans of bank certificates, fragmented communication records, screenshots, etc.\nAll these multiple data sources, heterogeneous data, The unstructured data, all these characteristics make it difficult to store raw data directly in the database.\nIn big data collecting, there are some Problems：\nthe original data format cannot be recognized and processed by the data platform.\nIn many cases, the original data still has problems such as missing records, missing value ranges, and different level data quality problems.\nThis requires cleaning the original data before building a database or data warehouse, by merging or removing duplicate data items, eliminating data errors,\nData could be Extracted from multiple data sources, extract different value ranges from data items to form the data structure of the target database,\nOr data items could be Extracted from one data source and decompose them into multiple structures and load them into the target database,\nTransform means Transforming original data items in different formats into a unified standard target database format.\nData extraction, cleaning and conversion can be done manually or using software tools.\nNow let’s look at data modeling, Data modeling is an important part of the data layer work.\nData modeling is to establish an abstract model of entity data, including metadata, data structure, attributes, value range, association relationship, and consistency, Timeliness and other elements.\nThe data model provides a reference for further data storage structure design, database design and calculation model.\nBusiness model normally includes process model and data model, process model describes how the business works.\nData model describe the data supporting the business process.\nThe data model is defined in three levels conceptual model, logic model, and physical model.\nIn this process diagram. First based on the process models and data requirement we can do the logical modeling, then generate the logical data model as the output.\nSynthesize the logical data model, technical requirement and performance requirements, we carry out the physical data modeling and generate the output physical data model. After we have the logical data model and the corresponding physical model, the generated business data can be stored by creating, updating operations in the logical and physical model.\nData modeling process\nLet’s look at the three data model one by one.\nBased on the user's data function requirements. functions and association relationships are obtained,\nWe can find Entity Class corresponding to the business elements and functions.\nConceptual model schema describes the semantics of a domain (the scope of the model).\nThis consists of entity classes, representing kinds of things of significance in the domain, and relationships assertions about associations between pairs of entity classes. Simply described, a conceptual schema is the first step in organizing the data requirements.\nIn logical model design, more details of data entities, including primary keys, foreign keys, attributes, indexes, relationships, constraints, and even views, with data tables, data columns, value ranges, object-oriented classes, XML tags and other can be describe.\nThe physical model describes the storage implementation of data, including data partition, data table space, and data integration.This is concerned with partitions, CPUs, tablespaces, and the like.\nAccording to American National Standards Institute, ANSI, the three perspectives should be relatively independent of each other.\nStorage technology can change without affecting either the logical or the conceptual schema.\nThe table/column structure can change without (necessarily) affecting the conceptual schema.\nbut, the structures must remain consistent across all schemas of the same data model, logical or physical.\nUML is commonly used Data modeling language, and\nCommon data modeling tools includes Power designer, ER/studio.CA Erwin, IBM Infosphere Data Architect, etc.\nLet’s summarize, in this session, we learned the first layer of data storing system, which includes data acquisition, extraction, transforming and modeling.\nthank you for your attention, if you have any question, feel free to contact me."
}