{
  "topic": "Massively Parallel Processing (MPP) for Structured Data",
  "summary": "This session discusses the Massively Parallel Processing (MPP) model for structured data. MPP is a computing model where data is partitioned across multiple servers or nodes, each with its own memory and processors, communicating via a network interconnect in a shared-nothing architecture. The process involves a client issuing a query to a master node, which generates an execution plan and distributes it to the underlying nodes for parallel execution. The query results are then returned to the master node. MPP databases typically adopt a shared-nothing architecture with a master node and multiple slave nodes, each responsible for storing and processing a partition of the data. Fault tolerance is achieved through a mirror scheme where each segment has a replica on another node. Data distribution is a key characteristic, achieved using clauses like 'DISTRIBUTED BY' to enable data and processing parallelism.",
  "keywords": [
    "Massively Parallel Processing",
    "MPP",
    "shared-nothing architecture",
    "data partitioning",
    "master node",
    "slave node",
    "segment",
    "data distribution",
    "fault tolerance"
  ],
  "concepts": [
    {
      "name": "Massively Parallel Processing (MPP)",
      "definition": "Large-scale concurrent processing model for structured data.",
      "text_evidence": "in this session, we discuss Massively Parallel Processing model for Structured Data."
    },
    {
      "name": "MPP databases",
      "definition": "Data is partitioned across multiple servers or nodes with each server/node having memory/processors to process data locally. All communication is via a network interconnect — there is no disk-level sharing or contention to be concerned with (i.e. it is a ‘shared-nothing’ architecture).",
      "text_evidence": "in Massively Parallel Processing (MPP) databases data is partitioned across multiple servers or nodes with each server/node having memory/processors to process data locally. All communication is via a network interconnect — there is no disk-level sharing or contention to be concerned with (i.e. it is a ‘shared-nothing’ architecture)."
    },
    {
      "name": "Master Node",
      "definition": "Contains information, such as the data dictionary and session information, which it uses to generate an execution plan designed to retrieve the needed information from each underlying Node.",
      "text_evidence": "The Master Node contains information, such as the data dictionary and session information, which it uses to generate an execution plan designed to retrieve the needed information from each underlying Node."
    },
    {
      "name": "Parallel Execution",
      "definition": "Represents the implementation of the execution plan through the parallel computing of Node 1 to Node n.",
      "text_evidence": "Parallel Execution represents the implementation of the execution plan through the parallel computing of Node 1 to Node n."
    },
    {
      "name": "shared nothing architecture",
      "definition": "There is no single point of contention across the system and nodes do not share memory or disk storage.",
      "text_evidence": "In the shared nothing architecture, there is no single point of contention across the system and nodes do not share memory or disk storage."
    },
    {
      "name": "Segment instances",
      "definition": "Process queries in parallel",
      "text_evidence": "Segment instances process queries in parallel"
    },
    {
      "name": "mirror segment",
      "definition": "Replication is commonly used to ensure durability and availability of data.",
      "text_evidence": "As Fig shows, each segment (primary segment) is allocated with a mirror (mirror segment) in another node."
    },
    {
      "name": "standby",
      "definition": "Works as the replication/mirror of the master node.",
      "text_evidence": "Similarly, a standby works as the replication/mirror of the master node."
    },
    {
      "name": "Data distribution",
      "definition": "Data is distributed across each segment database to achieve data and processing parallelism.",
      "text_evidence": "Data is distributed across each segment database to achieve data and processing parallelism."
    }
  ],
  "original_text": "Hello everyone, I am Haiying Che, from Institute of Data Science and knowledge Engineering\nSchool of Computer Science, in Beijing Institute of Technology,\nin this session, we discuss Massively Parallel Processing model for Structured Data.\nThe data processing system provides big data computing and processing capabilities and an application development platform.\nFrom the perspective of computing architecture, the data processing system is divided into data algorithm layer, computing model layer, computing platform layer, computing engine layer, etc.\nComputing models are the way that different kinds of big data is processed in different scenarios,\nwhich include batch processing, stream computing, Large-scale concurrent processing (MPP) model for structured data, In-memory Computing model, and Data Flow Graph models.\nNow let’s look at the third computing model Massively Parallel Processing.\nIn Massively Parallel Processing (MPP) databases data is partitioned across multiple servers or nodes with each server/node having memory/processors to process data locally.\nAll communication is via a network interconnect — there is no disk-level sharing or contention to be concerned with (i.e. it is a ‘shared-nothing’ architecture).\nBig data may be semi-structured or unstructured.\nThe massively parallel processing (MPP) architecture structures big data to enable easy querying for reporting and analytic purposes.\nMPP systems are sometimes referred to as shared nothing systems.\nThis means that data is partitioned across many servers (otherwise known as nodes) and each server processes queries locally.\nIn the diagram , 4 nodes are using to replace one single server and reduce the query time from one hour to 15 minutes.\nThe process begins by the Client issuing a query that is then passed to the Master Node.\nThe Master Node contains information, such as the data dictionary and session information,\nwhich it uses to generate an execution plan designed to retrieve the needed information from each underlying Node.\nParallel Execution represents the implementation of the execution plan through the parallel computing of Node 1 to Node n.\nAnd the query results return to master node\nMassively Parallel Processing is the coordinated processing of a single task by multiple processor,\nEach processor using its own OS and memory and communicating with each other using some form of messaging interface\nMPP can be setup with a shared nothing or shared disk architecture\nIn the shared nothing architecture, there is no single point of contention across the system and nodes do not share memory or disk storage.\ndata is horizontally partitioned across nodes such that each node has a sub set of rows from each table in the DB\nEach node then processes only rows on its own disks.\nThe “shared nothing” systems with distributed databases need a lot of coordination to complete a common task.\nEach node owns slices of the database.\nManaging this database could be very difficult. Shared nothing systems with the replicated database are not suitable for applications with tremendous data requirements.\nIf the computation needs a lot of data modification operations like data insertion and join, then the “shared nothing” architecture may not be viable.\nPerformance through segment instance parallelism\nMaster host and standby master Host\nMaster coordinates work with segment host\nSegment host with one or more segment instances\nSegment instances process queries in parallel\nSegment hosts have their own CPU disk memory(shared nothing)\nHigh speed interconnect for continuous pipelining of data processing\nArchitecture of MPP databases. There are a master and 4 slaves, with 2 segments on each slave and a mirror for each segment on another machine.\nMPP Database Architecture\nTypical MPP databases usually adopt a shared-nothing architecture , composed of one master node and n slave nodes.\nThe master node is responsible for interacting with clients, managing the whole cluster and coordinating the query processing.\nEach of the n salve nodes is responsible for storing a partition of the data and performing query processing on its partition.\nEach slave node hosts d database instances, which will be referred to as segments subsequently.\nMost MPP databases provide fault tolerance at storage level. A mirror scheme, i.e., replication, is commonly used to ensure durability and availability of data.\nAs Fig shows, each segment (primary segment) is allocated with a mirror (mirror segment) in another node.\nThe master node detects node failures by monitoring heartbeats of slave nodes. If a slave node stops responding for a certain amount of time, known as a system delay time (normally around 1 min),\nthe master will treat it as a failed node. Once a failure is detected, the corresponding mirror will be activated to replace the failed primary segment.\nSimilarly, a standby works as the replication/mirror of the master node.\nThrough the mirror scheme, the system’s availability can be significantly enhanced.\nHowever, such a mirror scheme does not support intra-query fault tolerance automatically.\nWhen a node failure occurs, the running query’s state on the failed node will be lost.\nAfter the corresponding mirror is activated, the whole query has to be rerun.\nIf it is a long running query, response to the client will be severely delayed. In the worst case, a query will run indefinitely, if the probability of failure is high.\nin Massively Parallel Processing (MPP) databases data is partitioned across multiple servers or nodes with each server/node having memory/processors to process data locally. All communication is via a network interconnect — there is no disk-level sharing or\ncontention to be concerned with (i.e. it is a ‘shared-nothing’ architecture).\nMaster Host – Separate physical server with its own OS/CPU/storage/memory.\nHosts master database. There is no user data in master database but stores metadata about segments – think in terms of system tables.\n3、 2, 3, 4 Segment hosts – Individual physical servers with their own OS/CPU/storage/memory.\n4、Hosts segment database. Each database stores portion of user data.\n5、 Interconnect switch – Segment server databases communicate through an interconnect switch\nthe main characteristic of MPP database is data distribution.\nData is distributed across each segment database to achieve data and processing parallelism.\nThis is achieved by creating a database table with DISTRIBUTED BY clause.\nBy using this clause data is automatically distributed across segment databases.\nIn Greenplum you can either use hash or round-robin distribution.\nIn this session we learned Large-scale concurrent processing (MPP Massively Parallel Processing) model for structured data. Thank you for your attention, if you have any question, feel free to contact me."
}