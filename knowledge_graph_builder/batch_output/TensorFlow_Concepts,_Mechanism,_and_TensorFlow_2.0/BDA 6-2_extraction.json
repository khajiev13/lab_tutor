{
  "topic": "TensorFlow Concepts, Mechanism, and TensorFlow 2.0",
  "summary": "This session introduces TensorFlow, an open-source library created by Google Brain for numerical computation and large-scale machine learning. TensorFlow bundles machine learning and deep learning models, utilizing dataflow graphs where nodes represent mathematical operations and edges are tensors. It uses Python for a front-end API and executes applications in high-performance C++. TensorFlow applications can run on various targets, including CPUs, GPUs, and TPUs. The session also covers TensorFlow 2.0, which focuses on simplicity and ease of use with features like Keras, eager execution, and tf.data for building scalable input pipelines. It supports distributed training using the Distribution Strategy API and standardizes on SavedModel for deployment across platforms like TensorFlow Serving, TensorFlow Lite, and TensorFlow.js. The lecture also touches on experiments like Boston Housing Prediction, Objection Detection, and Variational AutoEncoder.",
  "keywords": [
    "TensorFlow",
    "TensorFlow 2.0",
    "Keras",
    "eager execution",
    "dataflow graphs",
    "tensors",
    "TPU",
    "Distribution Strategy API",
    "SavedModel",
    "TensorFlow Lite"
  ],
  "concepts": [
    {
      "name": "TensorFlow",
      "definition": "An open source library for numerical computation and large-scale machine learning.",
      "text_evidence": "TensorFlow is Created by the Google Brain team, it is an open source library for numerical computation and large-scale machine learning."
    },
    {
      "name": "Tensor",
      "definition": "The core data unit of TensorFlow, which is essentially an array of arbitrary dimensions.",
      "text_evidence": "A tensor is the core data unit of TensorFlow, which is essentially an array of arbitrary dimensions."
    },
    {
      "name": "Dataflow graphs",
      "definition": "Structures that describe how data moves through a graph, or a series of processing nodes.",
      "text_evidence": "TensorFlow allows developers to create dataflow graphs—structures that describe how data moves through a graph, or a series of processing nodes."
    },
    {
      "name": "TensorFlow Processing Unit (TPU)",
      "definition": "Google’s custom TensorFlow Processing Unit silicon for further acceleration.",
      "text_evidence": "If you use Google’s own cloud, you can run TensorFlow on Google’s custom TensorFlow Processing Unit (TPU) silicon for further acceleration."
    },
    {
      "name": "Keras",
      "definition": "A user-friendly API standard for machine learning, will be the central high-level API used to build and train models.",
      "text_evidence": "Keras, a user-friendly API standard for machine learning, will be the central high-level API used to build and train models."
    },
    {
      "name": "Eager execution",
      "definition": "For immediate iteration",
      "text_evidence": "1） eager execution, for immediate iteration"
    },
    {
      "name": "tf.data",
      "definition": "For building scalable input pipelines.",
      "text_evidence": "3） Tf.data, for building scalable input pipelines."
    },
    {
      "name": "Distribution Strategy API",
      "definition": "Makes it easy to distribute and train models on different hardware configurations without changing the model definition.",
      "text_evidence": "For large ML training tasks, the Distribution Strategy API makes it easy to distribute and train models on different hardware configurations without changing the model definition."
    },
    {
      "name": "SavedModel",
      "definition": "An interchange format for TensorFlow Serving, TensorFlow Lite, TensorFlow.js, TensorFlow Hub, and more.",
      "text_evidence": "TensorFlow will standardize on SavedModel as an interchange format for TensorFlow Serving, TensorFlow Lite, TensorFlow.js, TensorFlow Hub, and more."
    },
    {
      "name": "TensorFlow Serving",
      "definition": "A TensorFlow library allowing models to be served over HTTP/REST or gRPC/Protocol Buffers.",
      "text_evidence": "TensorFlow Serving: A TensorFlow library allowing models to be served over HTTP/REST or gRPC/Protocol Buffers."
    },
    {
      "name": "TensorFlow Lite",
      "definition": "TensorFlow’s lightweight solution for mobile and embedded devices provides the capability to deploy models on Android, iOS and embedded systems like a Raspberry Pi and Edge TPUs.",
      "text_evidence": "TensorFlow Lite: TensorFlow’s lightweight solution for mobile and embedded devices provides the capability to deploy models on Android, iOS and embedded systems like a Raspberry Pi and Edge TPUs."
    },
    {
      "name": "TensorFlow.js",
      "definition": "Enables deploying models in JavaScript environments, such as in a web browser or server side through Node.js. TensorFlow.js also supports defining models in JavaScript and training directly in the web browser using a Keras-like API.",
      "text_evidence": "TensorFlow.js: Enables deploying models in JavaScript environments, such as in a web browser or server side through Node.js. TensorFlow.js also supports defining models in JavaScript and training directly in the web browser using a Keras-like API."
    }
  ],
  "original_text": "Hello everyone, I am Haiying Che, from Institute of Data Science and knowledge Engineering\nSchool of Computer Science, in Beijing Institute of Technology, in this session we will talk about the powerful Ml tool TensorFlow.\nIn this chapter, we introduce some useful platform， Spark MLlib and TensorFlow.\nIn this session we will discuss about the concepts and mechanism of TensorFlow.\nTensorFlow is Created by the Google Brain team, it is an open source library for numerical computation and large-scale machine learning.\nTensorFlow bundles together a lot of machine learning and deep learning (aka neural networking) models and algorithms and makes them useful by way of a common metaphor.\nTensorFlow has grown to become one of the most loved and widely adopted ML platforms in the world\nA tensor is the core data unit of TensorFlow, which is essentially an array of arbitrary dimensions.\nAvailable tensor types include constants, variables, tensor placeholders, and sparse tensors.\nHow TensorFlow works\nTensorFlow allows developers to create dataflow graphs—structures that describe how data moves through a graph, or a series of processing nodes.\nEach node in the graph represents a mathematical operation, and each connection or edge between nodes is a multidimensional data array, or tensor.\nTensorFlow provides all of this for the programmer by way of the Python language.\nPython is easy to learn and work with, and provides convenient ways to express how high-level abstractions can be coupled together.\nNodes and tensors in TensorFlow are Python objects, and TensorFlow applications are themselves Python applications.\nIt uses Python to provide a convenient front-end API for building applications with the framework, while executing those applications in high-performance C++.\nThe actual math operations, however, are not performed in Python.\nThe libraries of transformations that are available through TensorFlow are written as high-performance C++ binaries.\nPython just directs traffic between the pieces, and provides high-level programming abstractions to hook them together.\nTensorFlow applications can be run on most any target that’s convenient: a local machine, a cluster in the cloud, iOS and Android devices, CPUs or GPUs.\nIf you use Google’s own cloud, you can run TensorFlow on Google’s custom TensorFlow Processing Unit (TPU) silicon for further acceleration.\nThe resulting models created by TensorFlow, though, can be deployed on most any device where they will be used to serve predictions.\nTensorFlow has grown to become one of the most loved and widely adopted ML platforms in the world\nLet ‘s watch a video to understand more about TensorFlow\nNow let’s look at the structure of TensorFlow 2.0.\nTensorFlow 2.0 focus on simplicity and ease of use, featuring updates like:\nEasy model building with Keras and eager execution.\nRobust model deployment in production on any platform.\nPowerful experimentation for research.\nthe APIs has been packaged together into a comprehensive platform that supports machine learning workflows from training through deployment.\nKeras, a user-friendly API standard for machine learning, will be the central high-level API used to build and train models.\nThe Keras API makes it easy to get started with TensorFlow.\nImportantly, Keras provides several model-building APIs (Sequential, Functional, and Subclassing), so you can choose the right level of abstraction for your project.\nTensorFlow2.0’s implementation contains enhancements including\n1） eager execution, for immediate iteration\n2） Intuitive debugging,\n3） Tf.data, for building scalable input pipelines.\nLet’s take a look at the new architecture of TensorFlow 2.0 using a simplified, conceptual diagram as shown\nEasy model building-Here’s an example workflow:\nLoad your data using tf.data.\nTraining data is read using input pipelines which are created using tf.data.\nFeature characteristics, for example bucketing and feature crosses are described using tf.feature_column.\nConvenient input from in-memory data (for example, NumPy) is also supported.\nBuild, train and validate your model with tf.keras, or use Premade Estimators.\nKeras integrates tightly with the rest of TensorFlow so you can access TensorFlow’s features whenever you want.\nA set of standard packaged models (for example, linear or logistic regression, gradient boosted trees, random forests) are also available to use directly (implemented using the tf.estimator API).\nIf you’re not looking to train a model from scratch, you’ll soon be able to use transfer learning to train a Keras or Estimator model using modules from TensorFlow Hub.\nRun and debug with eager execution, then use tf.function for the benefits of graphs.\nTensorFlow 2.0 runs with eager execution by default for ease of use and smooth debugging.\nAdditionally, the tf.function annotation transparently translates your Python programs into TensorFlow graphs.\nThis process retains all the advantages of 1.x TensorFlow graph-based execution: Performance optimizations,\nremote execution and the ability to serialize, export and deploy easily, while adding the flexibility and ease of use of expressing programs in simple Python.\nUse Distribution Strategies for distributed training.\nFor large ML training tasks, the Distribution Strategy API makes it easy to distribute and train models on different hardware configurations without changing the model definition.\nSince TensorFlow provides support for a range of hardware accelerators like CPUs, GPUs, and TPUs, （Tensor Processing Unit）\nyou can enable training workloads to be distributed to single-node/multi-accelerator as well as multi-node/multi-accelerator configurations, including TPU Pods.\nAlthough this API supports a variety of cluster configurations, templates to deploy training on Kubernetes clusters in on-prem or cloud environments are provided.\nExport to SavedModel.\nTensorFlow will standardize on SavedModel as an interchange format for TensorFlow Serving, TensorFlow Lite, TensorFlow.js, TensorFlow Hub, and more.\nRobust model deployment in production on any platform\nTensorFlow has always provided a direct path to production. Whether it’s on servers, edge devices, or the web,\nTensorFlow lets you train and deploy your model easily, no matter what language or platform you use.\nIn TensorFlow 2.0, compatibility and parity across platforms and components are improved by standardizing exchange formats and aligning APIs.\nOnce you’ve trained and saved your model, you can execute it directly in your application or serve it using one of the deployment libraries:\nTensorFlow Serving: A TensorFlow library allowing models to be served over HTTP/REST or gRPC/Protocol Buffers.\nTensorFlow Lite: TensorFlow’s lightweight solution for mobile and embedded devices provides the capability to deploy models on Android, iOS and embedded systems like a Raspberry Pi and Edge TPUs.\nTensorFlow.js: Enables deploying models in JavaScript environments, such as in a web browser or server side through Node.js. TensorFlow.js also supports defining models in JavaScript and training directly in the web browser using a Keras-like API.\nTensorFlow also has support for additional languages (some maintained by the broader community), including C, Java, Go, C#, Rust, Julia, R, and others.\nThis picture shows typical platforms for the general-purpose computation, machine learning and Deep Learning, and Tensorflow can be used both for ML and DL.\nTensorFlow is Powerful experimentation for research\nTensorFlow makes it easy to take new ideas from concept to code, and from model to publication.\nTensorFlow 2.0 incorporates a number of features that enables the definition and training of state-of-the-art models without sacrificing speed or performance:\nKeras Functional API and Model Subclassing API: Allows for creation of complex topologies including using residual layers, custom multi-input/-output models, and imperatively written forward passes.\nCustom Training Logic: Fine-grained control on gradient computations with tf.GradientTape and tf.custom_gradient.\nAnd for even more flexibility and control, the low-level TensorFlow API is always available and working in conjunction with the higher-level abstractions for fully customizable logic.\nTensorFlow 2.0 brings several new additions that allow researchers and advanced users to experiment, using rich extensions\nlike Ragged Tensors, TensorFlow Probability, Tensor2Tensor, and more to be announced.\nAlong with these capabilities, TensorFlow provides eager execution for easy prototyping & debugging, Distribution Strategy API and AutoGraph to train at scale, and support for TPUs, making TensorFlow 2.0 an easy to use, customizable, and highly scalable platform for conducting state of the art ML research and translating that research into production pipelines.\nTo manage using TensorFlow, a serious experiments were designed,\nwhich included Boston Housing Prediction using linear regression, Objection Detection and Variational AutoEncoder.\nThe steps of each experiment showed in the diagram.\nBoston Housing Prediction included preparation, import data, Data visualization, build Model, Train the Model and result visualization.\nObjection Detection included build the environment of TensorFlow on PC, build computation graph by using TensorFlow and Using computational graph to compute computation.\nVariational AutoEncoder include two stages Network construction and Solving gradient disappearing problem using VAE, which consist of Learn the concept of layers, build a model that encapsulates layers by using the function sequential, set the loss function, calculate the gradient of the loss function to perform Back Propagation to adjust the parameters and add some noise into the validation set to solve the gradient disappearing problem.\nall the experiments material including the manual and codes are provided on the MOOC platform, which can help you to do the hands-on.\nIn this session, we learned concepts and mechanism of TensorFlow\nthank you for your attention, if you have any question, feel free to contact me."
}