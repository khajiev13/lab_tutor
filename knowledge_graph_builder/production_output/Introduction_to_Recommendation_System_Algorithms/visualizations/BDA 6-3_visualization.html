<style>
.lx-highlight { position: relative; border-radius:3px; padding:1px 2px;}
.lx-highlight .lx-tooltip {
  visibility: hidden;
  opacity: 0;
  transition: opacity 0.2s ease-in-out;
  background: #333;
  color: #fff;
  text-align: left;
  border-radius: 4px;
  padding: 6px 8px;
  position: absolute;
  z-index: 1000;
  bottom: 125%;
  left: 50%;
  transform: translateX(-50%);
  font-size: 12px;
  max-width: 240px;
  white-space: normal;
  box-shadow: 0 2px 6px rgba(0,0,0,0.3);
}
.lx-highlight:hover .lx-tooltip { visibility: visible; opacity:1; }
.lx-animated-wrapper { max-width: 100%; font-family: Arial, sans-serif; }
.lx-controls {
  background: #fafafa; border: 1px solid #90caf9; border-radius: 8px;
  padding: 12px; margin-bottom: 16px;
}
.lx-button-row {
  display: flex; justify-content: center; gap: 8px; margin-bottom: 12px;
}
.lx-control-btn {
  background: #4285f4; color: white; border: none; border-radius: 4px;
  padding: 8px 16px; cursor: pointer; font-size: 13px; font-weight: 500;
  transition: background-color 0.2s;
}
.lx-control-btn:hover { background: #3367d6; }
.lx-progress-container {
  margin-bottom: 8px;
}
.lx-progress-slider {
  width: 100%; margin: 0; appearance: none; height: 6px;
  background: #ddd; border-radius: 3px; outline: none;
}
.lx-progress-slider::-webkit-slider-thumb {
  appearance: none; width: 18px; height: 18px; background: #4285f4;
  border-radius: 50%; cursor: pointer;
}
.lx-progress-slider::-moz-range-thumb {
  width: 18px; height: 18px; background: #4285f4; border-radius: 50%;
  cursor: pointer; border: none;
}
.lx-status-text {
  text-align: center; font-size: 12px; color: #666; margin-top: 4px;
}
.lx-text-window {
  font-family: monospace; white-space: pre-wrap; border: 1px solid #90caf9;
  padding: 12px; max-height: 260px; overflow-y: auto; margin-bottom: 12px;
  line-height: 1.6;
}
.lx-attributes-panel {
  background: #fafafa; border: 1px solid #90caf9; border-radius: 6px;
  padding: 8px 10px; margin-top: 8px; font-size: 13px;
}
.lx-current-highlight {
  border-bottom: 4px solid #ff4444;
  font-weight: bold;
  animation: lx-pulse 1s ease-in-out;
}
@keyframes lx-pulse {
  0% { text-decoration-color: #ff4444; }
  50% { text-decoration-color: #ff0000; }
  100% { text-decoration-color: #ff4444; }
}
.lx-legend {
  font-size: 12px; margin-bottom: 8px;
  padding-bottom: 8px; border-bottom: 1px solid #e0e0e0;
}
.lx-label {
  display: inline-block;
  padding: 2px 4px;
  border-radius: 3px;
  margin-right: 4px;
  color: #000;
}
.lx-attr-key {
  font-weight: 600;
  color: #1565c0;
  letter-spacing: 0.3px;
}
.lx-attr-value {
  font-weight: 400;
  opacity: 0.85;
  letter-spacing: 0.2px;
}

/* Add optimizations with larger fonts and better readability for GIFs */
.lx-gif-optimized .lx-text-window { font-size: 16px; line-height: 1.8; }
.lx-gif-optimized .lx-attributes-panel { font-size: 15px; }
.lx-gif-optimized .lx-current-highlight { text-decoration-thickness: 4px; }
</style>
    <div class="lx-animated-wrapper lx-gif-optimized">
      <div class="lx-attributes-panel">
        <div class="lx-legend">Highlights Legend: <span class="lx-label" style="background-color:#D2E3FC;">CONCEPT</span> <span class="lx-label" style="background-color:#C8E6C9;">KEYWORDS</span> <span class="lx-label" style="background-color:#FEF0C3;">SUMMARY</span> <span class="lx-label" style="background-color:#F9DEDC;">TOPIC</span></div>
        <div id="attributesContainer"></div>
      </div>
      <div class="lx-text-window" id="textWindow">
        Hello everyone, I am Haiying Che, from Institute of Data Science and knowledge Engineering
School of Computer Science, in Beijing Institute of Technology
In this chapter, we introduced some useful platform， Spark  MLlib and  TensorFlow.
And in this session, we will talk about a typical big data analysis application, <span class="lx-highlight lx-current-highlight" data-idx="0" style="background-color:#D2E3FC;">Recommendation System</span>
<span class="lx-highlight" data-idx="1" style="background-color:#FEF0C3;">A recommendation system is</span> a subclass of Information filtering Systems that seeks to predict the rating or the preference a user might give to an item. 
In simple words, it is an algorithm that suggests relevant items to users. <span class="lx-highlight" data-idx="2" style="background-color:#C8E6C9;">Recommendation system is widely used in many fields, like Netflex, Amazon, JD, TaoBao
QQ music etc.
Recommendation Algorithms can be roughly divided into 3 categories. <span class="lx-highlight" data-idx="3" style="background-color:#D2E3FC;">Collaborative filtering</span>, content based and knowledge based. And the big difference between Collaborative filtering algorithm and content-based algorithm is that content based algorithm relies on the item features themselves, but the Collaborative filtering relies on how other user respond to the same item.
Collaborative filtering can be further divided into Neighborhood-based and model based, neighborhood-based algorithm includes user-based and item-based algorithm, and we will discuss in this session. Model based algorithms include Latent Factor model, Graph model and others. In latent Factor model, I will use matrix factorization as example to explain.
The content-based recommendation algorithm recommends items based on item features, which include structured features and unstructured features.
And the third category is knowledge-based algorithms.
Let ‘s look at the diagram,  
on the left it is the Collaborative filtering, exampled by user-based filtering algorithm.
it shows that the similar users will have the similar preferences for articles, 
and the similar users are defined based on the common articles (the green and red) they read.
Since they are similar users, the article read by her (the blue article) can be recommended to him.
On the right , it is content-based filtering recommendation , the red article and the green article are defined similar articles based on the article’s features, and when the red article is read by the user, the green article will be recommended to the same user.
This picture shows the user-based filtering and item-based filtering.
In user-based filtering, we find the similar users based on the common items they chose before, 
here Tim chose Ice cream with Egg Roll, chocolate, ice cream cone and donut, 
and John chose chocolate ice cream cone, Tim and John have certain items in common, then we define them similar users.
for the items Tim has chosen and John not, we can recommend to John, here are the Ice cream with Egg Roll and donut.
In item-based filtering, we define the Ice cream with Egg Roll and ice cream cone as similar items based on the user chosen behavior, 
and John has chosen the ice cream cone, so we recommend the Ice cream with Egg Roll to him.
We will explain the user-based filtering and item-based filtering in detail.
In this session we will explain 3 main Recommendation System Algorithms,
User-based filtering, Item-based filtering, and <span class="lx-highlight" data-idx="4" style="background-color:#D2E3FC;">Content</span> Based Filtering.
First let ‘s look at User-based filtering Recommendation System Algorithms.
The steps for User-based filtering are shown in the diagram, 
） we collect the User purchase records, 
） we build Item to User table based on the User purchase records.
） the User to User matrix is built based on Item to User table;
） the User – User similarity matrix is built based on User to User matrix ;
）then calculate the user&#x27;s interest in different items.
） Get recommendation result based on the user&#x27;s interest in different items.
<span class="lx-highlight" data-idx="5" style="background-color:#D2E3FC;">User-based collaborative filtering</span> is an algorithmic framework where the similar users are identified based on the similarity with the active user, and then scoring of the items is done based on neighbor’s ratings followed by a recommendation of an item based item’s scores by the recommendation system. 
Multiple users choose many of the same items, we can call these users similar users. 
In the user-based collaborative filtering algorithm, we believe that: a user will like items that his or her similar users like with higher probability. 
So how to calculate the similarity of the users. 
Usually use Jaccard similarity, cosine similarity, Euclidean distance and Pearson distance to calculate the similarity between two users.
Let N(u) be the set of items that user U likes, and N(v) be the set of items that user V likes.
Jaccard similarity, cosine similarity calculation methods are shown here.
Let us make an example to get recommendation result using User-based collaborative filtering.
Here the big ABCD are users, and the small a b c d and e are items, 
Based on the User purchase records, we build the item- user table, which shows for each item, all the uses who have purchased this item.
For example, item a is purchased by user A and B, item b is purchased by User A and C, etc.
Then User - User matrix is built based on the item to user table, in the way that each element value is the numbers of common items purchased by the row user and column user.
For example, the element of the first row and second column is calculated by the common items number of user A and B, they have just one common item which is item a, so the value is 1.
The other matrix element value is calculated in the same way.
Based on the User - User matrix we just calculated, use Cosine similarity we can calculate the User – User similarity matrix, 
each element in this matrix is the similarity of the user in corresponding row and user in corresponding column.
Here N(u) is the set of items that user U likes, and N(v) is the set of items that user V likes.
After we have the User – User similarity matrix, 
For each candidate item i, the degree that the user u is interested in it P(u,i) can be computed using the above formula.
Suppose we want to recommend items to user A, 
select K = 3 similar users, 
and similar users are B, C and D, based on the User – User similarity matrix
then the items that B, C and D chose and A has not chosen are c and e, 
then calculate user A &#x27;s interest in item c, P (A, c) and e, P (A, e) respectively, 
they both are 0.7416, which means User A  likes c and e equally.
Now let’s look at Item-based filtering
Now let’s look at the <span class="lx-highlight" data-idx="6" style="background-color:#D2E3FC;">Item-based collaborative filtering</span>.
Calculate the similarity between items and recommend items with high similarity to the items chosen by users. 
In the item-based collaborative filtering algorithm, we believe that: the similarity between item A and item B is because users who like item A also like item B. 
The calculation is also based on the user purchase records.
Item-item matrix is computed based on that. 
In the Item-item matrix , each element is the number of the users who chose the item in the corresponding row and the item in the corresponding column.
For example, on the right, in the Item - Item matrix, the value of the element in the first row, second column, the number of the users who chose both item a and item b is one, just user A.
The other elements can be calculated in the same way.
Now let ‘s calculate the Similarity of 
Let N(i) be the set of users who like item i, and N(j) be the set of users who like item j, 
and Intersection of N(i) and N(j) be the number of users who like both item i and item j.
cosine similarity of item i and item j, Wij can be calculated as the formula, 
the number of Intersection of N(i) and N(j) divided by the number of the union of N(i) and N(j) . 
Item - Item similarity matrix can be calculated using cosine similarity based on Item - Item matrix as showed on the right matrix.
Now let ‘s compute the user&#x27;s interest in different items.
For each candidate item j, the degree user u interested in item j, Puj can be calculate as the formula shows: 
where, N(u) represents the collection of items favored by user U, S (j, k) is the collection of k items most like item j, 
Wij is the similarity between item i and item j, and Rui represents user u&#x27;s interest in item i.
Now we can get recommendation result.
Suppose we want to recommend items to user B, select K = 3 similar items, 
so, the items user B has not chosen before are b, d and e. 
then calculate P (B, d), P (B, b) and P (B, e) respectively and 1, 0.5, 0.5, 
then we think User B likes d most and User B likes b, e equally
For user-based filtering
How to calculate the degree of user&#x27;s interest in candidate items based on users? 
We need to establish a connection between the user and the candidate item, and the connection is the user similarity. 
For example on the left, we calculate the user A’s interest degree in Item c in P (A, c), the items have been purchased by users are B and D, so add the similarity of W.AB and W.AD.
And for item-based filtering
How to calculate the degree of user‘s interest in candidate items based on items? 
We still need to establish a connection between the user and the candidate item, and the connection is the item similarity. 
For example on the left, we calculate User B’s interest degree in Item d in P (B, d), the items  have been purchased are item a and item c, so add the similarity of W.da and W.dc.
Now let’s look at Content-Based Filtering
Content-based Filtering Recommendations, is the first recommendation algorithm that recommends items similar to a user&#x27;s past favorite items.
The key here is the measure of item similarity, which is the core of the algorithm application process. 
Three main steps:
<span class="lx-highlight" data-idx="7" style="background-color:#D2E3FC;">Item Representation</span>: extracting some features (content) for each item to represent them
<span class="lx-highlight" data-idx="8" style="background-color:#D2E3FC;">Profile Learning</span></span>: Using the feature data of a user&#x27;s past favorite (or not favorite) items to learn the user&#x27;s preference features (that is user’s profile)
<span class="lx-highlight" data-idx="9" style="background-color:#D2E3FC;">Recommendation Generation</span>: By comparing the user profile obtained in the previous step with the features of the candidate items, a set of items with the highest relevance is recommended <span class="lx-highlight" data-idx="10" style="background-color:#F9DEDC;">to this user.
In this session, we learned 3 main Recommendation System Algorithms</span>,
User-based filtering, Item-based filtering and Content-Based Filtering
thank you for your attention, if you have any question, feel free to contact me.
      </div>
      <div class="lx-controls">
        <div class="lx-button-row">
          <button class="lx-control-btn" onclick="playPause()">▶️ Play</button>
          <button class="lx-control-btn" onclick="prevExtraction()">⏮ Previous</button>
          <button class="lx-control-btn" onclick="nextExtraction()">⏭ Next</button>
        </div>
        <div class="lx-progress-container">
          <input type="range" id="progressSlider" class="lx-progress-slider"
                 min="0" max="10" value="0"
                 onchange="jumpToExtraction(this.value)">
        </div>
        <div class="lx-status-text">
          Entity <span id="entityInfo">1/11</span> |
          Pos <span id="posInfo">[9980-10061]</span>
        </div>
      </div>
    </div>

    <script>
      (function() {
        const extractions = [{"index": 0, "class": "CONCEPT", "text": "Recommendation System", "color": "#D2E3FC", "startPos": 318, "endPos": 339, "beforeText": "r, we introduced some useful platform\uff0c Spark  MLlib and  TensorFlow.\nAnd in this session, we will talk about a typical big data analysis application, ", "extractionText": "Recommendation System", "afterText": "\nA recommendation system is a subclass of Information filtering Systems that seeks to predict the rating or the preference a user might give to an ite", "attributesHtml": "<div><strong>class:</strong> CONCEPT</div><div><strong>attributes:</strong> {<span class=\"lx-attr-key\">definition</span>: <span class=\"lx-attr-value\">A subclass of Information filtering Systems that seeks to predict the rating or the preference a user might give to an item; an algorithm that suggests relevant items to users.</span>}</div>"}, {"index": 1, "class": "SUMMARY", "text": "A recommendation system is an information filtering algorithm that predicts a user's preference for an item. These systems are broadly categorized into Collaborative Filtering, Content-Based, and Knowledge-Based algorithms. Collaborative filtering relies on user behavior, while content-based filtering uses item features. This session focuses on three main algorithms. The first, User-based collaborative filtering, identifies similar users based on common items they have rated or purchased. It then recommends items liked by these similar users to the target user. The process involves building item-to-user and user-to-user matrices, calculating user similarity using methods like Jaccard or cosine similarity, and then scoring potential items. The second, Item-based collaborative filtering, calculates similarity between items based on how many users liked both. It recommends items that are similar to those a user has already liked. This involves creating an item-item similarity matrix. The third, Content-Based filtering, recommends items that are similar to a user's past favorites based on their intrinsic features. This involves three steps: Item Representation (extracting features), Profile Learning (creating a user preference profile), and Recommendation Generation (matching the profile to candidate items).", "color": "#FEF0C3", "startPos": 340, "endPos": 366, "beforeText": "useful platform\uff0c Spark  MLlib and  TensorFlow.\nAnd in this session, we will talk about a typical big data analysis application, Recommendation System\n", "extractionText": "A recommendation system is", "afterText": " a subclass of Information filtering Systems that seeks to predict the rating or the preference a user might give to an item. \nIn simple words, it is ", "attributesHtml": "<div><strong>class:</strong> SUMMARY</div><div><strong>attributes:</strong> {}</div>"}, {"index": 2, "class": "KEYWORDS", "text": "Recommendation System, Collaborative Filtering, Content-Based Filtering, User-based filtering, Item-based filtering, Similarity Matrix, Cosine Similarity, Jaccard Similarity, Profile Learning", "color": "#C8E6C9", "startPos": 568, "endPos": 9654, "beforeText": "eks to predict the rating or the preference a user might give to an item. \nIn simple words, it is an algorithm that suggests relevant items to users. ", "extractionText": "Recommendation system is widely used in many fields, like Netflex, Amazon, JD, TaoBao\nQQ music etc.\nRecommendation Algorithms can be roughly divided into 3 categories. Collaborative filtering, content based and knowledge based. And the big difference between Collaborative filtering algorithm and content-based algorithm is that content based algorithm relies on the item features themselves, but the Collaborative filtering relies on how other user respond to the same item.\nCollaborative filtering can be further divided into Neighborhood-based and model based, neighborhood-based algorithm includes user-based and item-based algorithm, and we will discuss in this session. Model based algorithms include Latent Factor model, Graph model and others. In latent Factor model, I will use matrix factorization as example to explain.\nThe content-based recommendation algorithm recommends items based on item features, which include structured features and unstructured features.\nAnd the third category is knowledge-based algorithms.\nLet \u2018s look at the diagram,  \non the left it is the Collaborative filtering, exampled by user-based filtering algorithm.\nit shows that the similar users will have the similar preferences for articles, \nand the similar users are defined based on the common articles (the green and red) they read.\nSince they are similar users, the article read by her (the blue article) can be recommended to him.\nOn the right , it is content-based filtering recommendation , the red article and the green article are defined similar articles based on the article\u2019s features, and when the red article is read by the user, the green article will be recommended to the same user.\nThis picture shows the user-based filtering and item-based filtering.\nIn user-based filtering, we find the similar users based on the common items they chose before, \nhere Tim chose Ice cream with Egg Roll, chocolate, ice cream cone and donut, \nand John chose chocolate ice cream cone, Tim and John have certain items in common, then we define them similar users.\nfor the items Tim has chosen and John not, we can recommend to John, here are the Ice cream with Egg Roll and donut.\nIn item-based filtering, we define the Ice cream with Egg Roll and ice cream cone as similar items based on the user chosen behavior, \nand John has chosen the ice cream cone, so we recommend the Ice cream with Egg Roll to him.\nWe will explain the user-based filtering and item-based filtering in detail.\nIn this session we will explain 3 main Recommendation System Algorithms,\nUser-based filtering, Item-based filtering, and Content Based Filtering.\nFirst let \u2018s look at User-based filtering Recommendation System Algorithms.\nThe steps for User-based filtering are shown in the diagram, \n\uff09 we collect the User purchase records, \n\uff09 we build Item to User table based on the User purchase records.\n\uff09 the User to User matrix is built based on Item to User table;\n\uff09 the User \u2013 User similarity matrix is built based on User to User matrix ;\n\uff09then calculate the user&#x27;s interest in different items.\n\uff09 Get recommendation result based on the user&#x27;s interest in different items.\nUser-based collaborative filtering is an algorithmic framework where the similar users are identified based on the similarity with the active user, and then scoring of the items is done based on neighbor\u2019s ratings followed by a recommendation of an item based item\u2019s scores by the recommendation system.\u00a0\nMultiple users choose many of the same items, we can call these users similar users. \nIn the user-based collaborative filtering algorithm, we believe that: a user\u00a0will like items that his or her similar users like with higher\u00a0probability. \nSo how to calculate the similarity of the users. \nUsually use Jaccard similarity, cosine similarity, Euclidean distance and Pearson distance to calculate the similarity between two users.\nLet N(u) be the set of items that user U likes, and N(v) be the set of items that user V likes.\nJaccard similarity, cosine similarity calculation methods are shown here.\nLet us make an example to get recommendation result using User-based collaborative filtering.\nHere the big ABCD are users, and the small a b c d and e are items, \nBased on the User purchase records, we build the item- user table, which shows for each item, all the uses who have purchased this item.\nFor example, item a is purchased by user A and B, item b is purchased by User A and C, etc.\nThen User - User matrix is built based on the item to user table, in the way that each element value is the numbers of common items purchased by the row user and column user.\nFor example, the element of the first row and second column is calculated by the common items number of user A and B, they have just one common item which is item a, so the value is 1.\nThe other matrix element value is calculated in the same way.\nBased on the User - User matrix we just calculated, use Cosine similarity we can calculate the User \u2013 User similarity matrix, \neach element in this matrix is the similarity of the user in corresponding row and user in corresponding column.\nHere N(u) is the set of items that user U likes, and N(v) is the set of items that user V likes.\nAfter we have the User \u2013 User similarity matrix, \nFor each candidate item i, the degree that the user u is interested in it P(u,i) can be computed using the above formula.\nSuppose we want to recommend items to user A, \nselect K = 3 similar users, \nand similar users are B, C and D, based on the User \u2013 User similarity matrix\nthen the items that B, C and D chose and A has not chosen are c and e, \nthen calculate user A &#x27;s interest in item c, P (A, c) and e, P (A, e) respectively, \nthey both are 0.7416, which means User A  likes c and e equally.\nNow let\u2019s look at Item-based filtering\nNow let\u2019s look at the Item-based collaborative filtering.\nCalculate the similarity between items and recommend items with high similarity to the items chosen by users. \nIn the item-based collaborative filtering algorithm, we believe that: the similarity between item A and item B is because users who like item A also like item B. \nThe calculation is also based on the user purchase records.\nItem-item matrix is computed based on that. \nIn the Item-item matrix , each element is the number of the users who chose the item in the corresponding row and the item in the corresponding column.\nFor example, on the right, in the Item - Item matrix, the value of the element in the first row, second column, the number of the users who chose both item a and item b is one, just user A.\nThe other elements can be calculated in the same way.\nNow let \u2018s calculate the Similarity of \nLet N(i) be the set of users who like item i, and N(j) be the set of users who like item j, \nand Intersection of N(i) and N(j) be the number of users who like both item i and item j.\ncosine similarity of item i and item j, Wij can be calculated as the formula, \nthe number of Intersection of N(i) and N(j) divided by the number of the union of N(i) and N(j) . \nItem - Item similarity matrix can be calculated using cosine similarity based on Item - Item matrix as showed on the right matrix.\nNow let \u2018s compute the user&#x27;s interest in different items.\nFor each candidate item j, the degree user u interested in item j, Puj can be calculate as the formula shows: \nwhere, N(u) represents the collection of items favored by user U, S (j, k) is the collection of k items most like item j, \nWij is the similarity between item i and item j, and Rui represents user u&#x27;s interest in item i.\nNow we can get recommendation result.\nSuppose we want to recommend items to user B, select K = 3 similar items, \nso, the items user B has not chosen before are b, d and e. \nthen calculate P (B, d), P (B, b) and P (B, e) respectively and 1, 0.5, 0.5, \nthen we think User B likes d most and User B likes b, e equally\nFor user-based filtering\nHow to calculate the degree of user&#x27;s interest in candidate items based on users? \nWe need to establish a connection between the user and the candidate item, and the connection is the user similarity. \nFor example on the left, we calculate the user A\u2019s interest degree in Item c in P (A, c), the items have been purchased by users are B and D, so add the similarity of W.AB and W.AD.\nAnd for item-based filtering\nHow to calculate the degree of user\u2018s interest in candidate items based on items? \nWe still need to establish a connection between the user and the candidate item, and the connection is the item similarity. \nFor example on the left, we calculate User B\u2019s interest degree in Item d in P (B, d), the items  have been purchased are item a and item c, so add the similarity of W.da and W.dc.\nNow let\u2019s look at Content-Based Filtering\nContent-based Filtering Recommendations, is the first recommendation algorithm that recommends items similar to a user&#x27;s past favorite items.\nThe key here is the measure of item similarity, which is the core of the algorithm application process. \nThree main steps:\nItem Representation: extracting some features (content) for each item to represent them\nProfile Learning", "afterText": ": Using the feature data of a user&#x27;s past favorite (or not favorite) items to learn the user&#x27;s preference features (that is user\u2019s profile)\nRecommenda", "attributesHtml": "<div><strong>class:</strong> KEYWORDS</div><div><strong>attributes:</strong> {}</div>"}, {"index": 3, "class": "CONCEPT", "text": "Collaborative Filtering", "color": "#D2E3FC", "startPos": 736, "endPos": 759, "beforeText": "tem is widely used in many fields, like Netflex, Amazon, JD, TaoBao\nQQ music etc.\nRecommendation Algorithms can be roughly divided into 3 categories. ", "extractionText": "Collaborative filtering", "afterText": ", content based and knowledge based. And the big difference between Collaborative filtering algorithm and content-based algorithm is that content base", "attributesHtml": "<div><strong>class:</strong> CONCEPT</div><div><strong>attributes:</strong> {<span class=\"lx-attr-key\">definition</span>: <span class=\"lx-attr-value\">A type of recommendation algorithm that relies on how other users respond to the same item, rather than the item&#x27;s features. It can be divided into neighborhood-based (user-based, item-based) and model-based approaches.</span>}</div>"}, {"index": 4, "class": "CONCEPT", "text": "Content-Based Filtering", "color": "#D2E3FC", "startPos": 3164, "endPos": 3171, "beforeText": "m-based filtering in detail.\nIn this session we will explain 3 main Recommendation System Algorithms,\nUser-based filtering, Item-based filtering, and ", "extractionText": "Content", "afterText": " Based Filtering.\nFirst let \u2018s look at User-based filtering Recommendation System Algorithms.\nThe steps for User-based filtering are shown in the diag", "attributesHtml": "<div><strong>class:</strong> CONCEPT</div><div><strong>attributes:</strong> {<span class=\"lx-attr-key\">definition</span>: <span class=\"lx-attr-value\">A recommendation algorithm that recommends items similar to a user&#x27;s past favorite items based on the item features themselves.</span>}</div>"}, {"index": 5, "class": "CONCEPT", "text": "User-based collaborative filtering", "color": "#D2E3FC", "startPos": 3707, "endPos": 3741, "beforeText": "to User matrix ;\n\uff09then calculate the user&#x27;s interest in different items.\n\uff09 Get recommendation result based on the user&#x27;s interest in different items.\n", "extractionText": "User-based collaborative filtering", "afterText": " is an algorithmic framework where the similar users are identified based on the similarity with the active user, and then scoring of the items is don", "attributesHtml": "<div><strong>class:</strong> CONCEPT</div><div><strong>attributes:</strong> {<span class=\"lx-attr-key\">definition</span>: <span class=\"lx-attr-value\">An algorithmic framework where similar users are identified based on their similarity with an active user, and items are scored and recommended based on the neighbors&#x27; ratings. The core principle is that a user will likely enjoy items that similar users like.</span>}</div>"}, {"index": 6, "class": "CONCEPT", "text": "Item-based collaborative filtering", "color": "#D2E3FC", "startPos": 6369, "endPos": 6403, "beforeText": "P (A, e) respectively, \nthey both are 0.7416, which means User A  likes c and e equally.\nNow let\u2019s look at Item-based filtering\nNow let\u2019s look at the ", "extractionText": "Item-based collaborative filtering", "afterText": ".\nCalculate the similarity between items and recommend items with high similarity to the items chosen by users. \nIn the item-based collaborative filte", "attributesHtml": "<div><strong>class:</strong> CONCEPT</div><div><strong>attributes:</strong> {<span class=\"lx-attr-key\">definition</span>: <span class=\"lx-attr-value\">A recommendation algorithm that calculates the similarity between items and recommends items with high similarity to those already chosen by a user. The core principle is that similarity between two items is established because users who like one also tend to like the other.</span>}</div>"}, {"index": 7, "class": "CONCEPT", "text": "Item Representation", "color": "#D2E3FC", "startPos": 9550, "endPos": 9569, "beforeText": "ser&#x27;s past favorite items.\nThe key here is the measure of item similarity, which is the core of the algorithm application process. \nThree main steps:\n", "extractionText": "Item Representation", "afterText": ": extracting some features (content) for each item to represent them\nProfile Learning: Using the feature data of a user&#x27;s past favorite (or not favori", "attributesHtml": "<div><strong>class:</strong> CONCEPT</div><div><strong>attributes:</strong> {<span class=\"lx-attr-key\">definition</span>: <span class=\"lx-attr-value\">A step in content-based filtering that involves extracting features (content) for each item to represent them.</span>}</div>"}, {"index": 8, "class": "CONCEPT", "text": "Profile Learning", "color": "#D2E3FC", "startPos": 9638, "endPos": 9654, "beforeText": "core of the algorithm application process. \nThree main steps:\nItem Representation: extracting some features (content) for each item to represent them\n", "extractionText": "Profile Learning", "afterText": ": Using the feature data of a user&#x27;s past favorite (or not favorite) items to learn the user&#x27;s preference features (that is user\u2019s profile)\nRecommenda", "attributesHtml": "<div><strong>class:</strong> CONCEPT</div><div><strong>attributes:</strong> {<span class=\"lx-attr-key\">definition</span>: <span class=\"lx-attr-value\">A step in content-based filtering that uses the feature data of a user&#x27;s past favorite items to learn the user&#x27;s preference features, creating a user profile.</span>}</div>"}, {"index": 9, "class": "CONCEPT", "text": "Recommendation Generation", "color": "#D2E3FC", "startPos": 9794, "endPos": 9819, "beforeText": "e Learning: Using the feature data of a user&#x27;s past favorite (or not favorite) items to learn the user&#x27;s preference features (that is user\u2019s profile)\n", "extractionText": "Recommendation Generation", "afterText": ": By comparing the user profile obtained in the previous step with the features of the candidate items, a set of items with the highest relevance is r", "attributesHtml": "<div><strong>class:</strong> CONCEPT</div><div><strong>attributes:</strong> {<span class=\"lx-attr-key\">definition</span>: <span class=\"lx-attr-value\">A step in content-based filtering that involves comparing a user&#x27;s profile with the features of candidate items to recommend a set of items with the highest relevance.</span>}</div>"}, {"index": 10, "class": "TOPIC", "text": "Introduction to Recommendation System Algorithms", "color": "#F9DEDC", "startPos": 9980, "endPos": 10061, "beforeText": "ing the user profile obtained in the previous step with the features of the candidate items, a set of items with the highest relevance is recommended ", "extractionText": "to this user.\nIn this session, we learned 3 main Recommendation System Algorithms", "afterText": ",\nUser-based filtering, Item-based filtering and Content-Based Filtering\nthank you for your attention, if you have any question, feel free to contact ", "attributesHtml": "<div><strong>class:</strong> TOPIC</div><div><strong>attributes:</strong> {}</div>"}];
        let currentIndex = 0;
        let isPlaying = false;
        let animationInterval = null;
        let animationSpeed = 1.0;

        function updateDisplay() {
          const extraction = extractions[currentIndex];
          if (!extraction) return;

          document.getElementById('attributesContainer').innerHTML = extraction.attributesHtml;
          document.getElementById('entityInfo').textContent = (currentIndex + 1) + '/' + extractions.length;
          document.getElementById('posInfo').textContent = '[' + extraction.startPos + '-' + extraction.endPos + ']';
          document.getElementById('progressSlider').value = currentIndex;

          const playBtn = document.querySelector('.lx-control-btn');
          if (playBtn) playBtn.textContent = isPlaying ? '⏸ Pause' : '▶️ Play';

          const prevHighlight = document.querySelector('.lx-text-window .lx-current-highlight');
          if (prevHighlight) prevHighlight.classList.remove('lx-current-highlight');
          const currentSpan = document.querySelector('.lx-text-window span[data-idx="' + currentIndex + '"]');
          if (currentSpan) {
            currentSpan.classList.add('lx-current-highlight');
            currentSpan.scrollIntoView({block: 'center', behavior: 'smooth'});
          }
        }

        function nextExtraction() {
          currentIndex = (currentIndex + 1) % extractions.length;
          updateDisplay();
        }

        function prevExtraction() {
          currentIndex = (currentIndex - 1 + extractions.length) % extractions.length;
          updateDisplay();
        }

        function jumpToExtraction(index) {
          currentIndex = parseInt(index);
          updateDisplay();
        }

        function playPause() {
          if (isPlaying) {
            clearInterval(animationInterval);
            isPlaying = false;
          } else {
            animationInterval = setInterval(nextExtraction, animationSpeed * 1000);
            isPlaying = true;
          }
          updateDisplay();
        }

        window.playPause = playPause;
        window.nextExtraction = nextExtraction;
        window.prevExtraction = prevExtraction;
        window.jumpToExtraction = jumpToExtraction;

        updateDisplay();
      })();
    </script>