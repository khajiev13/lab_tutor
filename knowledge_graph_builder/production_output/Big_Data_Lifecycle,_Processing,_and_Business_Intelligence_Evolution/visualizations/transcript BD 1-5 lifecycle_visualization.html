<style>
.lx-highlight { position: relative; border-radius:3px; padding:1px 2px;}
.lx-highlight .lx-tooltip {
  visibility: hidden;
  opacity: 0;
  transition: opacity 0.2s ease-in-out;
  background: #333;
  color: #fff;
  text-align: left;
  border-radius: 4px;
  padding: 6px 8px;
  position: absolute;
  z-index: 1000;
  bottom: 125%;
  left: 50%;
  transform: translateX(-50%);
  font-size: 12px;
  max-width: 240px;
  white-space: normal;
  box-shadow: 0 2px 6px rgba(0,0,0,0.3);
}
.lx-highlight:hover .lx-tooltip { visibility: visible; opacity:1; }
.lx-animated-wrapper { max-width: 100%; font-family: Arial, sans-serif; }
.lx-controls {
  background: #fafafa; border: 1px solid #90caf9; border-radius: 8px;
  padding: 12px; margin-bottom: 16px;
}
.lx-button-row {
  display: flex; justify-content: center; gap: 8px; margin-bottom: 12px;
}
.lx-control-btn {
  background: #4285f4; color: white; border: none; border-radius: 4px;
  padding: 8px 16px; cursor: pointer; font-size: 13px; font-weight: 500;
  transition: background-color 0.2s;
}
.lx-control-btn:hover { background: #3367d6; }
.lx-progress-container {
  margin-bottom: 8px;
}
.lx-progress-slider {
  width: 100%; margin: 0; appearance: none; height: 6px;
  background: #ddd; border-radius: 3px; outline: none;
}
.lx-progress-slider::-webkit-slider-thumb {
  appearance: none; width: 18px; height: 18px; background: #4285f4;
  border-radius: 50%; cursor: pointer;
}
.lx-progress-slider::-moz-range-thumb {
  width: 18px; height: 18px; background: #4285f4; border-radius: 50%;
  cursor: pointer; border: none;
}
.lx-status-text {
  text-align: center; font-size: 12px; color: #666; margin-top: 4px;
}
.lx-text-window {
  font-family: monospace; white-space: pre-wrap; border: 1px solid #90caf9;
  padding: 12px; max-height: 260px; overflow-y: auto; margin-bottom: 12px;
  line-height: 1.6;
}
.lx-attributes-panel {
  background: #fafafa; border: 1px solid #90caf9; border-radius: 6px;
  padding: 8px 10px; margin-top: 8px; font-size: 13px;
}
.lx-current-highlight {
  border-bottom: 4px solid #ff4444;
  font-weight: bold;
  animation: lx-pulse 1s ease-in-out;
}
@keyframes lx-pulse {
  0% { text-decoration-color: #ff4444; }
  50% { text-decoration-color: #ff0000; }
  100% { text-decoration-color: #ff4444; }
}
.lx-legend {
  font-size: 12px; margin-bottom: 8px;
  padding-bottom: 8px; border-bottom: 1px solid #e0e0e0;
}
.lx-label {
  display: inline-block;
  padding: 2px 4px;
  border-radius: 3px;
  margin-right: 4px;
  color: #000;
}
.lx-attr-key {
  font-weight: 600;
  color: #1565c0;
  letter-spacing: 0.3px;
}
.lx-attr-value {
  font-weight: 400;
  opacity: 0.85;
  letter-spacing: 0.2px;
}

/* Add optimizations with larger fonts and better readability for GIFs */
.lx-gif-optimized .lx-text-window { font-size: 16px; line-height: 1.8; }
.lx-gif-optimized .lx-attributes-panel { font-size: 15px; }
.lx-gif-optimized .lx-current-highlight { text-decoration-thickness: 4px; }
</style>
    <div class="lx-animated-wrapper lx-gif-optimized">
      <div class="lx-attributes-panel">
        <div class="lx-legend">Highlights Legend: <span class="lx-label" style="background-color:#D2E3FC;">CONCEPT</span> <span class="lx-label" style="background-color:#C8E6C9;">KEYWORDS</span> <span class="lx-label" style="background-color:#FEF0C3;">SUMMARY</span> <span class="lx-label" style="background-color:#F9DEDC;">TOPIC</span></div>
        <div id="attributesContainer"></div>
      </div>
      <div class="lx-text-window" id="textWindow">
        Hello everyone, I am Haiying Che, from Institute of Data Science and knowledge Engineering，
School of Computer Science, Beijing Institute of Technology, 
in this session, we will discuss about <span class="lx-highlight lx-current-highlight" data-idx="0" style="background-color:#F9DEDC;">big data Lifecycle</span> and big data processing flow.
The effective use of Big Data with exponential growth in data types and data volumes has the potential to transform economies，useful business and marketing information and customer surplus. Big Data has become a key success mantra for current competitive markets for existing companies, and a game changer for new companies in the competition. This all can be proven true if VALUE FROM DATA is leveraged
Let’s look at the stages of digging the value in bigdata lifecycle . 
As this figure explains, <span class="lx-highlight" data-idx="1" style="background-color:#FEF0C3;">the Big Data</span> life cycle can be divided into four stages. Let&#x27;s study them in detail.
Collecting data is key in a Big Data life cycle; it defines which type of data is captured at the source. Some examples are gathering logs from the server, fetching user profiles, crawling reviews of organizations for sentiment analysis, and order information. 
Examples that we have mentioned might involve dealing with local language, text, unstructured data, and images, which will be taken care of as we move forward in the Big Data life cycle.
With an increased level of automating data collection streams, organizations that have been classically spending a lot of effort on gathering structured data to analyze and estimate key success data points for business are changing. Mature organizations now use data that was generally ignored because of either its size or format, which, in <span class="lx-highlight" data-idx="2" style="background-color:#C8E6C9;">Big Data</span> terminology, is often referred to as unstructured data. These organizations always try to use the maximum amount of information whether it is structured or unstructured, as for them, data is value.
You can use data to be transferred and consolidated into <span class="lx-highlight" data-idx="3" style="background-color:#D2E3FC;">Big Data</span> platform like HDFS (Hadoop Distributed File System). Once data is processed with the help of tools like Apache Spark, you can load it back to the MySQL database, which can help you populate relevant data to show which MySQL consists.
Storing data that has been collected from various sources. Let&#x27;s consider an example of crawling reviews of organizations for sentiment analysis, where in each gathers data from different sites with each of them having data uniquely displayed.
Traditionally, data was processed using the <span class="lx-highlight" data-idx="4" style="background-color:#D2E3FC;">ETL (Extract, Transform, and Load)</span> procedure, which used to gather data from various sources, modify it according to the requirements, and upload it to the store for further processing or display. Tools that were every so often used for such scenarios were spreadsheets, relational databases, business intelligence tools, and so on, and sometimes manual effort was also a part of it.
The most common storage used in Big Data platform is <span class="lx-highlight" data-idx="5" style="background-color:#D2E3FC;">HDFS</span>. HDFS also provides HQL (Hive Query Language), which helps us do many analytical tasks that are traditionally done in business intelligence tools. A few other storage options that can be considered are Apache Spark, Redis, and MongoDB. Each storage option has their own way of working in the backend; however, most storage providers exposes SQL APIs which can be used to do further data analysis.
There might be a case where we need to gather real-time data and show case in real time, which practically doesn&#x27;t need the data to be stored for future purposes and can run real-time analytics to produce results based on the requests.
Analyze
how these various data types are being analyzed with a common question starting with what if...? 
The way organizations have evolved with data also has impacted new metadata standards, organizing it for initial detection and reprocessing for structural approaches to be matured on the value of data being created.
Most mature organizations reliably provide accessibility, superiority, and value across business units with a constant automated process of structuring metadata and outcomes to be processed for analysis. 
A mature data-driven organization&#x27;s analyzing engine generally works on multiple sources of data and data types, which also includes real-time data.
During the analysis phase, raw data is processed, for which MySQL has Map/Reduce jobs in Hadoop, to analyze and give the output. With MySQL data lying in HDFS, it can be accessed by the rest of the ecosystem of Big Data platform-related tools for further analysis.
)Governance
Value for data cannot be expected for a business without an established governance policy in practice. In the absence of a mature <span class="lx-highlight" data-idx="6" style="background-color:#D2E3FC;">data governance</span> policy, businesses can experience misinterpreted information, which could ultimately cause unpredictable damages to the business. With the help of Big Data governance, an organization can achieve consistent, precise, and actionable awareness of data.
Data governance is all about managing data to meet compliance, privacy, regulatory, legal, and anything that is specifically obligatory as per business requirements. 
For data governance, continuous monitoring, studying, revising, and optimizing the quality of the process should also respect data security needs. So far, data governance has been taken with ease where Big Data is concerned; however, with data growing rapidly and being used in various places, this has drawn attention to data governance. It is gradually becoming a must-considerable factor for any Big Data project.
The purpose of big data analysis is to extract knowledge and wisdom from the data, but all the beginning is raw data,
There are four layers in the <span class="lx-highlight" data-idx="7" style="background-color:#D2E3FC;">DIKW pyramid</span>  model data，which are Information ，Knowledge ，Wisdom.
Data is in the bottom, which is individual facts, figures, signals, measurements, 
And in the special context, we can draw information from the data, then reach the second level; 
Information is organized, structured, categorized, useful, condensed, calculated data.
For example , we have the Taobao online shopping data, and  form one customer’s shopping history, we can summarized the categories this customer preferred, which are his shopping interests. 
Above the information, it is knowledge, which is idea, learning, notion, concept, synthesized, compared, thought-out, discussed. In the example, from the shopping interest, we can learn this customers characters, knowledge is the meaningful information. 
According to the knowledge, we can get the insight, which is understanding, integration, applied, reflected upon, actionable, accumulated, principles, patterns, decision-making progress.
And from bottom to top, the decision risk is decreased, because from processed data we got the information, knowledge and wisdom, the uncertainty is reduced, we know more and more about the decision to make.
Harnessing Big data to get more business intelligence.
Stage1, at the very beginning, the hierarchical database invented in 1968   and the relational database invented in 1970, with these kinds of operational database, based on the data at rest, reporting and human analysis can be made on historical data. In this stage, it was mainly <span class="lx-highlight" data-idx="8" style="background-color:#D2E3FC;">OLTP</span>: Online Transaction Processing 
Stage 2, with the help of data warehousing, people can analyze the current data to improve business transaction, because data warehousing can integrate all the different aspects of the organization comprehensive information, which can help understand the business and customer better, and provide better services. In this stage, it was mainly <span class="lx-highlight" data-idx="9" style="background-color:#D2E3FC;">OLAP</span>: Online Analytical Processing  
Stage 3
With the rapid growth of data, the data is coming faster and need to be processed faster, to solve this in 2000, streaming computing was created, which can process the data fast when it comes, and support <span class="lx-highlight" data-idx="10" style="background-color:#D2E3FC;">RTAP</span>: Real-Time Analytics Processing to make the Realtime decision and improve Realtime business response.
With the data stored in the organization system, we can do the business intelligence, which is Ad-hoc querying and reporting
Using Data mining techniques, based on Structured data, typical sources in Small to mid-size datasets. 
But with the advantage of new technology, more and more data was collected, we want to know more and predict something when it is not happen, in that case the complexity will increase and the business value will expand.
Based on All types of data from many sources, integrate them into very large datasets, Complex statistical analysis can be done, Optimizations and predictive analytics can be made, And More of a real-time manner, and vice versa, which promote people to gather more data. And all this will drive the big data progress.
For example, with the sensors equipped in all the parts of the machine, we can collect the status data and by using data mining, we can predict when the specific part will be expired or broken, and what part of the machine need to be repaired or replaced by analyzing the data perceived from the machine part sensors.
Let’s look at the evolution of business intelligence.
At 1990’s Business Intelligence Reporting OLAP &amp;  Data warehouse can help organize to generate the useful information to summarize the organization situation with the tools like Business Objects, SAS, Informatics, Cognos other SQL Reporting Tools.
In 2000, When the dataset gets big, the analysis takes longer time, we need speed the analysis, with the help of Interactive Business Intelligence &amp; In-memory RDBMS like Tableau, HANA, analysis can be faster,
When the scale gets huge, the big data processing technology is needed. 
In 2010’s both the scale and speed are demanded, Big Data Real Time &amp; Single View of all comprehensive data are needed, then call for more advanced technology to address these challenge.
In this session we learned about big data lifecycle, which includes Collect, Store, Analyze and Governance.
Among all these, analyzing is the purpose, we want to dig value from the raw material. We reviewed the traditional analysis and Big data analysis, 
and nowadays we need fast analyze the huge amount of big data.
That is all for this session, thank you for your attention, if you have any question, feel free to connect me.
      </div>
      <div class="lx-controls">
        <div class="lx-button-row">
          <button class="lx-control-btn" onclick="playPause()">▶️ Play</button>
          <button class="lx-control-btn" onclick="prevExtraction()">⏮ Previous</button>
          <button class="lx-control-btn" onclick="nextExtraction()">⏭ Next</button>
        </div>
        <div class="lx-progress-container">
          <input type="range" id="progressSlider" class="lx-progress-slider"
                 min="0" max="10" value="0"
                 onchange="jumpToExtraction(this.value)">
        </div>
        <div class="lx-status-text">
          Entity <span id="entityInfo">1/11</span> |
          Pos <span id="posInfo">[193-211]</span>
        </div>
      </div>
    </div>

    <script>
      (function() {
        const extractions = [{"index": 0, "class": "TOPIC", "text": "Big Data Lifecycle, Processing, and Business Intelligence Evolution", "color": "#F9DEDC", "startPos": 193, "endPos": 211, "beforeText": "itute of Data Science and knowledge Engineering\uff0c\nSchool of Computer Science, Beijing Institute of Technology, \nin this session, we will discuss about ", "extractionText": "big data Lifecycle", "afterText": " and big data processing flow.\nThe effective use of Big Data with exponential growth in data types and data volumes has the potential to transform eco", "attributesHtml": "<div><strong>class:</strong> TOPIC</div><div><strong>attributes:</strong> {}</div>"}, {"index": 1, "class": "SUMMARY", "text": "The Big Data lifecycle is divided into four stages: Collect, Store, Analyze, and Governance. The collection stage involves gathering various data types, including unstructured data from sources like server logs and user profiles. The storage stage utilizes platforms like HDFS, moving beyond traditional ETL processes. Analysis involves processing raw data with tools like MapReduce to extract value. Governance is crucial for managing data to meet compliance, privacy, and business requirements, ensuring data quality and security. The DIKW pyramid model illustrates the transformation of raw data into information, then knowledge, and finally actionable wisdom, which reduces decision-making risk. The lecture also traces the evolution of business intelligence, starting from OLTP with relational databases, progressing to OLAP with data warehousing for integrated analysis, and then to RTAP with streaming computing for real-time decisions. Modern big data technologies now address the demands for both scale and speed, enabling complex statistical analysis and predictive analytics on very large, diverse datasets.", "color": "#FEF0C3", "startPos": 741, "endPos": 753, "beforeText": "all can be proven true if VALUE FROM DATA is leveraged\nLet\u2019s look at the stages of digging the value in bigdata lifecycle . \nAs this figure explains, ", "extractionText": "the Big Data", "afterText": " life cycle can be divided into four stages. Let&#x27;s study them in detail.\nCollecting data is key in a Big Data life cycle; it defines which type of dat", "attributesHtml": "<div><strong>class:</strong> SUMMARY</div><div><strong>attributes:</strong> {}</div>"}, {"index": 2, "class": "KEYWORDS", "text": "Big Data Lifecycle, Collect, Store, Analyze, Governance, DIKW Pyramid, Business Intelligence, OLTP, OLAP, HDFS", "color": "#C8E6C9", "startPos": 1617, "endPos": 1625, "beforeText": "s data points for business are changing. Mature organizations now use data that was generally ignored because of either its size or format, which, in ", "extractionText": "Big Data", "afterText": " terminology, is often referred to as unstructured data. These organizations always try to use the maximum amount of information whether it is structu", "attributesHtml": "<div><strong>class:</strong> KEYWORDS</div><div><strong>attributes:</strong> {}</div>"}, {"index": 3, "class": "CONCEPT", "text": "Big Data Lifecycle", "color": "#D2E3FC", "startPos": 1881, "endPos": 1889, "beforeText": " amount of information whether it is structured or unstructured, as for them, data is value.\nYou can use data to be transferred and consolidated into ", "extractionText": "Big Data", "afterText": " platform like HDFS (Hadoop Distributed File System). Once data is processed with the help of tools like Apache Spark, you can load it back to the MyS", "attributesHtml": "<div><strong>class:</strong> CONCEPT</div><div><strong>attributes:</strong> {<span class=\"lx-attr-key\">definition</span>: <span class=\"lx-attr-value\">A process divided into four stages (Collecting data, Storing data, Analyze, and Governance) for extracting value from big data.</span>}</div>"}, {"index": 4, "class": "CONCEPT", "text": "ETL (Extract, Transform, and Load)", "color": "#D2E3FC", "startPos": 2412, "endPos": 2446, "beforeText": "alysis, where in each gathers data from different sites with each of them having data uniquely displayed.\nTraditionally, data was processed using the ", "extractionText": "ETL (Extract, Transform, and Load)", "afterText": " procedure, which used to gather data from various sources, modify it according to the requirements, and upload it to the store for further processing", "attributesHtml": "<div><strong>class:</strong> CONCEPT</div><div><strong>attributes:</strong> {<span class=\"lx-attr-key\">definition</span>: <span class=\"lx-attr-value\">A traditional procedure used to gather data from various sources, modify it according to requirements, and upload it to a store for further processing or display.</span>}</div>"}, {"index": 5, "class": "CONCEPT", "text": "HDFS (Hadoop Distributed File System)", "color": "#D2E3FC", "startPos": 2849, "endPos": 2853, "beforeText": "ases, business intelligence tools, and so on, and sometimes manual effort was also a part of it.\nThe most common storage used in Big Data platform is ", "extractionText": "HDFS", "afterText": ". HDFS also provides HQL (Hive Query Language), which helps us do many analytical tasks that are traditionally done in business intelligence tools. A ", "attributesHtml": "<div><strong>class:</strong> CONCEPT</div><div><strong>attributes:</strong> {<span class=\"lx-attr-key\">definition</span>: <span class=\"lx-attr-value\">The most common storage used in Big Data platforms, which can be used to transfer and consolidate data.</span>}</div>"}, {"index": 6, "class": "CONCEPT", "text": "Data Governance", "color": "#D2E3FC", "startPos": 4570, "endPos": 4585, "beforeText": "alysis.\n)Governance\nValue for data cannot be expected for a business without an established governance policy in practice. In the absence of a mature ", "extractionText": "data governance", "afterText": " policy, businesses can experience misinterpreted information, which could ultimately cause unpredictable damages to the business. With the help of Bi", "attributesHtml": "<div><strong>class:</strong> CONCEPT</div><div><strong>attributes:</strong> {<span class=\"lx-attr-key\">definition</span>: <span class=\"lx-attr-value\">The process of managing data to meet compliance, privacy, regulatory, legal, and other business requirements, allowing an organization to achieve consistent, precise, and actionable awareness of its data.</span>}</div>"}, {"index": 7, "class": "CONCEPT", "text": "DIKW Pyramid", "color": "#D2E3FC", "startPos": 5568, "endPos": 5580, "beforeText": "t.\nThe purpose of big data analysis is to extract knowledge and wisdom from the data, but all the beginning is raw data,\nThere are four layers in the ", "extractionText": "DIKW pyramid", "afterText": "  model data\uff0cwhich are Information \uff0cKnowledge \uff0cWisdom.\nData is in the bottom, which is individual facts, figures, signals, measurements, \nAnd in the s", "attributesHtml": "<div><strong>class:</strong> CONCEPT</div><div><strong>attributes:</strong> {<span class=\"lx-attr-key\">definition</span>: <span class=\"lx-attr-value\">A four-layer model showing the progression from Data (individual facts), to Information (organized data), to Knowledge (meaningful information), and finally to Wisdom (actionable insights and decision-making).</span>}</div>"}, {"index": 8, "class": "CONCEPT", "text": "OLTP (Online Transaction Processing)", "color": "#D2E3FC", "startPos": 7079, "endPos": 7083, "beforeText": "e kinds of operational database, based on the data at rest, reporting and human analysis can be made on historical data. In this stage, it was mainly ", "extractionText": "OLTP", "afterText": ": Online Transaction Processing \nStage 2, with the help of data warehousing, people can analyze the current data to improve business transaction, beca", "attributesHtml": "<div><strong>class:</strong> CONCEPT</div><div><strong>attributes:</strong> {<span class=\"lx-attr-key\">definition</span>: <span class=\"lx-attr-value\">A method used in the first stage of business intelligence, based on operational databases, for reporting and human analysis of historical data.</span>}</div>"}, {"index": 9, "class": "CONCEPT", "text": "OLAP (Online Analytical Processing)", "color": "#D2E3FC", "startPos": 7459, "endPos": 7463, "beforeText": "tion comprehensive information, which can help understand the business and customer better, and provide better services. In this stage, it was mainly ", "extractionText": "OLAP", "afterText": ": Online Analytical Processing  \nStage 3\nWith the rapid growth of data, the data is coming faster and need to be processed faster, to solve this in 20", "attributesHtml": "<div><strong>class:</strong> CONCEPT</div><div><strong>attributes:</strong> {<span class=\"lx-attr-key\">definition</span>: <span class=\"lx-attr-value\">A method used in the second stage of business intelligence, which utilizes data warehousing to analyze current, integrated organizational data to improve business transactions and understanding.</span>}</div>"}, {"index": 10, "class": "CONCEPT", "text": "RTAP (Real-Time Analytics Processing)", "color": "#D2E3FC", "startPos": 7709, "endPos": 7713, "beforeText": "r and need to be processed faster, to solve this in 2000, streaming computing was created, which can process the data fast when it comes, and support ", "extractionText": "RTAP", "afterText": ": Real-Time Analytics Processing to make the Realtime decision and improve Realtime business response.\nWith the data stored in the organization system", "attributesHtml": "<div><strong>class:</strong> CONCEPT</div><div><strong>attributes:</strong> {<span class=\"lx-attr-key\">definition</span>: <span class=\"lx-attr-value\">A method supported by streaming computing to process data as it arrives, enabling real-time decisions and improving real-time business response.</span>}</div>"}];
        let currentIndex = 0;
        let isPlaying = false;
        let animationInterval = null;
        let animationSpeed = 1.0;

        function updateDisplay() {
          const extraction = extractions[currentIndex];
          if (!extraction) return;

          document.getElementById('attributesContainer').innerHTML = extraction.attributesHtml;
          document.getElementById('entityInfo').textContent = (currentIndex + 1) + '/' + extractions.length;
          document.getElementById('posInfo').textContent = '[' + extraction.startPos + '-' + extraction.endPos + ']';
          document.getElementById('progressSlider').value = currentIndex;

          const playBtn = document.querySelector('.lx-control-btn');
          if (playBtn) playBtn.textContent = isPlaying ? '⏸ Pause' : '▶️ Play';

          const prevHighlight = document.querySelector('.lx-text-window .lx-current-highlight');
          if (prevHighlight) prevHighlight.classList.remove('lx-current-highlight');
          const currentSpan = document.querySelector('.lx-text-window span[data-idx="' + currentIndex + '"]');
          if (currentSpan) {
            currentSpan.classList.add('lx-current-highlight');
            currentSpan.scrollIntoView({block: 'center', behavior: 'smooth'});
          }
        }

        function nextExtraction() {
          currentIndex = (currentIndex + 1) % extractions.length;
          updateDisplay();
        }

        function prevExtraction() {
          currentIndex = (currentIndex - 1 + extractions.length) % extractions.length;
          updateDisplay();
        }

        function jumpToExtraction(index) {
          currentIndex = parseInt(index);
          updateDisplay();
        }

        function playPause() {
          if (isPlaying) {
            clearInterval(animationInterval);
            isPlaying = false;
          } else {
            animationInterval = setInterval(nextExtraction, animationSpeed * 1000);
            isPlaying = true;
          }
          updateDisplay();
        }

        window.playPause = playPause;
        window.nextExtraction = nextExtraction;
        window.prevExtraction = prevExtraction;
        window.jumpToExtraction = jumpToExtraction;

        updateDisplay();
      })();
    </script>