{"extractions": [{"extraction_class": "TOPIC", "extraction_text": "Fundamentals of Big Data Storing Systems and Data Modeling", "char_interval": {"start_pos": 953, "end_pos": 1100}, "alignment_status": "match_fuzzy", "extraction_index": 1, "group_index": 0, "description": null, "attributes": null}, {"extraction_class": "SUMMARY", "extraction_text": "A big data computing system comprises three layers: data storing, data processing, and data application. The foundational data storing system is crucial for overall performance and consists of four parts: data collection and modeling, file systems, databases, and a unified data access interface. Data collection involves gathering heterogeneous, unstructured data from diverse sources like logs, web crawlers, and IoT devices. This raw data must be cleaned and transformed through an ETL (Extract, Transform, Load) process to handle issues like missing values and inconsistent formats before being stored. A key part of this stage is data modeling, which creates an abstract model of the data's structure, attributes, and relationships. Data modeling is performed at three levels: the conceptual model, which defines high-level business entities and their relationships; the logical model, which details data structures like tables, keys, and constraints; and the physical model, which specifies the actual storage implementation, including partitions and tablespaces. These models provide a blueprint for designing the database and subsequent data processing.", "char_interval": null, "alignment_status": null, "extraction_index": 2, "group_index": 1, "description": null, "attributes": null}, {"extraction_class": "KEYWORDS", "extraction_text": "Data Storing System, Data Modeling, ETL, Conceptual Model, Logical Model, Physical Model, Data Collection, Big Data Architecture, Unstructured Data", "char_interval": {"start_pos": 7520, "end_pos": 7540}, "alignment_status": "match_lesser", "extraction_index": 3, "group_index": 2, "description": null, "attributes": null}, {"extraction_class": "CONCEPT", "extraction_text": "Data Storing System", "char_interval": {"start_pos": 192, "end_pos": 211}, "alignment_status": "match_fuzzy", "extraction_index": 4, "group_index": 3, "description": null, "attributes": {"definition": "The foundational layer in a big data computing system that collects and stores data to support upper-level data processing. It includes data collection, data modeling, file systems, databases, and a unified data access interface."}}, {"extraction_class": "CONCEPT", "extraction_text": "Data Collection", "char_interval": {"start_pos": 1067, "end_pos": 1082}, "alignment_status": "match_fuzzy", "extraction_index": 5, "group_index": 4, "description": null, "attributes": {"definition": "The process of gathering data from multiple sources (e.g., System logs, Web Crawler, wireless sensor network), cleaning it to remove dirty data (repeated, empty, wrong), and converting it into a standard storage format."}}, {"extraction_class": "CONCEPT", "extraction_text": "ETL (Extract, Transform, Load)", "char_interval": {"start_pos": 2998, "end_pos": 7157}, "alignment_status": "match_fuzzy", "extraction_index": 6, "group_index": 5, "description": null, "attributes": {"definition": "A process for data extraction, cleaning, and conversion. It involves extracting data from various sources, transforming it into a unified standard format for the target database, and loading it."}}, {"extraction_class": "CONCEPT", "extraction_text": "Data Modeling", "char_interval": {"start_pos": 251, "end_pos": 264}, "alignment_status": "match_fuzzy", "extraction_index": 7, "group_index": 6, "description": null, "attributes": {"definition": "The process of establishing an abstract model of entity data, which includes metadata, data structure, attributes, value range, association relationships, consistency, and timeliness. It provides a reference for data storage structure and database design."}}, {"extraction_class": "CONCEPT", "extraction_text": "Conceptual Model", "char_interval": {"start_pos": 5232, "end_pos": 5248}, "alignment_status": "match_fuzzy", "extraction_index": 8, "group_index": 7, "description": null, "attributes": {"definition": "The first step in organizing data requirements, which describes the semantics of a domain. It consists of entity classes representing significant things in the domain and relationship assertions about associations between them."}}, {"extraction_class": "CONCEPT", "extraction_text": "Logical Model", "char_interval": {"start_pos": 6412, "end_pos": 6425}, "alignment_status": "match_fuzzy", "extraction_index": 9, "group_index": 8, "description": null, "attributes": {"definition": "A data model that describes details of data entities, including primary keys, foreign keys, attributes, indexes, relationships, and constraints, often using structures like data tables, data columns, and value ranges."}}, {"extraction_class": "CONCEPT", "extraction_text": "Physical Model", "char_interval": {"start_pos": 5267, "end_pos": 5281}, "alignment_status": "match_fuzzy", "extraction_index": 10, "group_index": 9, "description": null, "attributes": {"definition": "A data model that describes the storage implementation of data, including details such as data partitions, data table spaces, CPUs, and data integration."}}, {"extraction_class": "CONCEPT", "extraction_text": "Data Exhaust", "char_interval": {"start_pos": 2212, "end_pos": 2224}, "alignment_status": "match_fuzzy", "extraction_index": 11, "group_index": 10, "description": null, "attributes": {"definition": "The trail of data left by the activities of an Internet or other computer system user during their online activity, behavior, and transactions."}}], "text": "Hello everyone, I am Haiying Che, from Institute of Data Science and knowledge Engineering\nSchool of Computer Science, in Beijing Institute of Technology, from this session,\nwe start to learn Data storing system, and in this session, we discuss about data modeling.\nThe big data computing system can be summarized into three categories: from bottom to top, they are\nData storing system, Data processing system, Data application system.\nIn data storing system we collect the data and store the data, then support upper level data processing,\nafter data has been well processed, it can support the big data application. Like data analysis, business intelligent, decision making and so on.\nThe data storage architecture is the foundation of big data computing. The upper-level analysis algorithms,\ncomputing models and computing performance all depend on the performance of the data storage system. \nTherefore, the data storage system is an important area of big data research. \nIn the data storing system, there are 4 parts to accomplish the different tasks, which are data collection and data modeling, File system, database, data warehouse and Unified data access interface.\nData collection collect data from multiple data resources, like System logs, Web Crawler, wireless sensor network, internet of things and all kinds of data resources.\nAnd after data has been collected, we need clean the data，delete dirty data like repeated data, empty data, wrong data etc. \nConvert various types of structured, unstructured, and heterogeneous data into standard storage format data, and define data attributes and value ranges. \nAnd We build the data model to organize the data.\nAbove the data collection, it is file system, which physically implement the data storing, it could be Centralized or distributed file system, \nthen database, which design the logical structure to store the data, include RDBMs and No SQL database.\nAll above file system and database is the unified data access interface, which is a data access interface, through which the data processing system can retrieve the data from data storing system.\nThe data can be collected from CRM, ERP, financials, social media, exhaust data, logs, files. \n(Data exhaust or exhaust data is the trail of data left by the activities of an Internet or other computer system users during their online activity, behavior, and transactions. \nDue to the characteristics of multiple data sources, data heterogeneity, unstructured data, distributed computing environment and others, which make the design of big data storage system is more complicated than before.\nThe current big data storage architecture is mainly composed of data layer, distributed file system/non-relational database (NoSQL), and unified database reading interface. \nSome designs will add a data mining and analysis function on top of NoSQL database. Warehouse layer\nThe data layer mainly includes the data acquisition system and provides data extraction, cleaning, and conversion ETL-Extract transform Load, data modeling functions,\n）multiple data sources include enterprise data, business data, personal social data, government statistics, Internet data, Internet of Things data, System log data, Gene sequencing data, atmospheric physics monitoring data, earth satellite observation data, etc.\n） heterogeneous data could be text, pictures, audio and video etc.\n） The unstructured data includes medical imaging data, scans of bank certificates, fragmented communication records, screenshots, etc.\nAll these multiple data sources, heterogeneous data, The unstructured data, all these characteristics make it difficult to store raw data directly in the database.\nIn big data collecting, there are some Problems：\nthe original data format cannot be recognized and processed by the data platform.\nIn many cases, the original data still has problems such as missing records, missing value ranges, and different level data quality problems.\nThis requires cleaning the original data before building a database or data warehouse, by merging or removing duplicate data items, eliminating data errors, \nData could be Extracted from multiple data sources, extract different value ranges from data items to form the data structure of the target database, \nOr data items could be Extracted from one data source and decompose them into multiple structures and load them into the target database,\nTransform means Transforming original data items in different formats into a unified standard target database format. \nData extraction, cleaning and conversion can be done manually or using software tools.\nNow let’s look at data modeling, Data modeling is an important part of the data layer work. \nData modeling is to establish an abstract model of entity data, including metadata, data structure, attributes, value range, association relationship, and consistency, Timeliness and other elements.\nThe data model provides a reference for further data storage structure design, database design and calculation model.\nBusiness model normally includes process model and data model, process model describes how the business works. \nData model describe the data supporting the business process.\nThe data model is defined in three levels conceptual model, logic model, and physical model.\nIn this process diagram. First based on the process models and data requirement we can do the logical modeling, then generate the logical data model as the output.\nSynthesize the logical data model, technical requirement and performance requirements, we carry out the physical data modeling and generate the output physical data model. After we have the logical data model and the corresponding physical model, the generated business data can be stored by creating, updating operations in the logical and physical model.\nData modeling process\nLet’s look at the three data model one by one.\nBased on the user's data function requirements. functions and association relationships are obtained, \nWe can find Entity Class corresponding to the business elements and functions.\nConceptual model schema describes the semantics of a domain (the scope of the model). \nThis consists of entity classes, representing kinds of things of significance in the domain, and relationships assertions about associations between pairs of entity classes. Simply described, a conceptual schema is the first step in organizing the data requirements.\nIn logical model design, more details of data entities, including primary keys, foreign keys, attributes, indexes, relationships, constraints, and even views, with data tables, data columns, value ranges, object-oriented classes, XML tags and other can be describe.\nThe physical model  describes the storage implementation of data, including data partition, data table space, and data integration.This is concerned with partitions, CPUs, tablespaces, and the like.\nAccording to American National Standards Institute, ANSI, the three perspectives should be relatively independent of each other. \nStorage technology can change without affecting either the logical or the conceptual schema. \nThe table/column structure can change without (necessarily) affecting the conceptual schema. \nbut, the structures must remain consistent across all schemas of the same data model, logical or physical.\nUML is commonly used Data modeling language, and\nCommon data modeling tools includes Power designer, ER/studio.CA Erwin, IBM Infosphere Data Architect, etc.\nLet’s summarize, in this session, we learned the first layer of data storing system, which includes data acquisition, extraction, transforming and modeling.\nthank you for your attention, if you have any question, feel free to contact me.", "document_id": "doc_a549c310"}
