{"extractions": [{"extraction_class": "TOPIC", "extraction_text": "Architecture and Operation of the Hadoop Distributed File System (HDFS)", "char_interval": {"start_pos": 2996, "end_pos": 7546}, "alignment_status": "match_fuzzy", "extraction_index": 1, "group_index": 0, "description": null, "attributes": null}, {"extraction_class": "SUMMARY", "extraction_text": "The lecture introduces distributed file systems as the foundational physical storage architecture for big data computing, contrasting them with centralized systems. It focuses on the Hadoop Distributed File System (HDFS), which, like Google's GFS, is a key technology in this area. HDFS employs a master-slave architecture consisting of a single master NameNode and multiple slave DataNodes. The NameNode manages the file system's namespace, metadata, and the mapping of files to data blocks, storing this information in memory for fast access. DataNodes store the actual data blocks on their local disks. To ensure high availability, HDFS replicates each data block (typically 3 copies) across different DataNodes. Data in HDFS is immutable, supporting batch read/write operations but not updates. The session details the HDFS data writing process, where a client communicates with the NameNode to create a file, then streams data through a pipeline of DataNodes for replication. It also explains the data reading process, where the client first gets block locations from the NameNode and then reads data directly from the closest DataNode, with built-in mechanisms for handling node failures and data corruption.", "char_interval": {"start_pos": 216, "end_pos": 219}, "alignment_status": "match_lesser", "extraction_index": 2, "group_index": 1, "description": null, "attributes": null}, {"extraction_class": "KEYWORDS", "extraction_text": "HDFS, distributed file system, NameNode, DataNode, master-slave architecture, data replication, data block, HDFS write process, HDFS read process, GFS", "char_interval": null, "alignment_status": null, "extraction_index": 3, "group_index": 2, "description": null, "attributes": null}, {"extraction_class": "CONCEPT", "extraction_text": "Distributed File System", "char_interval": {"start_pos": 698, "end_pos": 721}, "alignment_status": "match_exact", "extraction_index": 4, "group_index": 3, "description": null, "attributes": {"definition": "A file system where data is stored on servers but is accessed and processed as if it was stored on the local client machine, allowing users on a network to share information and files in a controlled, authorized, and transparent way."}}, {"extraction_class": "CONCEPT", "extraction_text": "HDFS (Hadoop Distributed File System)", "char_interval": null, "alignment_status": null, "extraction_index": 5, "group_index": 4, "description": null, "attributes": {"definition": "An open-source distributed file system that adopts a master-slave structure to provide physical storage for big data. It achieves high availability through data redundancy by saving multiple copies of each data block."}}, {"extraction_class": "CONCEPT", "extraction_text": "GFS (Google File System)", "char_interval": {"start_pos": 1490, "end_pos": 1514}, "alignment_status": "match_exact", "extraction_index": 6, "group_index": 5, "description": null, "attributes": {"definition": "A distributed file system developed by Google, which has evolved into Colossus, and is one of the main file systems in big data computing architecture alongside HDFS."}}, {"extraction_class": "CONCEPT", "extraction_text": "Master-Slave Architecture", "char_interval": {"start_pos": 1586, "end_pos": 1598}, "alignment_status": "match_lesser", "extraction_index": 7, "group_index": 6, "description": null, "attributes": {"definition": "An architectural model used by HDFS, consisting of a master node (NameNode) and several slave nodes (DataNodes) that perform their respective tasks under the master's coordination."}}, {"extraction_class": "CONCEPT", "extraction_text": "NameNode", "char_interval": {"start_pos": 3713, "end_pos": 3721}, "alignment_status": "match_fuzzy", "extraction_index": 8, "group_index": 7, "description": null, "attributes": {"definition": "The master node in an HDFS cluster responsible for managing the file system namespace, the mapping of data files to data blocks to DataNodes, and scheduling client file access. It stores metadata in memory for quick access."}}, {"extraction_class": "CONCEPT", "extraction_text": "DataNode", "char_interval": {"start_pos": 4189, "end_pos": 4197}, "alignment_status": "match_fuzzy", "extraction_index": 9, "group_index": 8, "description": null, "attributes": {"definition": "The slave nodes in an HDFS cluster that store file data blocks on their local disks. They are responsible for processing read and write requests from clients and perform creation, deletion, and replication of data blocks under the unified scheduling of the NameNode."}}, {"extraction_class": "CONCEPT", "extraction_text": "Secondary NameNode", "char_interval": {"start_pos": 2303, "end_pos": 3721}, "alignment_status": "match_fuzzy", "extraction_index": 10, "group_index": 9, "description": null, "attributes": {"definition": "A component in HDFS that regularly connects to the primary NameNode to store an instant image of the system directory on its local disk, providing rollback recovery and restart functions if the primary NameNode fails."}}, {"extraction_class": "CONCEPT", "extraction_text": "Data Block", "char_interval": {"start_pos": 1641, "end_pos": 1651}, "alignment_status": "match_exact", "extraction_index": 11, "group_index": 10, "description": null, "attributes": {"definition": "In HDFS, a fixed-length segment of a file (e.g., 64MB or 128MB). Files are divided into these blocks, which are then replicated and stored on different DataNodes."}}, {"extraction_class": "CONCEPT", "extraction_text": "Data Immutability", "char_interval": {"start_pos": 1786, "end_pos": 1790}, "alignment_status": "match_lesser", "extraction_index": 12, "group_index": 11, "description": null, "attributes": {"definition": "A characteristic of data in HDFS where once data is written, it cannot be changed. HDFS supports batch reading and writing but does not support updating operations on existing data."}}], "text": "Hello everyone, I am Haiying Che, from  Institute of Data Science and knowledge Engineering\nSchool of Computer Science, in Beijing Institute of Technology , in this session we discuss about distributed file system .\nThe big data computing system can be summarized into three categories: \nData storing system, Data processing system, Data application system\nThe data storage architecture is the foundation of big data computing. \nIn data storing system , there are 4 parts to accomplish different tasks, \nwhich are Data collection and modeling, Distributed file system, Distributed database/data warehouse and  Unified Data Access Interface.\nwe learned data collection and modeling, now we focus on distributed file system.\nActually File system could be Centralized or distributed file system, but in the big data scenario, mostly we use distributed file system to achieve the scale and the efficiency.\nThe distributed file system provides a physical storage architecture for data.\nFile system with data stored on servers.  In distributed file system the data is accessed and processed as if it was stored on the local client machine. \nIt is Convenient to share information and files among users on a network in a controlled and authorized way, which is transparent to the users.\nAnd it reaches multiplied storage of a single server.\nAt present, there are the two main file systems in the big data computing architecture, which are\nthe open source community’s architecture HDFS and Google’s GFS (Google file system) which has evolved into Colossus.\nLet ‘s look at the HDFS\nHDFS adopts a master-slave structure. And HDFS save 3 copies of each data block, which means use redundancy to achieve high availability.\nAn HDFS cluster includes a Name node, which is the master node, and several Data Nodes, which are slave nodes.\nAs the central service node, the Name node is responsible for managing the file system namespace, the mapping relationship from data files to data blocks to Data nodes, \nand client scheduling of file access. And the metadata is stored in memory for quick access.\nHDFS also has a secondary name node, which is regularly connected to the primary name node, and the instant image of the system directory is stored on the local disk.\nWhen the primary name node is fails or crashes, the secondary name node can provide the name node rollback recovery and restart functions.\nData node Store file data block, Realize the mapping of data blocks to the local file system of the data node and Data blocks are stored on the local disk\nIn HDFS, each storage file is first divided into multiple data blocks with a fixed length of 64MB or 128MB, \nthese data blocks are replicated to 3 copies and stored on different Data nodes according to a certain rule.\nWhen one data node crashes, we can still retrieve the same data blocks from other 2 copies of another 2 data nodes.\nOnce the data is written, it can’t be changed , so the data in HDFS is immutable. So HDFS just support batch reading and writing operation, but doesn’t support updating operation.\nThis means that a Data Node can store data blocks from different files. \nEach data node runs a node program or process, which is responsible for processing read and write requests from the file system client.\nThe creation, deletion, and replication of data blocks are performed under the unified scheduling of the Name node. \nThe master node Name node and the slave node Data node perform their respective tasks\nNow let’s understand the Process of writing data in HDFS , The diagram summarizes file write operation in Hadoop.\nThe client creates the file by calling create() method on DistributedFileSystem.\nDistributedFileSystem makes an RPC call to the namenode to create a new file in the filesystem’s namespace, with no blocks associated with it.\nThe namenode performs various checks to make sure the file doesn’t already exist and the client has the right permissions to create the file. If all these checks pass, the namenode makes a record of the new file; otherwise, file creation fails and the client is thrown an IOException. TheDistributedFileSystem returns an FSDataOutputStream for the client to start writing data to datanode. FSDataOutputStream wraps a DFSOutputStream which handles communication with the datanodes and namenode.\nAs the client writes data, DFSOutputStream splits it into packets, which it writes to an internal queue, called the data queue. The data queue is consumed by the DataStreamer, which is responsible for asking the namenode to allocate new blocks by picking a list of suitable datanodes to store the replicas. The list of datanodes forms a pipeline, and default replication level is three, so there are three nodes in the pipeline. The DataStreamer streams the packets to the first datanode in the pipeline, which stores the packet and forwards it to the second datanode in the pipeline.\nSimilarly, the second datanode stores the packet and forwards it to the third (and last) datanode in the pipeline.\nDFSOutputStream also maintains an internal queue of packets that are waiting to be acknowledged by datanodes, called the ack queue. A packet is removed from the ack queue only when it has been acknowledged by all the datanodes in the pipeline.\nWhen the client has finished writing data, it calls close() on the stream.It flushes all the remaining packets to the datanode pipeline and waits for acknowledgments before contacting the namenode to signal that the file is complete The namenode already knows which blocks the file is made up of , so it only has to wait for blocks to be minimally replicated before returning successfully.\nThe Process of reading data in HDFS 2.0 is like this, \nThe client opens the file by calling open() method on DistributedFileSystem.\nDistributedFileSystem makes an RPC call to the namenode to determine location of datanodes where files is stored in form of blocks.For each blocks,the namenode returns address of datanodes(metadata of blocks and datanodes) that have a copy of block. Datanodes are sorted according to proximity(depending of network topology information).\nThe DistributedFileSystem returns an FSDataInputStream (an input stream that supports file seeks) to the client for it to read data from. FSDataInputStream in turn wraps a DFSInputStream, which manages the datanode and namenode I/O.\nThe client then calls read() on the stream. DFSInputStream, which has stored the datanode addresses for the first few blocks in the file, then connects to the first (closest) datanode for the first block in the file. \nData is streamed from the datanode back to the client (in the form of packets) and read () is repeatedly called on the stream by client.\nWhen the end of the block is reached, DFSInputStream will close the connection to the datanode, then find the best datanode for the next block (Step 5)\nWhen the client has finished reading, it calls close() on the FSDataInputStream (step 6).\nIn addition, During reading, if the DFSInputStream encounters an error while communicating with a datanode, it will try the next closest one for that block.It will also remember datanodes that have failed so that it doesn’t needlessly retry them for later blocks. \nThe DFSInputStream also verifies checksums for the data transferred to it from the datanode. If a corrupted block is found, the DFSInputStream attempts to read a replica of the block from another datanode; it also reports the corrupted block to the namenode. \nIn this session we learned the big data distributed file system mechanism using HDFS as an example, which is physical store of big data .\nWe learned the architecture of HDFS, name node, data node, and their responsibilities, \nWe also learned the data writing and data reading process of HDFS.\nthank you for your attention, if you have any question, feel free to contact me.", "document_id": "doc_f69829f8"}
