{"extractions": [{"extraction_class": "TOPIC", "extraction_text": "Massively Parallel Processing (MPP) Model for Structured Data", "char_interval": {"start_pos": 184, "end_pos": 202}, "alignment_status": "match_lesser", "extraction_index": 1, "group_index": 0, "description": null, "attributes": null}, {"extraction_class": "SUMMARY", "extraction_text": "Massively Parallel Processing (MPP) is a computing model for structured data that utilizes a 'shared-nothing' architecture to process large-scale queries. In an MPP system, data is partitioned across multiple servers, known as nodes or segment hosts, each with its own processor, memory, and storage. This allows for the coordinated, parallel processing of a single task. The architecture consists of a Master Node that receives client queries, creates an execution plan using its metadata, and coordinates the segment hosts. The segment hosts then execute the query in parallel on their local data partitions and return the results to the master. To ensure high availability, MPP databases typically use a mirror scheme for fault tolerance, where each primary data segment has a replicated mirror on another node, and the master node has a standby. If a node fails, its mirror is activated. However, this scheme does not support intra-query fault tolerance, meaning a running query must be restarted from the beginning upon failure. Data distribution across segments is a key feature, often configured using a `DISTRIBUTED BY` clause with hash or round-robin methods.", "char_interval": {"start_pos": 906, "end_pos": 941}, "alignment_status": "match_lesser", "extraction_index": 2, "group_index": 0, "description": null, "attributes": null}, {"extraction_class": "KEYWORDS", "extraction_text": "Massively Parallel Processing (MPP), shared-nothing architecture, master node, segment host, data partitioning, parallel execution, fault tolerance, mirror segment, interconnect", "char_interval": null, "alignment_status": null, "extraction_index": 3, "group_index": 0, "description": null, "attributes": null}, {"extraction_class": "CONCEPT", "extraction_text": "Massively Parallel Processing (MPP)", "char_interval": {"start_pos": 5405, "end_pos": 5440}, "alignment_status": "match_exact", "extraction_index": 4, "group_index": 0, "description": null, "attributes": {"definition": "The coordinated processing of a single task by multiple processors, where each processor uses its own OS and memory and communicates with others using a messaging interface. In MPP databases, data is partitioned across multiple servers or nodes, with each node having its own memory and processors to process data locally."}}, {"extraction_class": "CONCEPT", "extraction_text": "Shared-Nothing Architecture", "char_interval": {"start_pos": 5707, "end_pos": 5721}, "alignment_status": "match_lesser", "extraction_index": 5, "group_index": 1, "description": null, "attributes": {"definition": "An architecture where data is partitioned across multiple servers or nodes, and each server processes queries locally using its own memory and processors. All communication is via a network interconnect, and there is no disk-level sharing or contention."}}, {"extraction_class": "CONCEPT", "extraction_text": "Master Node", "char_interval": {"start_pos": 5738, "end_pos": 5744}, "alignment_status": "match_lesser", "extraction_index": 6, "group_index": 2, "description": null, "attributes": {"definition": "A component in an MPP architecture that interacts with clients, manages the cluster, and coordinates query processing. It contains metadata and session information to generate an execution plan for retrieving information from the underlying nodes."}}, {"extraction_class": "CONCEPT", "extraction_text": "Segment Host", "char_interval": {"start_pos": 3323, "end_pos": 3335}, "alignment_status": "match_fuzzy", "extraction_index": 7, "group_index": 3, "description": null, "attributes": {"definition": "Individual physical servers in an MPP system with their own OS, CPU, storage, and memory. They host segment databases, where each database stores a portion of the user data."}}, {"extraction_class": "CONCEPT", "extraction_text": "Segment", "char_interval": {"start_pos": 5958, "end_pos": 5965}, "alignment_status": "match_exact", "extraction_index": 8, "group_index": 4, "description": null, "attributes": {"definition": "Database instances hosted on slave nodes (segment hosts) that are responsible for storing a partition of the data and performing query processing on that partition."}}, {"extraction_class": "CONCEPT", "extraction_text": "Mirror Scheme", "char_interval": {"start_pos": 4262, "end_pos": 4275}, "alignment_status": "match_fuzzy", "extraction_index": 9, "group_index": 5, "description": null, "attributes": {"definition": "A fault tolerance method, commonly using replication, where each primary segment is allocated a mirror segment on another node. If a node with a primary segment fails, the corresponding mirror is activated to ensure data durability and availability."}}, {"extraction_class": "CONCEPT", "extraction_text": "Interconnect", "char_interval": {"start_pos": 6111, "end_pos": 6123}, "alignment_status": "match_exact", "extraction_index": 10, "group_index": 6, "description": null, "attributes": {"definition": "A high-speed network switch through which segment server databases communicate, enabling continuous pipelining of data processing."}}], "text": "Hello everyone, I am Haiying Che, from Institute of Data Science and knowledge Engineering\nSchool of Computer Science, in Beijing Institute of Technology, \nin this session, we discuss Massively Parallel Processing model for Structured Data.\nThe data processing system provides big data computing and processing capabilities and an application development platform.\nFrom the perspective of computing architecture, the data processing system is divided into data algorithm layer, computing model layer, computing platform layer, computing engine layer, etc.\nComputing models are the way that different kinds of big data is processed in different scenarios, \nwhich include batch processing, stream computing, Large-scale concurrent processing (MPP) model for structured data, In-memory Computing model, and Data Flow Graph models.\nNow let’s look at the third computing model Massively Parallel Processing.\nIn Massively Parallel Processing (MPP) databases data is partitioned across multiple servers or nodes with each server/node having memory/processors to process data locally. \nAll communication is via a network interconnect — there is no disk-level sharing or contention to be concerned with (i.e. it is a ‘shared-nothing’ architecture).\nThe massively parallel processing (MPP) architecture structures big data to enable easy querying for reporting and analytic purposes. \nMPP systems are sometimes referred to as shared nothing systems.\nThis means that data is partitioned across many servers (otherwise known as nodes) and each server processes queries locally.\nIn the diagram , 4 nodes are using to replace one single server and reduce the query time from one hour to 15 minutes.\nThe process begins by the Client issuing a query that is then passed to the Master Node.\nThe Master Node contains information, such as the data dictionary and session information, \nwhich it uses to generate an execution plan designed to retrieve the needed information from each underlying Node.\nParallel Execution represents the implementation of the execution plan through the parallel computing of Node 1 to Node n.\nAnd the query results return to master node\nMassively Parallel Processing is the coordinated processing of a single task by multiple processor,\nEach processor using its own OS and memory and communicating with each other using some form of messaging interface\nMPP can be setup with a shared nothing or shared disk architecture\nIn the shared nothing architecture, there is no single point of contention across the system and nodes do not share memory or disk storage.\ndata is horizontally partitioned across nodes such that each node has a sub set of rows from each table in the DB\nEach node then processes only rows on its own disks.\nThe “shared nothing” systems with distributed databases need a lot of coordination to complete a common task. \nEach node owns slices of the database.\nManaging this database could be very difficult. Shared nothing systems with the replicated database are not suitable for applications with tremendous data requirements. \nIf the computation needs a lot of data modification operations like data insertion and join, then the “shared nothing” architecture may not be viable.\nPerformance through segment instance parallelism\nMaster host and standby master Host\nMaster coordinates work with segment host\nSegment host with one or more segment instances\nSegment instances process queries in parallel\nSegment hosts have their own CPU disk memory(shared nothing)\nHigh speed interconnect for continuous pipelining of data processing\nArchitecture of MPP databases. There are a master and 4 slaves, with 2 segments on each slave and a mirror for each segment on another machine.\nMPP Database Architecture\nTypical MPP databases usually adopt a shared-nothing architecture , composed of one master node and n slave nodes. \nThe master node is responsible for interacting with clients, managing the whole cluster and coordinating the query processing. \nEach of the n salve nodes is responsible for storing a partition of the data and performing query processing on its partition. \nEach slave node hosts d database instances, which will be referred to as segments subsequently. \nMost MPP databases provide fault tolerance at storage level. A mirror scheme, i.e., replication, is commonly used to ensure durability and availability of data. \nAs Fig shows, each segment (primary segment) is allocated with a mirror (mirror segment) in another node. \nThe master node detects node failures by monitoring heartbeats of slave nodes. If a slave node stops responding for a certain amount of time, known as a system delay time (normally around 1 min), \nthe master will treat it as a failed node. Once a failure is detected, the corresponding mirror will be activated to replace the failed primary segment. \nSimilarly, a standby works as the replication/mirror of the master node. \nThrough the mirror scheme, the system’s availability can be significantly enhanced.\nHowever, such a mirror scheme does not support intra-query fault tolerance automatically. \nWhen a node failure occurs, the running query’s state on the failed node will be lost.\nAfter the corresponding mirror is activated, the whole query has to be rerun.\nIf it is a long running query, response to the client will be severely delayed. In the worst case, a query will run indefinitely, if the probability of failure is high.\nin Massively Parallel Processing (MPP) databases data is partitioned across multiple servers or nodes with each server/node having memory/processors to process data locally. All communication is via a network interconnect — there is no disk-level sharing or\ncontention to be concerned with (i.e. it is a ‘shared-nothing’ architecture).\nMaster Host – Separate physical server with its own OS/CPU/storage/memory. \nHosts master database. There is no user data in master database but stores metadata about segments – think in terms of system tables.\n、 2, 3, 4 Segment hosts – Individual physical servers with their own OS/CPU/storage/memory. \n、Hosts segment database. Each database stores portion of user data.\n、 Interconnect switch – Segment server databases communicate through an interconnect switch\nthe main characteristic of MPP database is data distribution. \nData is distributed across each segment database to achieve data and processing parallelism. \nThis is achieved by creating a database table with DISTRIBUTED BY clause. \nBy using this clause data is automatically distributed across segment databases. \nIn Greenplum you can either use hash or round-robin distribution.\nIn this session we learned Large-scale concurrent processing (MPP Massively Parallel Processing) model for structured data. Thank you for your attention, if you have any question, feel free to contact me.", "document_id": "doc_817c40f1"}
