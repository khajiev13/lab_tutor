{"extractions": [{"extraction_class": "TOPIC", "extraction_text": "Data Cleaning Technologies", "char_interval": {"start_pos": 52, "end_pos": 56}, "alignment_status": "match_lesser", "extraction_index": 1, "group_index": 0, "description": null, "attributes": null}, {"extraction_class": "SUMMARY", "extraction_text": "This session discusses Data Cleaning Technology, which addresses three primary issues: duplicate records, missing values, and noisy data. Duplicate records, caused by data integration or repeated input, are identified by comparing record similarity against a threshold and then removed. Missing values, resulting from equipment errors or input omissions, can be handled by ignoring the record, using a default value, or imputing a value using averages or predictive models. Noisy data can be eliminated using three main algorithms. The Binning algorithm groups data into 'boxes' (sub-intervals) of either equal depth (same number of records) or equal width (same interval range), and then smooths the data within each box using the average, boundary, or median value. The Clustering algorithm groups similar data objects, identifying outliers that fall outside these clusters as noise. The Regression algorithm fits data to a function, such as linear regression, to find patterns and smooth the data accordingly.", "char_interval": {"start_pos": 158, "end_pos": 170}, "alignment_status": "match_lesser", "extraction_index": 2, "group_index": 1, "description": null, "attributes": null}, {"extraction_class": "KEYWORDS", "extraction_text": "Data Cleaning, Duplicate Records, Missing Values, Noise Data, Binning Algorithm, Clustering Algorithm, Regression Algorithm, Equal Depth Binning, Equal-Width Binning, Data Smoothing", "char_interval": {"start_pos": 648, "end_pos": 3558}, "alignment_status": "match_fuzzy", "extraction_index": 3, "group_index": 2, "description": null, "attributes": null}, {"extraction_class": "CONCEPT", "extraction_text": "Data Cleaning Technology", "char_interval": {"start_pos": 188, "end_pos": 212}, "alignment_status": "match_fuzzy", "extraction_index": 4, "group_index": 3, "description": null, "attributes": {"definition": "A technology that helps to solve three kinds of problems in datasets: cleaning duplicate records, handling missing values, and eliminating noise data."}}, {"extraction_class": "CONCEPT", "extraction_text": "Binning", "char_interval": {"start_pos": 1713, "end_pos": 1720}, "alignment_status": "match_fuzzy", "extraction_index": 5, "group_index": 4, "description": null, "attributes": {"definition": "A method to eliminate noise data by putting the data to be processed into some boxes according to certain rules, examining the data in each box, and using a certain method to process the data in each box separately."}}, {"extraction_class": "CONCEPT", "extraction_text": "Box (in Binning)", "char_interval": {"start_pos": 2678, "end_pos": 3277}, "alignment_status": "match_fuzzy", "extraction_index": 6, "group_index": 5, "description": null, "attributes": {"definition": "A sub-interval divided by attribute value. If an attribute value is within a certain sub-interval range, it is said to be put in the 'box' represented by this sub-interval."}}, {"extraction_class": "CONCEPT", "extraction_text": "Equal depth binning", "char_interval": {"start_pos": 2593, "end_pos": 2612}, "alignment_status": "match_fuzzy", "extraction_index": 7, "group_index": 6, "description": null, "attributes": {"definition": "A binning method where bins are divided according to the number of rows of records, so each bin has the same number of records."}}, {"extraction_class": "CONCEPT", "extraction_text": "Equal-width binning", "char_interval": {"start_pos": 2613, "end_pos": 2632}, "alignment_status": "match_fuzzy", "extraction_index": 8, "group_index": 7, "description": null, "attributes": {"definition": "A binning method where the interval range of each box is a constant, called the box width."}}, {"extraction_class": "CONCEPT", "extraction_text": "Data Smoothing (in Binning)", "char_interval": {"start_pos": 2149, "end_pos": 3277}, "alignment_status": "match_fuzzy", "extraction_index": 9, "group_index": 8, "description": null, "attributes": {"definition": "The process of choosing a value to represent a bin after binning. Methods include smoothing by average, by boundary value, or by median."}}, {"extraction_class": "CONCEPT", "extraction_text": "Clustering Algorithm (for noise elimination)", "char_interval": null, "alignment_status": null, "extraction_index": 10, "group_index": 9, "description": null, "attributes": {"definition": "A method of grouping a collection of data objects into different clusters to find and clear values (outliers) that fall outside the clusters, which are regarded as noise."}}, {"extraction_class": "CONCEPT", "extraction_text": "Regression Algorithm (for noise elimination)", "char_interval": null, "alignment_status": null, "extraction_index": 11, "group_index": 10, "description": null, "attributes": {"definition": "A method that finds the pattern of change between two related variables and smooths the data by fitting it to a function."}}, {"extraction_class": "CONCEPT", "extraction_text": "Linear Regression", "char_interval": {"start_pos": 4939, "end_pos": 4956}, "alignment_status": "match_exact", "extraction_index": 12, "group_index": 11, "description": null, "attributes": {"definition": "A regression method that uses a straight line (e.g., Y=aX+b) to model the relationship between two variables."}}], "text": "Hello everyone, I am Haiying Che, from Institute of Data Science and knowledge Engineering\nSchool of Computer Science, in Beijing Institute of Technology, in this session, we will discuss Data Cleaning Technology.\nData Cleaning Technology can help to solve three kinds of problems, repeat record cleaning, Missing value cleaning and Eliminating noise data.\nFirst let’s look at the Repeat record cleaning\nDuplicate records will lead to erroneous analysis results, so it is necessary to remove duplicate records in the data set to improve the accuracy and speed of the analysis.\nwhat are the Causes of duplicate values\n1 Integrate data from multiple data sources will result the duplicate values\n2 When inputting, some data is input repeatedly\nDuplicate values are combined after inference\n1 Delete completely duplicate records\n2 When merging different tables, some redundant attributes (such as time) is added\nIt is necessary to compare the related attributes of two records. According to the similarity of each attribute and the weight of the attribute, the similarity of the record is obtained. \nIf the similarity exceeds a certain threshold, it is considered as a duplicate record.\nNow let’s look at the Missing value cleaning.\nCauses of missing values could be\nEquipment abnormal, or When entering, some data is not taken seriously and not entered.\nMissing values must be inferred and added. We can Ignore this record; Use default; Use attribute average; \nUse the average of similar samples and Predict the most likely value\nThe third Data Cleaning Technology is Eliminating noise data\nData noise can be Eliminated by \nBinning/split bin algorithm\nClustering Algorithm\nRegression algorithm.\nFirst let’s look at Binning algorithm\nBinning: \nPut the data to be processed into some boxes according to certain rules, examine the data in each box, and use a certain method to process the data in each box separately.\nBox: \nA sub-interval divided by attribute value. If an attribute value is within a certain sub-interval range, it is said to put the attribute value in the \"box\" represented by this sub-interval.\nThe main issues:\nHow to divide the box;\nData smoothing method, that is, how to smooth the data in each box, which means use what methods to decide the value to present each box.\nIn the example here, there are 4 different bins, grey, yellow green and purple, each age value is put to certain range, like age 10 is put into range from 10 to 16, the grey box. And so, on\nThe ways of how to Sort the record set according to the size of the target attribute value before binning, include \nEqual depth binning\nEqual-width binning\nUser-defined interval\nEqual depth bin method (unified weight): \nBins are divided according to the number of rows of records, \neach bin has the same number of records, and the number of records in each bin is called the weight of the bin, also known as the depth of the bin.\nIn this example, we have 16 records, and we decide the box depth is 4 , after binning, we have 4 boxes results and each box contain 4 records\nEqual-width binning method, evenly distributed over the entire attribute value interval, that is, the interval range of each box is a constant, called the box width. \nIn the example, Set the interval range (the width of the box) to RMB 1,000, then the result is also 4 boxes, but the records in the boxes are different from the Equal depth bin method.\nAfter binning, we should choose a value to represent the boxes, which is called smooth. there are mainly 3 ways to smooth:\nSmooth by average：Average the data in the same box value and replace all the data in the box with the average value.\nSmooth according to the boundary value：Replace each data in the box with a boundary value with a smaller distance.\nSmooth according to the median：Take the median value of the box and use it to replace all the data in the box.\nSecond way of Eliminating Data noise is Clustering Algorithm. Now let’s look at Clustering Algorithm\nCluster: \nA collection of data objects. All objects in the same cluster are similar, and objects in different clusters are quite different.\nClustering: \nGrouping a collection of physical or abstract objects into different clusters, finding and clearing those values (outliers) that fall outside the clusters. These isolated points are regarded as noise.\nUnusual data is discovered through cluster analysis: \nsimilar or adjacent data are aggregated to form clusters, and those data objects outside these clusters are naturally considered as abnormal data.\nFeatures: Directly form clusters and describe the clusters without any prior knowledge.\nThe third way of Eliminating Data noise is Regression Algorithm. Now let’s look at Regression algorithm\nRegression: \nFind the pattern of change between two related variables, which are x and y in the diagram, and smooth the data by fitting the data to a function, that is, using the fitting function to smooth the data.\nmethod:\nLinear regression (simple regression): Use straight line modeling to treat one variable as a linear function of another variable. \nFor example: Y=aX+b, where a and b are called regression coefficients, and the coefficients a and b can be obtained by the least square method.\nIn this session we general introduced Data Preprocessing.\nthank you for your attention, if you have any question, feel free to contact me.", "document_id": "doc_e7fe7471"}
