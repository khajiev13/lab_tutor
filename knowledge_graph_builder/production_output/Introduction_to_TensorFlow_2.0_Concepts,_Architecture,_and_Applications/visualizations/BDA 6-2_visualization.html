<style>
.lx-highlight { position: relative; border-radius:3px; padding:1px 2px;}
.lx-highlight .lx-tooltip {
  visibility: hidden;
  opacity: 0;
  transition: opacity 0.2s ease-in-out;
  background: #333;
  color: #fff;
  text-align: left;
  border-radius: 4px;
  padding: 6px 8px;
  position: absolute;
  z-index: 1000;
  bottom: 125%;
  left: 50%;
  transform: translateX(-50%);
  font-size: 12px;
  max-width: 240px;
  white-space: normal;
  box-shadow: 0 2px 6px rgba(0,0,0,0.3);
}
.lx-highlight:hover .lx-tooltip { visibility: visible; opacity:1; }
.lx-animated-wrapper { max-width: 100%; font-family: Arial, sans-serif; }
.lx-controls {
  background: #fafafa; border: 1px solid #90caf9; border-radius: 8px;
  padding: 12px; margin-bottom: 16px;
}
.lx-button-row {
  display: flex; justify-content: center; gap: 8px; margin-bottom: 12px;
}
.lx-control-btn {
  background: #4285f4; color: white; border: none; border-radius: 4px;
  padding: 8px 16px; cursor: pointer; font-size: 13px; font-weight: 500;
  transition: background-color 0.2s;
}
.lx-control-btn:hover { background: #3367d6; }
.lx-progress-container {
  margin-bottom: 8px;
}
.lx-progress-slider {
  width: 100%; margin: 0; appearance: none; height: 6px;
  background: #ddd; border-radius: 3px; outline: none;
}
.lx-progress-slider::-webkit-slider-thumb {
  appearance: none; width: 18px; height: 18px; background: #4285f4;
  border-radius: 50%; cursor: pointer;
}
.lx-progress-slider::-moz-range-thumb {
  width: 18px; height: 18px; background: #4285f4; border-radius: 50%;
  cursor: pointer; border: none;
}
.lx-status-text {
  text-align: center; font-size: 12px; color: #666; margin-top: 4px;
}
.lx-text-window {
  font-family: monospace; white-space: pre-wrap; border: 1px solid #90caf9;
  padding: 12px; max-height: 260px; overflow-y: auto; margin-bottom: 12px;
  line-height: 1.6;
}
.lx-attributes-panel {
  background: #fafafa; border: 1px solid #90caf9; border-radius: 6px;
  padding: 8px 10px; margin-top: 8px; font-size: 13px;
}
.lx-current-highlight {
  border-bottom: 4px solid #ff4444;
  font-weight: bold;
  animation: lx-pulse 1s ease-in-out;
}
@keyframes lx-pulse {
  0% { text-decoration-color: #ff4444; }
  50% { text-decoration-color: #ff0000; }
  100% { text-decoration-color: #ff4444; }
}
.lx-legend {
  font-size: 12px; margin-bottom: 8px;
  padding-bottom: 8px; border-bottom: 1px solid #e0e0e0;
}
.lx-label {
  display: inline-block;
  padding: 2px 4px;
  border-radius: 3px;
  margin-right: 4px;
  color: #000;
}
.lx-attr-key {
  font-weight: 600;
  color: #1565c0;
  letter-spacing: 0.3px;
}
.lx-attr-value {
  font-weight: 400;
  opacity: 0.85;
  letter-spacing: 0.2px;
}

/* Add optimizations with larger fonts and better readability for GIFs */
.lx-gif-optimized .lx-text-window { font-size: 16px; line-height: 1.8; }
.lx-gif-optimized .lx-attributes-panel { font-size: 15px; }
.lx-gif-optimized .lx-current-highlight { text-decoration-thickness: 4px; }
</style>
    <div class="lx-animated-wrapper lx-gif-optimized">
      <div class="lx-attributes-panel">
        <div class="lx-legend">Highlights Legend: <span class="lx-label" style="background-color:#D2E3FC;">CONCEPT</span> <span class="lx-label" style="background-color:#C8E6C9;">KEYWORDS</span> <span class="lx-label" style="background-color:#FEF0C3;">TOPIC</span></div>
        <div id="attributesContainer"></div>
      </div>
      <div class="lx-text-window" id="textWindow">
        Hello everyone, I am Haiying Che, from Institute of Data Science and knowledge Engineering
School of Computer Science, in Beijing Institute of Technology, in this session we will talk about the powerful Ml tool <span class="lx-highlight lx-current-highlight" data-idx="0" style="background-color:#D2E3FC;">TensorFlow</span>.
In this chapter, we introduce some useful platform， Spark  MLlib and  TensorFlow.
In this session we will discuss about the concepts and mechanism of TensorFlow. 
TensorFlow is Created by the Google Brain team, it is an open source library for numerical computation and large-scale machine learning. 
TensorFlow bundles together a lot of machine learning and deep learning <span class="lx-highlight" data-idx="1" style="background-color:#D2E3FC;">(aka neural networking) models and algorithms and makes them useful by way of a common metaphor. 
TensorFlow has grown to become one of the most loved and widely adopted ML platforms in the world
A <span class="lx-highlight" data-idx="2" style="background-color:#D2E3FC;">tensor</span> is the core data unit of TensorFlow, which is essentially an array of arbitrary dimensions. 
Available tensor types include constants, variables, tensor placeholders, and sparse tensors.
How TensorFlow works
TensorFlow allows developers to create <span class="lx-highlight" data-idx="3" style="background-color:#D2E3FC;">dataflow graphs</span>—structures that describe how data moves through a graph, or a series of processing nodes. 
Each node in the graph represents a mathematical operation, and each connection or edge between nodes is a multidimensional data array, or tensor.
TensorFlow provides all of this for the programmer by way of the Python language. 
Python is easy to learn and work with, and provides convenient ways to express how high-level abstractions can be coupled together. 
Nodes and tensors in TensorFlow are Python objects, and TensorFlow applications are themselves Python applications.
It uses Python to provide a convenient front-end API for building applications with the framework, while executing those applications in high-performance C++.
The actual math operations, however, are not performed in Python.
The libraries of transformations that are available through TensorFlow are written as high-performance C++ binaries. 
Python just directs traffic between the pieces, and provides high-level programming abstractions to hook them together.
TensorFlow applications can be run on most any target that’s convenient: a local machine, a cluster in the cloud, iOS and Android devices, CPUs or GPUs. 
If you use Google’s own cloud, you can run TensorFlow on Google’s custom TensorFlow Processing Unit (TPU)</span> silicon for further acceleration. 
The resulting models created by TensorFlow, though, can be deployed on most any device where they will be used to serve predictions.
TensorFlow has grown to become one of the most loved and widely adopted ML platforms in the world
Let ‘s watch a video to understand more about TensorFlow
Now let’s look at the structure of TensorFlow 2.0.
TensorFlow 2.0 focus on simplicity and ease of use, featuring updates like:
Easy model building with <span class="lx-highlight" data-idx="4" style="background-color:#D2E3FC;">Keras</span> and <span class="lx-highlight" data-idx="5" style="background-color:#D2E3FC;">eager execution</span>.
Robust model deployment in production on any platform.
Powerful experimentation for research.
the APIs has been packaged together into a comprehensive platform that supports machine learning workflows from training through deployment. 
Keras, a user-friendly API standard for machine learning, will be the central high-level API used to build and train models. 
The Keras API makes it easy <span class="lx-highlight" data-idx="6" style="background-color:#FEF0C3;">to get started with <span class="lx-highlight" data-idx="7" style="background-color:#C8E6C9;">TensorFlow. 
Importantly, Keras provides several model-building APIs (Sequential, Functional, and Subclassing), so you can choose the right level of abstraction for your project.
TensorFlow2.0’s implementation contains enhancements including 
） eager execution, for immediate iteration 
） Intuitive debugging, 
） Tf.data, for building scalable input pipelines.
Let’s take a look at the new architecture of TensorFlow 2.0 using a simplified, conceptual diagram as shown  
Easy model building-Here’s an example workflow:
Load your data using tf.data. 
Training data is read using input pipelines which are created using tf.data. 
Feature characteristics, for example bucketing and feature crosses are described using tf.feature_column. 
Convenient input from in-memory data (for example, NumPy) is also supported.
Build, train and validate your model with tf.keras, or use Premade Estimators. 
Keras integrates tightly with the rest of TensorFlow so you can access TensorFlow’s features whenever you want. 
A set of standard packaged models (for example, linear or logistic regression, gradient boosted trees, random forests) are also available to use directly (implemented using the tf.estimator API).
If you’re not looking to train a model from scratch, you’ll soon be able to use transfer learning to train a Keras or Estimator model using modules from TensorFlow Hub.
Run and debug with eager execution, then use <span class="lx-highlight" data-idx="8" style="background-color:#D2E3FC;">tf.function</span> for the benefits of graphs. 
TensorFlow 2.0 runs with eager execution by default for ease of use and smooth debugging. 
Additionally, the tf.function annotation transparently translates your Python programs into TensorFlow graphs.
This process retains all the advantages of 1.x TensorFlow graph-based execution: Performance optimizations, 
remote execution and the ability to serialize, export and deploy easily, while adding the flexibility and ease of use of expressing programs in simple Python.
Use Distribution Strategies for distributed training. 
For large ML training tasks, the <span class="lx-highlight" data-idx="9" style="background-color:#D2E3FC;">Distribution Strategy API</span> makes it easy to distribute and train models on different hardware configurations without changing the model definition. 
Since TensorFlow provides support for a range of hardware accelerators like CPUs, GPUs, and TPUs, （Tensor Processing Unit）
you can enable training workloads to be distributed to single-node/multi-accelerator as well as multi-node/multi-accelerator configurations, including TPU Pods. 
Although this API supports a variety of cluster configurations, templates to deploy training on Kubernetes clusters in on-prem or cloud environments are provided.
Export to <span class="lx-highlight" data-idx="10" style="background-color:#D2E3FC;">SavedModel</span>. 
TensorFlow will standardize on SavedModel as an interchange format for <span class="lx-highlight" data-idx="11" style="background-color:#D2E3FC;">TensorFlow Serving</span>, <span class="lx-highlight" data-idx="12" style="background-color:#D2E3FC;">TensorFlow Lite</span></span>, <span class="lx-highlight" data-idx="13" style="background-color:#D2E3FC;">TensorFlow.js</span>, TensorFlow Hub, and more.
Robust model deployment in production on any platform
TensorFlow has always provided a direct path to production. Whether it’s on servers, edge devices, or the web, 
TensorFlow lets you train and deploy your model easily, no matter what language or platform you use.
In TensorFlow 2.0, compatibility and parity across platforms and components are improved by standardizing exchange formats and aligning APIs.
Once you’ve trained and saved your model, you can execute it directly in your application</span> or serve it using one of the deployment libraries:
TensorFlow Serving: A TensorFlow library allowing models to be served over HTTP/REST or gRPC/Protocol Buffers.
TensorFlow Lite: TensorFlow’s lightweight solution for mobile and embedded devices provides the capability to deploy models on Android, iOS and embedded systems like a Raspberry Pi and Edge TPUs.
TensorFlow.js: Enables deploying models in JavaScript environments, such as in a web browser or server side through Node.js. TensorFlow.js also supports defining models in JavaScript and training directly in the web browser using a Keras-like API.
TensorFlow also has support for additional languages (some maintained by the broader community), including C, Java, Go, C#, Rust, Julia, R, and others.
This picture shows typical platforms for the general-purpose computation, machine learning and Deep Learning, and Tensorflow can be used both for ML and DL.
TensorFlow is Powerful experimentation for research
TensorFlow makes it easy to take new ideas from concept to code, and from model to publication. 
TensorFlow 2.0 incorporates a number of features that enables the definition and training of state-of-the-art models without sacrificing speed or performance:
Keras Functional API and Model Subclassing API: Allows for creation of complex topologies including using residual layers, custom multi-input/-output models, and imperatively written forward passes.
Custom Training Logic: Fine-grained control on gradient computations with tf.GradientTape and tf.custom_gradient.
And for even more flexibility and control, the low-level TensorFlow API is always available and working in conjunction with the higher-level abstractions for fully customizable logic.
TensorFlow 2.0 brings several new additions that allow researchers and advanced users to experiment, using rich extensions 
like Ragged Tensors, TensorFlow Probability, Tensor2Tensor, and more to be announced.
Along with these capabilities, TensorFlow provides eager execution for easy prototyping &amp; debugging, Distribution Strategy API and AutoGraph to train at scale, and support for TPUs, making TensorFlow 2.0 an easy to use, customizable, and highly scalable platform for conducting state of the art ML research and translating that research into production pipelines.
To manage using TensorFlow, a serious experiments were designed, 
which included Boston Housing Prediction using linear regression, Objection Detection and Variational AutoEncoder.
The steps of each experiment showed in the diagram.
Boston Housing Prediction included preparation, import data, Data visualization, build Model, Train the Model  and result visualization.
Objection Detection included build the environment of TensorFlow on PC, build computation graph by using TensorFlow and Using computational graph to compute computation.
Variational AutoEncoder include two stages Network construction and Solving gradient disappearing problem using VAE, which consist of Learn the concept of layers, build a model that encapsulates layers by using the function sequential, set the loss function, calculate the gradient of the loss function to perform Back Propagation to adjust the parameters and add some noise into the validation set to solve the gradient disappearing problem. 
all the experiments material including the manual and codes are provided on the MOOC platform, which can help you to do the hands-on.
In this session, we learned concepts and mechanism of TensorFlow
thank you for your attention, if you have any question, feel free to contact me.
      </div>
      <div class="lx-controls">
        <div class="lx-button-row">
          <button class="lx-control-btn" onclick="playPause()">▶️ Play</button>
          <button class="lx-control-btn" onclick="prevExtraction()">⏮ Previous</button>
          <button class="lx-control-btn" onclick="nextExtraction()">⏭ Next</button>
        </div>
        <div class="lx-progress-container">
          <input type="range" id="progressSlider" class="lx-progress-slider"
                 min="0" max="13" value="0"
                 onchange="jumpToExtraction(this.value)">
        </div>
        <div class="lx-status-text">
          Entity <span id="entityInfo">1/14</span> |
          Pos <span id="posInfo">[3249-6549]</span>
        </div>
      </div>
    </div>

    <script>
      (function() {
        const extractions = [{"index": 0, "class": "CONCEPT", "text": "TensorFlow", "color": "#D2E3FC", "startPos": 211, "endPos": 221, "beforeText": "nce and knowledge Engineering\nSchool of Computer Science, in Beijing Institute of Technology, in this session we will talk about the powerful Ml tool ", "extractionText": "TensorFlow", "afterText": ".\nIn this chapter, we introduce some useful platform\uff0c Spark  MLlib and  TensorFlow.\nIn this session we will discuss about the concepts and mechanism o", "attributesHtml": "<div><strong>class:</strong> CONCEPT</div><div><strong>attributes:</strong> {<span class=\"lx-attr-key\">definition</span>: <span class=\"lx-attr-value\">An open-source library created by the Google Brain team for numerical computation and large-scale machine learning, which bundles together many machine learning and deep learning models and algorithms.</span>}</div>"}, {"index": 1, "class": "CONCEPT", "text": "TPU (TensorFlow Processing Unit)", "color": "#D2E3FC", "startPos": 596, "endPos": 2356, "beforeText": "n source library for numerical computation and large-scale machine learning. \nTensorFlow bundles together a lot of machine learning and deep learning ", "extractionText": "(aka neural networking) models and algorithms and makes them useful by way of a common metaphor. \nTensorFlow has grown to become one of\u00a0the most loved\u00a0and\u00a0widely adopted\u00a0ML platforms in the world\nA tensor is the core data unit of TensorFlow, which is essentially an array of arbitrary dimensions. \nAvailable tensor types include constants, variables, tensor placeholders, and sparse tensors.\nHow TensorFlow works\nTensorFlow allows developers to create\u00a0dataflow graphs\u2014structures that describe how data moves through a\u00a0graph, or a series of processing nodes. \nEach node in the graph represents a mathematical operation, and each connection or edge between nodes is a multidimensional data array, or\u00a0tensor.\nTensorFlow provides all of this for the programmer by way of the Python language. \nPython is easy to learn and work with, and provides convenient ways to express how high-level abstractions can be coupled together. \nNodes and tensors in TensorFlow are Python objects, and TensorFlow applications are themselves Python applications.\nIt uses Python to provide a convenient front-end API for building applications with the framework, while executing those applications in high-performance C++.\nThe actual math operations, however, are not performed in Python.\nThe libraries of transformations that are available through TensorFlow are written as high-performance C++ binaries. \nPython just directs traffic between the pieces, and provides high-level programming abstractions to hook them together.\nTensorFlow applications can be run on most any target that\u2019s convenient: a local machine, a cluster in the cloud, iOS and Android devices, CPUs or GPUs. \nIf you use Google\u2019s own cloud, you can run TensorFlow on Google\u2019s custom\u00a0TensorFlow Processing Unit\u00a0(TPU)", "afterText": " silicon for further acceleration. \nThe resulting models created by TensorFlow, though, can be deployed on most any device where they will be used to ", "attributesHtml": "<div><strong>class:</strong> CONCEPT</div><div><strong>attributes:</strong> {<span class=\"lx-attr-key\">definition</span>: <span class=\"lx-attr-value\">Google\u2019s custom silicon designed for accelerating TensorFlow workloads.</span>}</div>"}, {"index": 2, "class": "CONCEPT", "text": "Tensor", "color": "#D2E3FC", "startPos": 794, "endPos": 800, "beforeText": "d makes them useful by way of a common metaphor. \nTensorFlow has grown to become one of\u00a0the most loved\u00a0and\u00a0widely adopted\u00a0ML platforms in the world\nA ", "extractionText": "tensor", "afterText": " is the core data unit of TensorFlow, which is essentially an array of arbitrary dimensions. \nAvailable tensor types include constants, variables, ten", "attributesHtml": "<div><strong>class:</strong> CONCEPT</div><div><strong>attributes:</strong> {<span class=\"lx-attr-key\">definition</span>: <span class=\"lx-attr-value\">The core data unit of TensorFlow, which is essentially an array of arbitrary dimensions. Available types include constants, variables, placeholders, and sparse tensors.</span>}</div>"}, {"index": 3, "class": "CONCEPT", "text": "Dataflow Graph", "color": "#D2E3FC", "startPos": 1048, "endPos": 1063, "beforeText": "lable tensor types include constants, variables, tensor placeholders, and sparse tensors.\nHow TensorFlow works\nTensorFlow allows developers to create\u00a0", "extractionText": "dataflow graphs", "afterText": "\u2014structures that describe how data moves through a\u00a0graph, or a series of processing nodes. \nEach node in the graph represents a mathematical operation", "attributesHtml": "<div><strong>class:</strong> CONCEPT</div><div><strong>attributes:</strong> {<span class=\"lx-attr-key\">definition</span>: <span class=\"lx-attr-value\">Structures that describe how data moves through a series of processing nodes. Each node in the graph represents a mathematical operation, and each connection or edge between nodes is a multidimensional data array, or tensor.</span>}</div>"}, {"index": 4, "class": "CONCEPT", "text": "Keras", "color": "#D2E3FC", "startPos": 2832, "endPos": 2837, "beforeText": "w let\u2019s look at the structure of TensorFlow 2.0.\nTensorFlow 2.0 focus on simplicity and ease of use, featuring updates like:\nEasy model building with ", "extractionText": "Keras", "afterText": " and eager execution.\nRobust model deployment in production on any platform.\nPowerful experimentation for research.\nthe APIs has been packaged togethe", "attributesHtml": "<div><strong>class:</strong> CONCEPT</div><div><strong>attributes:</strong> {<span class=\"lx-attr-key\">definition</span>: <span class=\"lx-attr-value\">A user-friendly API standard for machine learning that serves as the central high-level API in TensorFlow 2.0 to build and train models.</span>}</div>"}, {"index": 5, "class": "CONCEPT", "text": "Eager Execution", "color": "#D2E3FC", "startPos": 2842, "endPos": 2857, "beforeText": "ok at the structure of TensorFlow 2.0.\nTensorFlow 2.0 focus on simplicity and ease of use, featuring updates like:\nEasy model building with Keras and ", "extractionText": "eager execution", "afterText": ".\nRobust model deployment in production on any platform.\nPowerful experimentation for research.\nthe APIs has been packaged together into a comprehensi", "attributesHtml": "<div><strong>class:</strong> CONCEPT</div><div><strong>attributes:</strong> {<span class=\"lx-attr-key\">definition</span>: <span class=\"lx-attr-value\">A mode in TensorFlow 2.0 that runs by default, allowing for immediate iteration and intuitive debugging by executing operations as they are called from Python.</span>}</div>"}, {"index": 6, "class": "TOPIC", "text": "Introduction to TensorFlow 2.0: Concepts, Architecture, and Applications", "color": "#FEF0C3", "startPos": 3249, "endPos": 6549, "beforeText": "s, a user-friendly API standard for machine learning, will be the central high-level API used to build and train models. \nThe Keras API makes it easy ", "extractionText": "to get started with TensorFlow. \nImportantly, Keras provides several model-building APIs (Sequential, Functional, and Subclassing), so you can choose the right level of abstraction for your project.\nTensorFlow2.0\u2019s implementation contains enhancements including \n\uff09 eager execution, for immediate iteration \n\uff09 Intuitive debugging, \n\uff09 Tf.data, for building scalable input pipelines.\nLet\u2019s take a look at the new architecture of TensorFlow 2.0 using a simplified, conceptual diagram as shown\u00a0 \nEasy model building-Here\u2019s an example workflow:\nLoad your data using\u00a0tf.data. \nTraining data is read using input pipelines which are created using\u00a0tf.data. \nFeature characteristics, for example bucketing and feature crosses are described using\u00a0tf.feature_column. \nConvenient input from in-memory data (for example, NumPy) is also supported.\nBuild, train and validate your model with\u00a0tf.keras, or use\u00a0Premade Estimators. \nKeras integrates tightly with the rest of TensorFlow so you can access TensorFlow\u2019s features whenever you want. \nA set of standard packaged models (for example, linear or logistic regression, gradient boosted trees, random forests) are also available to use directly (implemented using the\u00a0tf.estimator\u00a0API).\nIf you\u2019re not looking to train a model from scratch, you\u2019ll soon be able to use transfer learning to train a Keras or Estimator model using modules from\u00a0TensorFlow Hub.\nRun and debug with\u00a0eager execution, then use\u00a0tf.function\u00a0for the benefits of graphs.\u00a0\nTensorFlow 2.0 runs with eager execution by default for ease of use and smooth debugging. \nAdditionally, the\u00a0tf.function\u00a0annotation transparently translates your Python programs into TensorFlow graphs.\nThis process retains all the advantages of 1.x TensorFlow graph-based execution: Performance optimizations, \nremote execution and the ability to serialize, export and deploy easily, while adding the flexibility and ease of use of expressing programs in simple Python.\nUse Distribution Strategies for distributed training.\u00a0\nFor large ML training tasks, the\u00a0Distribution Strategy API\u00a0makes it easy to distribute and train models on different hardware configurations without changing the model definition. \nSince TensorFlow provides support for a range of hardware accelerators like CPUs, GPUs, and TPUs, \uff08Tensor Processing Unit\uff09\nyou can enable training workloads to be distributed to single-node/multi-accelerator as well as multi-node/multi-accelerator configurations, including\u00a0TPU Pods. \nAlthough this API supports a variety of cluster configurations,\u00a0templates\u00a0to deploy training on\u00a0Kubernetes clusters\u00a0in on-prem or cloud environments are provided.\nExport to SavedModel.\u00a0\nTensorFlow will standardize on SavedModel as an interchange format for TensorFlow Serving, TensorFlow Lite, TensorFlow.js, TensorFlow Hub, and more.\nRobust model deployment in production on any platform\nTensorFlow has always provided a direct path to production. Whether it\u2019s on servers, edge devices, or the web, \nTensorFlow lets you train and deploy your model easily, no matter what language or platform you use.\nIn TensorFlow 2.0, compatibility and parity across platforms and components are improved by standardizing exchange formats and aligning APIs.\nOnce you\u2019ve trained and saved your model, you can execute it directly in your application", "afterText": " or serve it using one of the deployment libraries:\nTensorFlow Serving: A TensorFlow library allowing models to be served over HTTP/REST or gRPC/Proto", "attributesHtml": "<div><strong>class:</strong> TOPIC</div><div><strong>attributes:</strong> {}</div>"}, {"index": 7, "class": "KEYWORDS", "text": "TensorFlow, Keras, eager execution, dataflow graph, tensor, tf.data, Distribution Strategy API, SavedModel, TensorFlow Serving, TensorFlow Lite", "color": "#C8E6C9", "startPos": 3269, "endPos": 6008, "beforeText": "PI standard for machine learning, will be the central high-level API used to build and train models. \nThe Keras API makes it easy to get started with ", "extractionText": "TensorFlow. \nImportantly, Keras provides several model-building APIs (Sequential, Functional, and Subclassing), so you can choose the right level of abstraction for your project.\nTensorFlow2.0\u2019s implementation contains enhancements including \n\uff09 eager execution, for immediate iteration \n\uff09 Intuitive debugging, \n\uff09 Tf.data, for building scalable input pipelines.\nLet\u2019s take a look at the new architecture of TensorFlow 2.0 using a simplified, conceptual diagram as shown\u00a0 \nEasy model building-Here\u2019s an example workflow:\nLoad your data using\u00a0tf.data. \nTraining data is read using input pipelines which are created using\u00a0tf.data. \nFeature characteristics, for example bucketing and feature crosses are described using\u00a0tf.feature_column. \nConvenient input from in-memory data (for example, NumPy) is also supported.\nBuild, train and validate your model with\u00a0tf.keras, or use\u00a0Premade Estimators. \nKeras integrates tightly with the rest of TensorFlow so you can access TensorFlow\u2019s features whenever you want. \nA set of standard packaged models (for example, linear or logistic regression, gradient boosted trees, random forests) are also available to use directly (implemented using the\u00a0tf.estimator\u00a0API).\nIf you\u2019re not looking to train a model from scratch, you\u2019ll soon be able to use transfer learning to train a Keras or Estimator model using modules from\u00a0TensorFlow Hub.\nRun and debug with\u00a0eager execution, then use\u00a0tf.function\u00a0for the benefits of graphs.\u00a0\nTensorFlow 2.0 runs with eager execution by default for ease of use and smooth debugging. \nAdditionally, the\u00a0tf.function\u00a0annotation transparently translates your Python programs into TensorFlow graphs.\nThis process retains all the advantages of 1.x TensorFlow graph-based execution: Performance optimizations, \nremote execution and the ability to serialize, export and deploy easily, while adding the flexibility and ease of use of expressing programs in simple Python.\nUse Distribution Strategies for distributed training.\u00a0\nFor large ML training tasks, the\u00a0Distribution Strategy API\u00a0makes it easy to distribute and train models on different hardware configurations without changing the model definition. \nSince TensorFlow provides support for a range of hardware accelerators like CPUs, GPUs, and TPUs, \uff08Tensor Processing Unit\uff09\nyou can enable training workloads to be distributed to single-node/multi-accelerator as well as multi-node/multi-accelerator configurations, including\u00a0TPU Pods. \nAlthough this API supports a variety of cluster configurations,\u00a0templates\u00a0to deploy training on\u00a0Kubernetes clusters\u00a0in on-prem or cloud environments are provided.\nExport to SavedModel.\u00a0\nTensorFlow will standardize on SavedModel as an interchange format for TensorFlow Serving, TensorFlow Lite", "afterText": ", TensorFlow.js, TensorFlow Hub, and more.\nRobust model deployment in production on any platform\nTensorFlow has always provided a direct path to produ", "attributesHtml": "<div><strong>class:</strong> KEYWORDS</div><div><strong>attributes:</strong> {}</div>"}, {"index": 8, "class": "CONCEPT", "text": "tf.function", "color": "#D2E3FC", "startPos": 4684, "endPos": 4695, "beforeText": " be able to use transfer learning to train a Keras or Estimator model using modules from\u00a0TensorFlow Hub.\nRun and debug with\u00a0eager execution, then use\u00a0", "extractionText": "tf.function", "afterText": "\u00a0for the benefits of graphs.\u00a0\nTensorFlow 2.0 runs with eager execution by default for ease of use and smooth debugging. \nAdditionally, the\u00a0tf.function", "attributesHtml": "<div><strong>class:</strong> CONCEPT</div><div><strong>attributes:</strong> {<span class=\"lx-attr-key\">definition</span>: <span class=\"lx-attr-value\">An annotation that transparently translates Python programs into TensorFlow graphs, retaining the performance, remote execution, and deployment advantages of graph-based execution.</span>}</div>"}, {"index": 9, "class": "CONCEPT", "text": "Distribution Strategy API", "color": "#D2E3FC", "startPos": 5283, "endPos": 5308, "beforeText": "lity and ease of use of expressing programs in simple Python.\nUse Distribution Strategies for distributed training.\u00a0\nFor large ML training tasks, the\u00a0", "extractionText": "Distribution Strategy API", "afterText": "\u00a0makes it easy to distribute and train models on different hardware configurations without changing the model definition. \nSince TensorFlow provides s", "attributesHtml": "<div><strong>class:</strong> CONCEPT</div><div><strong>attributes:</strong> {<span class=\"lx-attr-key\">definition</span>: <span class=\"lx-attr-value\">An API that makes it easy to distribute and train models on different hardware configurations (like CPUs, GPUs, and TPUs) without changing the model definition.</span>}</div>"}, {"index": 10, "class": "CONCEPT", "text": "SavedModel", "color": "#D2E3FC", "startPos": 5889, "endPos": 5899, "beforeText": "rts a variety of cluster configurations,\u00a0templates\u00a0to deploy training on\u00a0Kubernetes clusters\u00a0in on-prem or cloud environments are provided.\nExport to ", "extractionText": "SavedModel", "afterText": ".\u00a0\nTensorFlow will standardize on SavedModel as an interchange format for TensorFlow Serving, TensorFlow Lite, TensorFlow.js, TensorFlow Hub, and more", "attributesHtml": "<div><strong>class:</strong> CONCEPT</div><div><strong>attributes:</strong> {<span class=\"lx-attr-key\">definition</span>: <span class=\"lx-attr-value\">The standardized interchange format in TensorFlow for deploying models via TensorFlow Serving, TensorFlow Lite, TensorFlow.js, and TensorFlow Hub.</span>}</div>"}, {"index": 11, "class": "CONCEPT", "text": "TensorFlow Serving", "color": "#D2E3FC", "startPos": 5973, "endPos": 5991, "beforeText": "clusters\u00a0in on-prem or cloud environments are provided.\nExport to SavedModel.\u00a0\nTensorFlow will standardize on SavedModel as an interchange format for ", "extractionText": "TensorFlow Serving", "afterText": ", TensorFlow Lite, TensorFlow.js, TensorFlow Hub, and more.\nRobust model deployment in production on any platform\nTensorFlow has always provided a dir", "attributesHtml": "<div><strong>class:</strong> CONCEPT</div><div><strong>attributes:</strong> {<span class=\"lx-attr-key\">definition</span>: <span class=\"lx-attr-value\">A TensorFlow library that allows trained models to be served over HTTP/REST or gRPC/Protocol Buffers.</span>}</div>"}, {"index": 12, "class": "CONCEPT", "text": "TensorFlow Lite", "color": "#D2E3FC", "startPos": 5993, "endPos": 6008, "beforeText": "or cloud environments are provided.\nExport to SavedModel.\u00a0\nTensorFlow will standardize on SavedModel as an interchange format for TensorFlow Serving, ", "extractionText": "TensorFlow Lite", "afterText": ", TensorFlow.js, TensorFlow Hub, and more.\nRobust model deployment in production on any platform\nTensorFlow has always provided a direct path to produ", "attributesHtml": "<div><strong>class:</strong> CONCEPT</div><div><strong>attributes:</strong> {<span class=\"lx-attr-key\">definition</span>: <span class=\"lx-attr-value\">TensorFlow\u2019s lightweight solution for deploying models on mobile and embedded devices such as Android, iOS, Raspberry Pi, and Edge TPUs.</span>}</div>"}, {"index": 13, "class": "CONCEPT", "text": "TensorFlow.js", "color": "#D2E3FC", "startPos": 6010, "endPos": 6023, "beforeText": "ents are provided.\nExport to SavedModel.\u00a0\nTensorFlow will standardize on SavedModel as an interchange format for TensorFlow Serving, TensorFlow Lite, ", "extractionText": "TensorFlow.js", "afterText": ", TensorFlow Hub, and more.\nRobust model deployment in production on any platform\nTensorFlow has always provided a direct path to production. Whether ", "attributesHtml": "<div><strong>class:</strong> CONCEPT</div><div><strong>attributes:</strong> {<span class=\"lx-attr-key\">definition</span>: <span class=\"lx-attr-value\">A library that enables deploying and defining models in JavaScript environments, such as a web browser or server-side through Node.js.</span>}</div>"}];
        let currentIndex = 0;
        let isPlaying = false;
        let animationInterval = null;
        let animationSpeed = 1.0;

        function updateDisplay() {
          const extraction = extractions[currentIndex];
          if (!extraction) return;

          document.getElementById('attributesContainer').innerHTML = extraction.attributesHtml;
          document.getElementById('entityInfo').textContent = (currentIndex + 1) + '/' + extractions.length;
          document.getElementById('posInfo').textContent = '[' + extraction.startPos + '-' + extraction.endPos + ']';
          document.getElementById('progressSlider').value = currentIndex;

          const playBtn = document.querySelector('.lx-control-btn');
          if (playBtn) playBtn.textContent = isPlaying ? '⏸ Pause' : '▶️ Play';

          const prevHighlight = document.querySelector('.lx-text-window .lx-current-highlight');
          if (prevHighlight) prevHighlight.classList.remove('lx-current-highlight');
          const currentSpan = document.querySelector('.lx-text-window span[data-idx="' + currentIndex + '"]');
          if (currentSpan) {
            currentSpan.classList.add('lx-current-highlight');
            currentSpan.scrollIntoView({block: 'center', behavior: 'smooth'});
          }
        }

        function nextExtraction() {
          currentIndex = (currentIndex + 1) % extractions.length;
          updateDisplay();
        }

        function prevExtraction() {
          currentIndex = (currentIndex - 1 + extractions.length) % extractions.length;
          updateDisplay();
        }

        function jumpToExtraction(index) {
          currentIndex = parseInt(index);
          updateDisplay();
        }

        function playPause() {
          if (isPlaying) {
            clearInterval(animationInterval);
            isPlaying = false;
          } else {
            animationInterval = setInterval(nextExtraction, animationSpeed * 1000);
            isPlaying = true;
          }
          updateDisplay();
        }

        window.playPause = playPause;
        window.nextExtraction = nextExtraction;
        window.prevExtraction = prevExtraction;
        window.jumpToExtraction = jumpToExtraction;

        updateDisplay();
      })();
    </script>