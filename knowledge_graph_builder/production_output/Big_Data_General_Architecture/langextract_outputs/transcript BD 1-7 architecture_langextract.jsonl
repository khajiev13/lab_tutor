{"extractions": [{"extraction_class": "TOPIC", "extraction_text": "Big Data General Architecture", "char_interval": {"start_pos": 187, "end_pos": 216}, "alignment_status": "match_exact", "extraction_index": 1, "group_index": 0, "description": null, "attributes": null}, {"extraction_class": "SUMMARY", "extraction_text": "The session discusses the general architecture of big data systems, which evolved from the need to replace expensive, high-performance servers with distributed computing. This approach uses a group of cheap servers for distributed processing and storage, achieving high performance through redundancy. Key hardware and software innovations, including virtualization and automated load balancing, enabled this shift. The core architecture consists of two main components—distributed storage and distributed processing—and is generally structured in three layers. The bottom layer is the Data Storage System, which handles data collection, cleaning, modeling, and storage using distributed databases or file systems. It also includes unified data access interfaces like ODBC. The middle layer is the Data Processing System, which comprises various computing models (e.g., MapReduce for batch, Stream Computing for dynamic data, MPP for structured data), computing platforms (e.g., Hadoop, Spark, Storm), and specialized computing engines (e.g., Google's Dremel, Pregel for graph data, Yahoo's S4 for streaming). The top layer is the Data Application System, where processed data is used for visualization, data products, and services across various industries like e-commerce, finance, and healthcare. An alternative logical view presents this as a bottom layer for data collection, a middle layer for analysis and integration, and a top layer for user-facing analysis and visualization.", "char_interval": {"start_pos": 223, "end_pos": 226}, "alignment_status": "match_lesser", "extraction_index": 2, "group_index": 0, "description": null, "attributes": null}, {"extraction_class": "KEYWORDS", "extraction_text": "big data architecture, distributed computing, distributed storage, distributed processing, MapReduce, Hadoop, Spark, computing models, computing engines, ODBC", "char_interval": {"start_pos": 187, "end_pos": 4462}, "alignment_status": "match_fuzzy", "extraction_index": 3, "group_index": 0, "description": null, "attributes": null}, {"extraction_class": "CONCEPT", "extraction_text": "Distributed Computing", "char_interval": {"start_pos": 768, "end_pos": 789}, "alignment_status": "match_fuzzy", "extraction_index": 4, "group_index": 0, "description": null, "attributes": {"definition": "A computing paradigm that uses a group of cheap servers working as a team to replace expensive high-performance servers, employing distributed processing and storage, and using high redundancy to achieve high performance."}}, {"extraction_class": "CONCEPT", "extraction_text": "Big Data Architecture", "char_interval": {"start_pos": 2057, "end_pos": 2078}, "alignment_status": "match_fuzzy", "extraction_index": 5, "group_index": 1, "description": null, "attributes": {"definition": "A three-layer structure for big data systems, consisting of a data storage system, a data processing system, and a data application system."}}, {"extraction_class": "CONCEPT", "extraction_text": "ODBC (Open DataBase Connectivity)", "char_interval": {"start_pos": 4458, "end_pos": 4566}, "alignment_status": "match_fuzzy", "extraction_index": 6, "group_index": 2, "description": null, "attributes": {"definition": "A database application programming access interface provided by Microsoft that uses Structured Query Language (SQL) as the database access language. It is a set of function calls and does not rely on any specific DBMS, instead using a corresponding driver to handle database operations."}}, {"extraction_class": "CONCEPT", "extraction_text": "MapReduce", "char_interval": {"start_pos": 5139, "end_pos": 5148}, "alignment_status": "match_exact", "extraction_index": 7, "group_index": 3, "description": null, "attributes": {"definition": "A batch processing model designed for processing massive amounts of data."}}, {"extraction_class": "CONCEPT", "extraction_text": "Stream Computing", "char_interval": {"start_pos": 5195, "end_pos": 5211}, "alignment_status": "match_exact", "extraction_index": 8, "group_index": 4, "description": null, "attributes": {"definition": "A computing model designed for processing dynamic data streams in real-time."}}, {"extraction_class": "CONCEPT", "extraction_text": "MPP (Massively Parallel Processing)", "char_interval": {"start_pos": 5284, "end_pos": 5318}, "alignment_status": "match_fuzzy", "extraction_index": 9, "group_index": 5, "description": null, "attributes": {"definition": "A computing model for large-scale concurrent processing of structured data."}}, {"extraction_class": "CONCEPT", "extraction_text": "Computing Engine", "char_interval": {"start_pos": 5644, "end_pos": 5660}, "alignment_status": "match_exact", "extraction_index": 10, "group_index": 6, "description": null, "attributes": {"definition": "A server-side program designed and encapsulated for a specific computing model based on a computing platform. It supports back-end big data processing, computing, and task analysis in a specific mode."}}, {"extraction_class": "CONCEPT", "extraction_text": "Pregel", "char_interval": {"start_pos": 6800, "end_pos": 6806}, "alignment_status": "match_exact", "extraction_index": 11, "group_index": 7, "description": null, "attributes": {"definition": "A graph parallel computing engine technology developed by Google for efficient computing and processing of network graph data."}}, {"extraction_class": "CONCEPT", "extraction_text": "S4 (Simple, Scalable Streaming System)", "char_interval": {"start_pos": 6853, "end_pos": 6891}, "alignment_status": "match_exact", "extraction_index": 12, "group_index": 8, "description": null, "attributes": {"definition": "A streaming computing engine provided by Yahoo! for real-time data calculations, initially used to predict user click behavior on advertisements."}}], "text": "Hello everyone, I am Haiying Che, from Institute of Data Science and knowledge Engineering，\nSchool of Computer Science, Beijing Institute of Technology, \nin this session, we will discuss big data general architecture.\nWhen the volume of data get bigger and bigger, any single traditional high performance server can not satisfy the requirement, more servers are needed. But the traditional high-performance server is very expensive, normally Hundreds of millions of yuan, because it is very reliable, like IBM Z series server, which can reach the reliability of 99.9999%, Known as zero downtime, so it is called Z series. High performance and high reliability means high price. But no company can afford such expensive server to deal with the big data issues. So, the distributed computing was used to address this issue. \nThe logic of distributed computing is use a group of cheap servers working as a team to replace the expensive high performance servers, which could be distributed processing, distributed storage.  And use high redundancy to achieve high performance. \nKey hardware and software breakthroughs revolutionized the data management industry. \nFirst, innovation and demand increased the power and decreased the price of hardware. \nNew software emerged that understood how to take advantage of this hardware by automating processes like load balancing and optimization across a huge cluster of nodes.\nThe software included built-in rules that understood that certain workloads required a certain performance level. \nThe software treated all the nodes as though they were simply one big pool of computing, storage, and networking assets, and moved processes to another node without interruption if a node failed, using the technology of virtualization.\nIn the scope of big data, there are 2 main components, distributed storage and distributed processing. \nThe data need to be stored, then processed, and the intermediate and results also need to be stored. \nThese two components complement each other and closely work together.\nGenerally the big data architecture includes 3 layers, from bottom to top, \ndata storage system includes distributed database/Datawarehouse, which store the structured data in relational database, distributed file system, which store the unstructured data, and also the data collection and modeling, which responsible for collecting data according to the predefined model.\nData processing system includes calculation engine, Computing platform, calculation model and algorithm. Based on the stored data, we need design the calculation model, algorithms, also we need big data distributed calculation engine like MapReduce, and computing platform, like Hadoop, spark, Storm etc. to facilitate the data processing. \nBased on the data storage and data processing results, the customized big data application can be built, which includes big data applications, data products and services, and also the data visualization. \nWith the help of processing system, all the needed data has already been calculated and modeled, the upper level application can present the data visualized results or give suggestions, or make smart decisions.\nIn the storage structure: the database provides the logical storage structure of the data; \nthe distributed file system provides the physical storage structure of the data.\nData storage system could include several parts.\nData collection layer:\nSystem logs, Web Crawler, wireless sensor network, internet of things and all kinds of data resources, from which we can collect data.\n）Data cleaning, extraction and MODELING\nThen we can convert various types of structured, unstructured, and heterogeneous data from different sources into standard storage format data, and define data attributes and value ranges to prepare for the data analysis. \n）Data storage architecture; \nCentralized or distributed file system, relational database or distributed database, row based storage data structure or column based storage data structure, key-value pair structure, hash table retrieval, etc. data scientist can choose the suitable data storage architecture to store the data, making the data storing and data retrieval more convenient. \n）Unified Data Access Interface, etc.\nThe application 's access to the database and data exchange is an important issue in distributed computing systems. \nThe industry earlier used the database application programming access interface provided by Microsoft, ODBC-Open DataBase Connectivity, which uses the X/open and ISO/IEC call interface (CLI call-level interface) standards as the basis, and uses a structured query language-SQL  as the database access language.\nODBC is essentially a set of database access APIs, consisting of a set of function calls, and the core is SQL statements. When an ODBC-based application operates on the database, the user directly transmits SQL statements to ODBC.  At the same time, ODBC does not rely on any DBMS for database operations, and does not directly deal with DBMS， All database operations are handled by the corresponding ODBC driver.\nComputing models for different types of data, \nsuch as the MapReduce Batch Processing Model for massive data, \nthe Stream Computing model for dynamic data streams, \nthe Large-scale concurrent processing (MPP-Massively Parallel Processing) model for structured data, \nand the large-scale physical memory In-memory Computing model; \nData Flow Graph model for machine learning algorithms; \nImplementation of various analysis algorithms, and computing platforms that provide various development kits and operating environments, such as Hadoop, Spark , Storm, etc.\nThe computing engine is a server-side program designed and encapsulated for a specific computing model based on a computing platform. \nIt is used to support the back-end big data processing, computing and tasks analysis in a specific computing mode. \nFor example, the MapReduce computing engine provides big data division and node allocation, job scheduling and calculation result integration, directly supporting the development of upper-level applications. \nGoogle’s interactive computing engine uses Dremel and PowerDrill technologies to provide rapid calculation and analysis of large-scale data sets; \nThe open source Apache drill project is based on column storage structure, data localization, In-memory storage and other technologies to achieve large-scale data Quick query access. \nThe graph parallel computing engine provides efficient computing and processing of network graph data (social networks, telecommunications networks, and brain function connection networks are often represented by weighted directed graphs)\n(20% of the data processed by the Google search engine is enabled by a graph computing engine). This technology includes Google’s Pregel, open source technology Hama, GraphLab, etc. \nS4 (Simple, Scalable Streaming System) is Yahoo! A streaming computing engine is provided. The initial goal is to improve the click-through rate of cost-per-click advertisements, and predict the user's possible click behavior on advertisements through real-time data calculations\nBased on the above-mentioned computing architecture and processing platform, big data application technology solutions in various industries and fields were provided. \nAt present, the Internet, e-commerce, e-government, finance, telecommunications, medical and health industries are the most popular areas for big data applications, \nwhile manufacturing, education, energy, environmental protection, and smart transportation are the areas that big data technology will or have begun to expand. \nAfter  go through the general architecture of the big data, let’s look at the big data layer in another logical perspective.\nIn the bottom layer, the network data was collected, probe data was collected, service data was collected, business data was collected, terminal data was collected.\nIn the middle layer, user behavior was analyzed, Key indicators was monitored and other data was integrated and analyzed using the models and algorithms. And the processed data was provided to the upper level data services through unified data platform.\nIn the top layer, based on the analyzed data provided through the unified data platform, user can do different kinds of analysis, business process analysis, user analysis, data analysis and data output visualization.\nIn this session, we discussed the big data architecture 3 layers, Data storage system; Data processing system; Data application system; Thank you for your attention, if you have any question, feel free to contact me.", "document_id": "doc_1ac76a91"}
