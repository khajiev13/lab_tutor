{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03d74fe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Prompt alignment: non-exact match: [example#0] class='TOPIC' status=AlignmentStatus.MATCH_LESSER text='In-Memory Computation and Computer Clusters' char_span=(0, 21)\n",
      "WARNING:absl:Prompt alignment: non-exact match: [example#0] class='TOPIC' status=AlignmentStatus.MATCH_LESSER text='In-Memory Computation and Computer Clusters' char_span=(0, 21)\n",
      "WARNING:absl:Prompt alignment: FAILED to align: [example#0] class='SUMMARY' status=None text='In-memory computation uses cluster RAM for calculations, avoiding disk access for better performance.'\n",
      "WARNING:absl:Prompt alignment: non-exact match: [example#0] class='CONCEPT' status=AlignmentStatus.MATCH_FUZZY text='In-memory computation' char_span=(0, 21)\n",
      "WARNING:absl:Prompt alignment: non-exact match: [example#0] class='TOPIC' status=AlignmentStatus.MATCH_LESSER text='In-Memory Computation and Computer Clusters' char_span=(0, 21)\n",
      "WARNING:absl:Prompt alignment: FAILED to align: [example#0] class='SUMMARY' status=None text='In-memory computation uses cluster RAM for calculations, avoiding disk access for better performance.'\n",
      "WARNING:absl:Prompt alignment: FAILED to align: [example#0] class='SUMMARY' status=None text='In-memory computation uses cluster RAM for calculations, avoiding disk access for better performance.'\n",
      "WARNING:absl:Prompt alignment: non-exact match: [example#0] class='CONCEPT' status=AlignmentStatus.MATCH_FUZZY text='In-memory computation' char_span=(0, 21)\n",
      "WARNING:absl:Prompt alignment: non-exact match: [example#0] class='CONCEPT' status=AlignmentStatus.MATCH_FUZZY text='In-memory computation' char_span=(0, 21)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text length: 5710\n",
      "After preprocessing length: 5425\n",
      "Preprocessing removed: 285 characters\n",
      "\n",
      "First 200 chars of cleaned text:\n",
      "Hello everyone, I am Haiying Che, from Institute of Data Science and knowledge Engineering\n",
      "School of Computer Science, in Beijing Institute of Technology, in this session, we will discuss\n",
      "Some idea ab...\n",
      "üîÑ Using custom OpenAI endpoint: https://api.xiaocaseai.com/v1\n",
      "üìã Model: gemini-2.5-pro\n",
      "Original text length: 13464\n",
      "After preprocessing length: 13335\n",
      "Preprocessing removed: 129 characters\n",
      "\n",
      "First 200 chars of cleaned text:\n",
      "Hello everyone, I am Haiying Che, from Institute of Data Science and knowledge Engineering\n",
      "School of Computer Science, in Beijing Institute of Technology, \n",
      "in this session, we discuss in memory comput...\n",
      "üîÑ Using custom OpenAI endpoint: https://api.xiaocaseai.com/v1\n",
      "üìã Model: gemini-2.5-pro\n",
      "Original text length: 14313\n",
      "After preprocessing length: 14118\n",
      "Preprocessing removed: 195 characters\n",
      "\n",
      "First 200 chars of cleaned text:\n",
      "Hello everyone, I am Haiying Che, from  Institute of Data Science and knowledge Engineering\n",
      "School of Computer Science, in Beijing Institute of Technology , in this session we discuss In memory Databa...\n",
      "üîÑ Using custom OpenAI endpoint: https://api.xiaocaseai.com/v1\n",
      "üìã Model: gemini-2.5-pro\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khajievroma/Projects/lab_tutor/knowledge_graph_builder/.venv/lib/python3.12/site-packages/networkx/readwrite/json_graph/node_link.py:145: FutureWarning: \n",
      "The default value will be `edges=\"edges\" in NetworkX 3.6.\n",
      "\n",
      "To make this warning go away, explicitly set the edges kwarg, e.g.:\n",
      "\n",
      "  nx.node_link_data(G, edges=\"links\") to preserve current behavior, or\n",
      "  nx.node_link_data(G, edges=\"edges\") for forward compatibility.\n",
      "  warnings.warn(\n",
      "WARNING:absl:Prompt alignment: non-exact match: [example#0] class='TOPIC' status=AlignmentStatus.MATCH_LESSER text='In-Memory Computation and Computer Clusters' char_span=(0, 21)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Successfully extracted concepts with preprocessing + LLM compression\n",
      "Saved knowledge graph for 'transcript BD 2-3 external data acquisition.docx' to 'outputs/transcript BD 2-3 external data acquisition.json'\n",
      "Original text length: 5513\n",
      "After preprocessing length: 5352\n",
      "Preprocessing removed: 161 characters\n",
      "\n",
      "First 200 chars of cleaned text:\n",
      "Hello everyone, I am Haiying Che, from Institute of Data Science and knowledge Engineering\n",
      "School of Computer Science, in Beijing Institute of Technology, in this session, we will discuss Data Cleanin...\n",
      "üîÑ Using custom OpenAI endpoint: https://api.xiaocaseai.com/v1\n",
      "üìã Model: gemini-2.5-pro\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Prompt alignment: FAILED to align: [example#0] class='SUMMARY' status=None text='In-memory computation uses cluster RAM for calculations, avoiding disk access for better performance.'\n",
      "WARNING:absl:Prompt alignment: non-exact match: [example#0] class='CONCEPT' status=AlignmentStatus.MATCH_FUZZY text='In-memory computation' char_span=(0, 21)\n",
      "WARNING:absl:Prompt alignment: non-exact match: [example#0] class='TOPIC' status=AlignmentStatus.MATCH_LESSER text='In-Memory Computation and Computer Clusters' char_span=(0, 21)\n",
      "WARNING:absl:Prompt alignment: FAILED to align: [example#0] class='SUMMARY' status=None text='In-memory computation uses cluster RAM for calculations, avoiding disk access for better performance.'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Successfully extracted concepts with preprocessing + LLM compression\n",
      "Saved knowledge graph for 'big data analysis 3-3.docx' to 'outputs/big data analysis 3-3.json'\n",
      "Original text length: 2039\n",
      "After preprocessing length: 1972\n",
      "Preprocessing removed: 67 characters\n",
      "\n",
      "First 200 chars of cleaned text:\n",
      "Hello everyone, I am Haiying Che, from Institute of Data Science and knowledge Engineering\n",
      "School of Computer Science, in Beijing Institute of Technology, In this chapter we will learn some popular al...\n",
      "üîÑ Using custom OpenAI endpoint: https://api.xiaocaseai.com/v1\n",
      "üìã Model: gemini-2.5-pro\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Prompt alignment: non-exact match: [example#0] class='CONCEPT' status=AlignmentStatus.MATCH_FUZZY text='In-memory computation' char_span=(0, 21)\n",
      "WARNING:absl:Prompt alignment: non-exact match: [example#0] class='TOPIC' status=AlignmentStatus.MATCH_LESSER text='In-Memory Computation and Computer Clusters' char_span=(0, 21)\n",
      "WARNING:absl:Prompt alignment: FAILED to align: [example#0] class='SUMMARY' status=None text='In-memory computation uses cluster RAM for calculations, avoiding disk access for better performance.'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Successfully extracted concepts with preprocessing + LLM compression\n",
      "Saved knowledge graph for 'BDA 5-22.docx' to 'outputs/BDA 5-22.json'\n",
      "Original text length: 10334\n",
      "After preprocessing length: 10101\n",
      "Preprocessing removed: 233 characters\n",
      "\n",
      "First 200 chars of cleaned text:\n",
      "Hello everyone, I am Haiying Che, from Institute of Data Science and knowledge EngineeringÔºå\n",
      "School of Computer Science, Beijing Institute of Technology, \n",
      "in this session, we will discuss about big dat...\n",
      "üîÑ Using custom OpenAI endpoint: https://api.xiaocaseai.com/v1\n",
      "üìã Model: gemini-2.5-pro\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Prompt alignment: non-exact match: [example#0] class='CONCEPT' status=AlignmentStatus.MATCH_FUZZY text='In-memory computation' char_span=(0, 21)\n",
      "WARNING:absl:Prompt alignment: non-exact match: [example#0] class='TOPIC' status=AlignmentStatus.MATCH_LESSER text='In-Memory Computation and Computer Clusters' char_span=(0, 21)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Successfully extracted concepts with preprocessing + LLM compression\n",
      "Saved knowledge graph for 'transcript BD 1-5 lifecycle.docx' to 'outputs/transcript BD 1-5 lifecycle.json'\n",
      "Original text length: 5852\n",
      "After preprocessing length: 5755\n",
      "Preprocessing removed: 97 characters\n",
      "\n",
      "First 200 chars of cleaned text:\n",
      "Hello everyone, I am Haiying Che, from Institute of Data Science and knowledge EngineeringÔºå\n",
      "School of Computer Science, Beijing Institute of Technology, \n",
      "in this session, we will discuss about Big Dat...\n",
      "üîÑ Using custom OpenAI endpoint: https://api.xiaocaseai.com/v1\n",
      "üìã Model: gemini-2.5-pro\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Prompt alignment: FAILED to align: [example#0] class='SUMMARY' status=None text='In-memory computation uses cluster RAM for calculations, avoiding disk access for better performance.'\n",
      "WARNING:absl:Prompt alignment: non-exact match: [example#0] class='CONCEPT' status=AlignmentStatus.MATCH_FUZZY text='In-memory computation' char_span=(0, 21)\n",
      "WARNING:absl:Prompt alignment: non-exact match: [example#0] class='TOPIC' status=AlignmentStatus.MATCH_LESSER text='In-Memory Computation and Computer Clusters' char_span=(0, 21)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Successfully extracted concepts with preprocessing + LLM compression\n",
      "Saved knowledge graph for 'transcript BD 1-6 processing flow.docx' to 'outputs/transcript BD 1-6 processing flow.json'\n",
      "Original text length: 2989\n",
      "After preprocessing length: 2940\n",
      "Preprocessing removed: 49 characters\n",
      "\n",
      "First 200 chars of cleaned text:\n",
      "types of NoSQL\n",
      "Key Value Pair Based\n",
      "Data is stored in key/value pairs. It is designed in such a way to handle lots of data and heavy load.\n",
      "Key-value pair storage databases store data as a hash table w...\n",
      "üîÑ Using custom OpenAI endpoint: https://api.xiaocaseai.com/v1\n",
      "üìã Model: gemini-2.5-pro\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Prompt alignment: FAILED to align: [example#0] class='SUMMARY' status=None text='In-memory computation uses cluster RAM for calculations, avoiding disk access for better performance.'\n",
      "WARNING:absl:Prompt alignment: non-exact match: [example#0] class='CONCEPT' status=AlignmentStatus.MATCH_FUZZY text='In-memory computation' char_span=(0, 21)\n",
      "WARNING:absl:Prompt alignment: non-exact match: [example#0] class='TOPIC' status=AlignmentStatus.MATCH_LESSER text='In-Memory Computation and Computer Clusters' char_span=(0, 21)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Successfully extracted concepts with preprocessing + LLM compression\n",
      "Saved knowledge graph for '4 types of NoSQL.docx' to 'outputs/4 types of NoSQL.json'\n",
      "Original text length: 7238\n",
      "After preprocessing length: 7113\n",
      "Preprocessing removed: 125 characters\n",
      "\n",
      "First 200 chars of cleaned text:\n",
      "Hello everyone, I am Haiying Che, from Institute of Data Science and knowledge Engineering\n",
      "School of Computer Science, in Beijing Institute of Technology, in this session, we will discuss\n",
      "Some idea ab...\n",
      "üîÑ Using custom OpenAI endpoint: https://api.xiaocaseai.com/v1\n",
      "üìã Model: gemini-2.5-pro\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Prompt alignment: FAILED to align: [example#0] class='SUMMARY' status=None text='In-memory computation uses cluster RAM for calculations, avoiding disk access for better performance.'\n",
      "WARNING:absl:Prompt alignment: non-exact match: [example#0] class='CONCEPT' status=AlignmentStatus.MATCH_FUZZY text='In-memory computation' char_span=(0, 21)\n",
      "WARNING:absl:Prompt alignment: non-exact match: [example#0] class='TOPIC' status=AlignmentStatus.MATCH_LESSER text='In-Memory Computation and Computer Clusters' char_span=(0, 21)\n",
      "WARNING:absl:Prompt alignment: FAILED to align: [example#0] class='SUMMARY' status=None text='In-memory computation uses cluster RAM for calculations, avoiding disk access for better performance.'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Successfully extracted concepts with preprocessing + LLM compression\n",
      "Saved knowledge graph for 'transcript BD 2-1 resources-attack  explaination.docx' to 'outputs/transcript BD 2-1 resources-attack  explaination.json'\n",
      "Original text length: 5224\n",
      "After preprocessing length: 5137\n",
      "Preprocessing removed: 87 characters\n",
      "\n",
      "First 200 chars of cleaned text:\n",
      "Hello everyone, I am Haiying Che, from  Institute of Data Science and knowledge Engineering\n",
      "School of Computer Science, in Beijing Institute of Technology , from this session ,\n",
      "we start to learn Data ...\n",
      "üîÑ Using custom OpenAI endpoint: https://api.xiaocaseai.com/v1\n",
      "üìã Model: gemini-2.5-pro\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Prompt alignment: non-exact match: [example#0] class='CONCEPT' status=AlignmentStatus.MATCH_FUZZY text='In-memory computation' char_span=(0, 21)\n",
      "WARNING:absl:Prompt alignment: non-exact match: [example#0] class='TOPIC' status=AlignmentStatus.MATCH_LESSER text='In-Memory Computation and Computer Clusters' char_span=(0, 21)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Successfully extracted concepts with preprocessing + LLM compression\n",
      "Saved knowledge graph for 'BDA 4-6.docx' to 'outputs/BDA 4-6.json'\n",
      "Original text length: 5761\n",
      "After preprocessing length: 5661\n",
      "Preprocessing removed: 100 characters\n",
      "\n",
      "First 200 chars of cleaned text:\n",
      "Hello everyone, I am Haiying Che, from Institute of Data Science and knowledge Engineering\n",
      "School of Computer Science, in Beijing Institute of Technology, in this session, we will discuss Data Quality...\n",
      "üîÑ Using custom OpenAI endpoint: https://api.xiaocaseai.com/v1\n",
      "üìã Model: gemini-2.5-pro\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Prompt alignment: FAILED to align: [example#0] class='SUMMARY' status=None text='In-memory computation uses cluster RAM for calculations, avoiding disk access for better performance.'\n",
      "WARNING:absl:Prompt alignment: non-exact match: [example#0] class='CONCEPT' status=AlignmentStatus.MATCH_FUZZY text='In-memory computation' char_span=(0, 21)\n",
      "WARNING:absl:Prompt alignment: non-exact match: [example#0] class='TOPIC' status=AlignmentStatus.MATCH_LESSER text='In-Memory Computation and Computer Clusters' char_span=(0, 21)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Successfully extracted concepts with preprocessing + LLM compression\n",
      "Saved knowledge graph for 'Big data 3-2.docx' to 'outputs/Big data 3-2.json'\n",
      "Original text length: 3723\n",
      "After preprocessing length: 3613\n",
      "Preprocessing removed: 110 characters\n",
      "\n",
      "First 200 chars of cleaned text:\n",
      "Hello everyone, I am Haiying Che, from Institute of Data Science and knowledge Engineering\n",
      "School of Computer Science, in Beijing Institute of Technology, in this session, we will discuss  Data transf...\n",
      "üîÑ Using custom OpenAI endpoint: https://api.xiaocaseai.com/v1\n",
      "üìã Model: gemini-2.5-pro\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Prompt alignment: FAILED to align: [example#0] class='SUMMARY' status=None text='In-memory computation uses cluster RAM for calculations, avoiding disk access for better performance.'\n",
      "WARNING:absl:Prompt alignment: non-exact match: [example#0] class='CONCEPT' status=AlignmentStatus.MATCH_FUZZY text='In-memory computation' char_span=(0, 21)\n",
      "WARNING:absl:Prompt alignment: non-exact match: [example#0] class='TOPIC' status=AlignmentStatus.MATCH_LESSER text='In-Memory Computation and Computer Clusters' char_span=(0, 21)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Successfully extracted concepts with preprocessing + LLM compression\n",
      "Saved knowledge graph for 'Big data analysis 3-4.docx' to 'outputs/Big data analysis 3-4.json'\n",
      "Original text length: 9628\n",
      "After preprocessing length: 9516\n",
      "Preprocessing removed: 112 characters\n",
      "\n",
      "First 200 chars of cleaned text:\n",
      "Hello everyone, I am Haiying Che, from Institute of Data Science and knowledge Engineering\n",
      "School of Computer Science, in Beijing Institute of Technology, in this session, we will discuss about The fo...\n",
      "üîÑ Using custom OpenAI endpoint: https://api.xiaocaseai.com/v1\n",
      "üìã Model: gemini-2.5-pro\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Prompt alignment: FAILED to align: [example#0] class='SUMMARY' status=None text='In-memory computation uses cluster RAM for calculations, avoiding disk access for better performance.'\n",
      "WARNING:absl:Prompt alignment: non-exact match: [example#0] class='CONCEPT' status=AlignmentStatus.MATCH_FUZZY text='In-memory computation' char_span=(0, 21)\n",
      "WARNING:absl:Prompt alignment: non-exact match: [example#0] class='TOPIC' status=AlignmentStatus.MATCH_LESSER text='In-Memory Computation and Computer Clusters' char_span=(0, 21)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Successfully extracted concepts with preprocessing + LLM compression\n",
      "Saved knowledge graph for 'BDA5-6.docx' to 'outputs/BDA5-6.json'\n",
      "Original text length: 7811\n",
      "After preprocessing length: 7693\n",
      "Preprocessing removed: 118 characters\n",
      "\n",
      "First 200 chars of cleaned text:\n",
      "Hello everyone, I am Haiying Che, from Institute of Data Science and knowledge Engineering\n",
      "School of Computer Science, in Beijing Institute of Technology, from this session,\n",
      "we start to learn Data sto...\n",
      "üîÑ Using custom OpenAI endpoint: https://api.xiaocaseai.com/v1\n",
      "üìã Model: gemini-2.5-pro\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Prompt alignment: FAILED to align: [example#0] class='SUMMARY' status=None text='In-memory computation uses cluster RAM for calculations, avoiding disk access for better performance.'\n",
      "WARNING:absl:Prompt alignment: non-exact match: [example#0] class='CONCEPT' status=AlignmentStatus.MATCH_FUZZY text='In-memory computation' char_span=(0, 21)\n",
      "WARNING:absl:Prompt alignment: non-exact match: [example#0] class='TOPIC' status=AlignmentStatus.MATCH_LESSER text='In-Memory Computation and Computer Clusters' char_span=(0, 21)\n",
      "WARNING:absl:Prompt alignment: FAILED to align: [example#0] class='SUMMARY' status=None text='In-memory computation uses cluster RAM for calculations, avoiding disk access for better performance.'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Successfully extracted concepts with preprocessing + LLM compression\n",
      "Saved knowledge graph for 'BDA5-7.docx' to 'outputs/BDA5-7.json'\n",
      "Original text length: 8107\n",
      "After preprocessing length: 7453\n",
      "Preprocessing removed: 654 characters\n",
      "\n",
      "First 200 chars of cleaned text:\n",
      "Hello everyone, I am Haiying Che, from Institute of Data Science and knowledge Engineering\n",
      "School of Computer Science, in Beijing Institute of Technology, in this session, we will discuss about big da...\n",
      "üîÑ Using custom OpenAI endpoint: https://api.xiaocaseai.com/v1\n",
      "üìã Model: gemini-2.5-pro\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Prompt alignment: non-exact match: [example#0] class='CONCEPT' status=AlignmentStatus.MATCH_FUZZY text='In-memory computation' char_span=(0, 21)\n",
      "WARNING:absl:Prompt alignment: non-exact match: [example#0] class='TOPIC' status=AlignmentStatus.MATCH_LESSER text='In-Memory Computation and Computer Clusters' char_span=(0, 21)\n",
      "WARNING:absl:Prompt alignment: FAILED to align: [example#0] class='SUMMARY' status=None text='In-memory computation uses cluster RAM for calculations, avoiding disk access for better performance.'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Successfully extracted concepts with preprocessing + LLM compression\n",
      "Saved knowledge graph for 'transcript BD 1-3 The fourth paradigm.docx' to 'outputs/transcript BD 1-3 The fourth paradigm.json'\n",
      "Original text length: 14192\n",
      "After preprocessing length: 13816\n",
      "Preprocessing removed: 376 characters\n",
      "\n",
      "First 200 chars of cleaned text:\n",
      "Hello everyone, I am Haiying Che, from Institute of Data Science and knowledge Engineering\n",
      "School of Computer Science, in Beijing Institute of Technology, from this session on, we will discuss somethi...\n",
      "üîÑ Using custom OpenAI endpoint: https://api.xiaocaseai.com/v1\n",
      "üìã Model: gemini-2.5-pro\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Prompt alignment: non-exact match: [example#0] class='CONCEPT' status=AlignmentStatus.MATCH_FUZZY text='In-memory computation' char_span=(0, 21)\n",
      "WARNING:absl:Prompt alignment: non-exact match: [example#0] class='TOPIC' status=AlignmentStatus.MATCH_LESSER text='In-Memory Computation and Computer Clusters' char_span=(0, 21)\n",
      "WARNING:absl:Prompt alignment: FAILED to align: [example#0] class='SUMMARY' status=None text='In-memory computation uses cluster RAM for calculations, avoiding disk access for better performance.'\n",
      "WARNING:absl:Prompt alignment: non-exact match: [example#0] class='CONCEPT' status=AlignmentStatus.MATCH_FUZZY text='In-memory computation' char_span=(0, 21)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Successfully extracted concepts with preprocessing + LLM compression\n",
      "Saved knowledge graph for 'BDA 4-1.docx' to 'outputs/BDA 4-1.json'\n",
      "Original text length: 5340\n",
      "After preprocessing length: 5170\n",
      "Preprocessing removed: 170 characters\n",
      "\n",
      "First 200 chars of cleaned text:\n",
      "Hello everyone, I am Haiying Che, from Institute of Data Science and knowledge Engineering\n",
      "School of Computer Science, in Beijing Institute of Technology, in the scope of big data, there are mainly tw...\n",
      "üîÑ Using custom OpenAI endpoint: https://api.xiaocaseai.com/v1\n",
      "üìã Model: gemini-2.5-pro\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Prompt alignment: non-exact match: [example#0] class='TOPIC' status=AlignmentStatus.MATCH_LESSER text='In-Memory Computation and Computer Clusters' char_span=(0, 21)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Successfully extracted concepts with preprocessing + LLM compression\n",
      "Saved knowledge graph for 'transcript BD 1-4 Big Data Characters.docx' to 'outputs/transcript BD 1-4 Big Data Characters.json'\n",
      "Original text length: 7429\n",
      "After preprocessing length: 7135\n",
      "Preprocessing removed: 294 characters\n",
      "\n",
      "First 200 chars of cleaned text:\n",
      "Hello everyone, I am Haiying Che, from Institute of Data Science and knowledge Engineering\n",
      "School of Computer Science, in Beijing Institute of Technology, from this session,\n",
      "we start to learn Data pro...\n",
      "üîÑ Using custom OpenAI endpoint: https://api.xiaocaseai.com/v1\n",
      "üìã Model: gemini-2.5-pro\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Prompt alignment: FAILED to align: [example#0] class='SUMMARY' status=None text='In-memory computation uses cluster RAM for calculations, avoiding disk access for better performance.'\n",
      "WARNING:absl:Prompt alignment: non-exact match: [example#0] class='CONCEPT' status=AlignmentStatus.MATCH_FUZZY text='In-memory computation' char_span=(0, 21)\n",
      "WARNING:absl:Prompt alignment: non-exact match: [example#0] class='TOPIC' status=AlignmentStatus.MATCH_LESSER text='In-Memory Computation and Computer Clusters' char_span=(0, 21)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Successfully extracted concepts with preprocessing + LLM compression\n",
      "Saved knowledge graph for 'transcript BD 1-2 structured and unstructured data.docx' to 'outputs/transcript BD 1-2 structured and unstructured data.json'\n",
      "Original text length: 6321\n",
      "After preprocessing length: 6144\n",
      "Preprocessing removed: 177 characters\n",
      "\n",
      "First 200 chars of cleaned text:\n",
      "Hello everyone, I am Haiying Che, from  Institute of Data Science and knowledge Engineering\n",
      "School of Computer Science, in Beijing Institute of Technology , in this session we discuss Data processing ...\n",
      "üîÑ Using custom OpenAI endpoint: https://api.xiaocaseai.com/v1\n",
      "üìã Model: gemini-2.5-pro\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Prompt alignment: FAILED to align: [example#0] class='SUMMARY' status=None text='In-memory computation uses cluster RAM for calculations, avoiding disk access for better performance.'\n",
      "WARNING:absl:Prompt alignment: non-exact match: [example#0] class='CONCEPT' status=AlignmentStatus.MATCH_FUZZY text='In-memory computation' char_span=(0, 21)\n",
      "WARNING:absl:Prompt alignment: non-exact match: [example#0] class='TOPIC' status=AlignmentStatus.MATCH_LESSER text='In-Memory Computation and Computer Clusters' char_span=(0, 21)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Successfully extracted concepts with preprocessing + LLM compression\n",
      "Saved knowledge graph for 'BDA5-2.docx' to 'outputs/BDA5-2.json'\n",
      "Original text length: 6167\n",
      "After preprocessing length: 6057\n",
      "Preprocessing removed: 110 characters\n",
      "\n",
      "First 200 chars of cleaned text:\n",
      "Hello everyone, I am Haiying Che, from Institute of Data Science and knowledge Engineering\n",
      "School of Computer Science, in Beijing Institute of Technology, in this session, we will discuss\n",
      "Some idea ab...\n",
      "üîÑ Using custom OpenAI endpoint: https://api.xiaocaseai.com/v1\n",
      "üìã Model: gemini-2.5-pro\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Prompt alignment: FAILED to align: [example#0] class='SUMMARY' status=None text='In-memory computation uses cluster RAM for calculations, avoiding disk access for better performance.'\n",
      "WARNING:absl:Prompt alignment: non-exact match: [example#0] class='CONCEPT' status=AlignmentStatus.MATCH_FUZZY text='In-memory computation' char_span=(0, 21)\n",
      "WARNING:absl:Prompt alignment: non-exact match: [example#0] class='TOPIC' status=AlignmentStatus.MATCH_LESSER text='In-Memory Computation and Computer Clusters' char_span=(0, 21)\n",
      "WARNING:absl:Prompt alignment: FAILED to align: [example#0] class='SUMMARY' status=None text='In-memory computation uses cluster RAM for calculations, avoiding disk access for better performance.'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Successfully extracted concepts with preprocessing + LLM compression\n",
      "Saved knowledge graph for 'transcript BD 2-1 Data resources.docx' to 'outputs/transcript BD 2-1 Data resources.json'\n",
      "Original text length: 10256\n",
      "After preprocessing length: 10107\n",
      "Preprocessing removed: 149 characters\n",
      "\n",
      "First 200 chars of cleaned text:\n",
      "Hello everyone, I am Haiying Che, from Institute of Data Science and knowledge Engineering\n",
      "School of Computer Science, in Beijing Institute of Technology, in this session we will talk about the powerf...\n",
      "üîÑ Using custom OpenAI endpoint: https://api.xiaocaseai.com/v1\n",
      "üìã Model: gemini-2.5-pro\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Prompt alignment: non-exact match: [example#0] class='CONCEPT' status=AlignmentStatus.MATCH_FUZZY text='In-memory computation' char_span=(0, 21)\n",
      "WARNING:absl:Prompt alignment: non-exact match: [example#0] class='TOPIC' status=AlignmentStatus.MATCH_LESSER text='In-Memory Computation and Computer Clusters' char_span=(0, 21)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Successfully extracted concepts with preprocessing + LLM compression\n",
      "Saved knowledge graph for 'BDA5-1.docx' to 'outputs/BDA5-1.json'\n",
      "Original text length: 5739\n",
      "After preprocessing length: 5615\n",
      "Preprocessing removed: 124 characters\n",
      "\n",
      "First 200 chars of cleaned text:\n",
      "Hello everyone, I am Haiying Che, from Institute of Data Science and knowledge Engineering\n",
      "School of Computer Science, in Beijing Institute of Technology, in this session, we will discuss\n",
      "Deep web dat...\n",
      "üîÑ Using custom OpenAI endpoint: https://api.xiaocaseai.com/v1\n",
      "üìã Model: gemini-2.5-pro\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Prompt alignment: FAILED to align: [example#0] class='SUMMARY' status=None text='In-memory computation uses cluster RAM for calculations, avoiding disk access for better performance.'\n",
      "WARNING:absl:Prompt alignment: non-exact match: [example#0] class='CONCEPT' status=AlignmentStatus.MATCH_FUZZY text='In-memory computation' char_span=(0, 21)\n",
      "WARNING:absl:Prompt alignment: non-exact match: [example#0] class='TOPIC' status=AlignmentStatus.MATCH_LESSER text='In-Memory Computation and Computer Clusters' char_span=(0, 21)\n",
      "WARNING:absl:Prompt alignment: FAILED to align: [example#0] class='SUMMARY' status=None text='In-memory computation uses cluster RAM for calculations, avoiding disk access for better performance.'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Successfully extracted concepts with preprocessing + LLM compression\n",
      "Saved knowledge graph for 'transcript BD 2-4 deep web.docx' to 'outputs/transcript BD 2-4 deep web.json'\n",
      "Original text length: 5822\n",
      "After preprocessing length: 5736\n",
      "Preprocessing removed: 86 characters\n",
      "\n",
      "First 200 chars of cleaned text:\n",
      "Hello everyone, I am Haiying Che, from Institute of Data Science and knowledge Engineering\n",
      "School of Computer Science, in Beijing Institute of Technology, \n",
      "in this session, we discuss about what is No...\n",
      "üîÑ Using custom OpenAI endpoint: https://api.xiaocaseai.com/v1\n",
      "üìã Model: gemini-2.5-pro\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Prompt alignment: non-exact match: [example#0] class='CONCEPT' status=AlignmentStatus.MATCH_FUZZY text='In-memory computation' char_span=(0, 21)\n",
      "WARNING:absl:Prompt alignment: non-exact match: [example#0] class='TOPIC' status=AlignmentStatus.MATCH_LESSER text='In-Memory Computation and Computer Clusters' char_span=(0, 21)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Successfully extracted concepts with preprocessing + LLM compression\n",
      "Saved knowledge graph for 'BDA 4-3.docx' to 'outputs/BDA 4-3.json'\n",
      "Original text length: 8714\n",
      "After preprocessing length: 8605\n",
      "Preprocessing removed: 109 characters\n",
      "\n",
      "First 200 chars of cleaned text:\n",
      "Hello everyone, I am Haiying Che, from Institute of Data Science and knowledge EngineeringÔºå\n",
      "School of Computer Science, Beijing Institute of Technology, \n",
      "in this session, we will discuss big data gene...\n",
      "üîÑ Using custom OpenAI endpoint: https://api.xiaocaseai.com/v1\n",
      "üìã Model: gemini-2.5-pro\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Prompt alignment: FAILED to align: [example#0] class='SUMMARY' status=None text='In-memory computation uses cluster RAM for calculations, avoiding disk access for better performance.'\n",
      "WARNING:absl:Prompt alignment: non-exact match: [example#0] class='CONCEPT' status=AlignmentStatus.MATCH_FUZZY text='In-memory computation' char_span=(0, 21)\n",
      "WARNING:absl:Prompt alignment: non-exact match: [example#0] class='TOPIC' status=AlignmentStatus.MATCH_LESSER text='In-Memory Computation and Computer Clusters' char_span=(0, 21)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Successfully extracted concepts with preprocessing + LLM compression\n",
      "Saved knowledge graph for 'BDA 6-1.docx' to 'outputs/BDA 6-1.json'\n",
      "Original text length: 7930\n",
      "After preprocessing length: 7835\n",
      "Preprocessing removed: 95 characters\n",
      "\n",
      "First 200 chars of cleaned text:\n",
      "Hello everyone, I am Haiying Che, from  Institute of Data Science and knowledge Engineering\n",
      "School of Computer Science, in Beijing Institute of Technology , in this session we discuss about distribute...\n",
      "üîÑ Using custom OpenAI endpoint: https://api.xiaocaseai.com/v1\n",
      "üìã Model: gemini-2.5-pro\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Prompt alignment: FAILED to align: [example#0] class='SUMMARY' status=None text='In-memory computation uses cluster RAM for calculations, avoiding disk access for better performance.'\n",
      "WARNING:absl:Prompt alignment: non-exact match: [example#0] class='CONCEPT' status=AlignmentStatus.MATCH_FUZZY text='In-memory computation' char_span=(0, 21)\n",
      "WARNING:absl:Prompt alignment: non-exact match: [example#0] class='TOPIC' status=AlignmentStatus.MATCH_LESSER text='In-Memory Computation and Computer Clusters' char_span=(0, 21)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Successfully extracted concepts with preprocessing + LLM compression\n",
      "Saved knowledge graph for 'transcript BD 1-7 architecture.docx' to 'outputs/transcript BD 1-7 architecture.json'\n",
      "Original text length: 10415\n",
      "After preprocessing length: 10214\n",
      "Preprocessing removed: 201 characters\n",
      "\n",
      "First 200 chars of cleaned text:\n",
      "Hello everyone, I am Haiying Che, from Institute of Data Science and knowledge Engineering\n",
      "School of Computer Science, in Beijing Institute of Technology\n",
      "In this chapter, we introduced some useful pla...\n",
      "üîÑ Using custom OpenAI endpoint: https://api.xiaocaseai.com/v1\n",
      "üìã Model: gemini-2.5-pro\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Prompt alignment: FAILED to align: [example#0] class='SUMMARY' status=None text='In-memory computation uses cluster RAM for calculations, avoiding disk access for better performance.'\n",
      "WARNING:absl:Prompt alignment: non-exact match: [example#0] class='CONCEPT' status=AlignmentStatus.MATCH_FUZZY text='In-memory computation' char_span=(0, 21)\n",
      "WARNING:absl:Prompt alignment: non-exact match: [example#0] class='TOPIC' status=AlignmentStatus.MATCH_LESSER text='In-Memory Computation and Computer Clusters' char_span=(0, 21)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Successfully extracted concepts with preprocessing + LLM compression\n",
      "Saved knowledge graph for 'BDA 4-2.docx' to 'outputs/BDA 4-2.json'\n",
      "Original text length: 5392\n",
      "After preprocessing length: 5179\n",
      "Preprocessing removed: 213 characters\n",
      "\n",
      "First 200 chars of cleaned text:\n",
      "School of Computer Science, in Beijing Institute of Technology, in this session, we will discuss Data Preprocessing.\n",
      "Data Preprocessing mainly includes data cleaning Data transformation and data reduc...\n",
      "üîÑ Using custom OpenAI endpoint: https://api.xiaocaseai.com/v1\n",
      "üìã Model: gemini-2.5-pro\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Prompt alignment: FAILED to align: [example#0] class='SUMMARY' status=None text='In-memory computation uses cluster RAM for calculations, avoiding disk access for better performance.'\n",
      "WARNING:absl:Prompt alignment: non-exact match: [example#0] class='CONCEPT' status=AlignmentStatus.MATCH_FUZZY text='In-memory computation' char_span=(0, 21)\n",
      "WARNING:absl:Prompt alignment: non-exact match: [example#0] class='TOPIC' status=AlignmentStatus.MATCH_LESSER text='In-Memory Computation and Computer Clusters' char_span=(0, 21)\n",
      "WARNING:absl:Prompt alignment: FAILED to align: [example#0] class='SUMMARY' status=None text='In-memory computation uses cluster RAM for calculations, avoiding disk access for better performance.'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Successfully extracted concepts with preprocessing + LLM compression\n",
      "Saved knowledge graph for 'Big data 3-1.docx' to 'outputs/Big data 3-1.json'\n",
      "Original text length: 4109\n",
      "After preprocessing length: 4039\n",
      "Preprocessing removed: 70 characters\n",
      "\n",
      "First 200 chars of cleaned text:\n",
      "Hello everyone, I am Haiying Che, from  Institute of Data Science and knowledge Engineering\n",
      "School of Computer Science, in Beijing Institute of Technology , in this session we discuss batch processing...\n",
      "üîÑ Using custom OpenAI endpoint: https://api.xiaocaseai.com/v1\n",
      "üìã Model: gemini-2.5-pro\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Prompt alignment: non-exact match: [example#0] class='CONCEPT' status=AlignmentStatus.MATCH_FUZZY text='In-memory computation' char_span=(0, 21)\n",
      "WARNING:absl:Prompt alignment: non-exact match: [example#0] class='TOPIC' status=AlignmentStatus.MATCH_LESSER text='In-Memory Computation and Computer Clusters' char_span=(0, 21)\n",
      "WARNING:absl:Prompt alignment: FAILED to align: [example#0] class='SUMMARY' status=None text='In-memory computation uses cluster RAM for calculations, avoiding disk access for better performance.'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Successfully extracted concepts with preprocessing + LLM compression\n",
      "Saved knowledge graph for 'BDA5-3.docx' to 'outputs/BDA5-3.json'\n",
      "Original text length: 5100\n",
      "After preprocessing length: 4899\n",
      "Preprocessing removed: 201 characters\n",
      "\n",
      "First 200 chars of cleaned text:\n",
      "Hello everyone, I am Haiying Che, from Institute of Data Science and knowledge Engineering\n",
      "School of Computer Science, in Beijing Institute of Technology, in this session, we will discuss Some idea ab...\n",
      "üîÑ Using custom OpenAI endpoint: https://api.xiaocaseai.com/v1\n",
      "üìã Model: gemini-2.5-pro\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Prompt alignment: non-exact match: [example#0] class='CONCEPT' status=AlignmentStatus.MATCH_FUZZY text='In-memory computation' char_span=(0, 21)\n",
      "WARNING:absl:Prompt alignment: non-exact match: [example#0] class='TOPIC' status=AlignmentStatus.MATCH_LESSER text='In-Memory Computation and Computer Clusters' char_span=(0, 21)\n",
      "WARNING:absl:Prompt alignment: FAILED to align: [example#0] class='SUMMARY' status=None text='In-memory computation uses cluster RAM for calculations, avoiding disk access for better performance.'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Successfully extracted concepts with preprocessing + LLM compression\n",
      "Saved knowledge graph for 'BDA 6-2.docx' to 'outputs/BDA 6-2.json'\n",
      "Original text length: 16549\n",
      "After preprocessing length: 16403\n",
      "Preprocessing removed: 146 characters\n",
      "\n",
      "First 200 chars of cleaned text:\n",
      "Hello everyone, I am Haiying Che, from Institute of Data Science and knowledge Engineering\n",
      "School of Computer Science, in Beijing Institute of Technology, in this session we discuss Distributed Graph ...\n",
      "üîÑ Using custom OpenAI endpoint: https://api.xiaocaseai.com/v1\n",
      "üìã Model: gemini-2.5-pro\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Prompt alignment: non-exact match: [example#0] class='CONCEPT' status=AlignmentStatus.MATCH_FUZZY text='In-memory computation' char_span=(0, 21)\n",
      "WARNING:absl:Prompt alignment: non-exact match: [example#0] class='TOPIC' status=AlignmentStatus.MATCH_LESSER text='In-Memory Computation and Computer Clusters' char_span=(0, 21)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Successfully extracted concepts with preprocessing + LLM compression\n",
      "Saved knowledge graph for 'transcript BD 1-1 Concepts.docx' to 'outputs/transcript BD 1-1 Concepts.json'\n",
      "Original text length: 4576\n",
      "After preprocessing length: 4465\n",
      "Preprocessing removed: 111 characters\n",
      "\n",
      "First 200 chars of cleaned text:\n",
      "Hello everyone, I am Haiying Che, from Institute of Data Science and knowledge Engineering\n",
      "School of Computer Science, in Beijing Institute of Technology\n",
      "in last session we learned 3 main Recommendati...\n",
      "üîÑ Using custom OpenAI endpoint: https://api.xiaocaseai.com/v1\n",
      "üìã Model: gemini-2.5-pro\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Prompt alignment: FAILED to align: [example#0] class='SUMMARY' status=None text='In-memory computation uses cluster RAM for calculations, avoiding disk access for better performance.'\n",
      "WARNING:absl:Prompt alignment: non-exact match: [example#0] class='CONCEPT' status=AlignmentStatus.MATCH_FUZZY text='In-memory computation' char_span=(0, 21)\n",
      "WARNING:absl:Prompt alignment: non-exact match: [example#0] class='TOPIC' status=AlignmentStatus.MATCH_LESSER text='In-Memory Computation and Computer Clusters' char_span=(0, 21)\n",
      "WARNING:absl:Prompt alignment: FAILED to align: [example#0] class='SUMMARY' status=None text='In-memory computation uses cluster RAM for calculations, avoiding disk access for better performance.'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Successfully extracted concepts with preprocessing + LLM compression\n",
      "Saved knowledge graph for 'BDA 6-4.docx' to 'outputs/BDA 6-4.json'\n",
      "Original text length: 6815\n",
      "After preprocessing length: 6707\n",
      "Preprocessing removed: 108 characters\n",
      "\n",
      "First 200 chars of cleaned text:\n",
      "Hello everyone, I am Haiying Che, from  Institute of Data Science and knowledge Engineering\n",
      "School of Computer Science, in Beijing Institute of Technology , from this session ,\n",
      "we start to learn Data ...\n",
      "üîÑ Using custom OpenAI endpoint: https://api.xiaocaseai.com/v1\n",
      "üìã Model: gemini-2.5-pro\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Prompt alignment: non-exact match: [example#0] class='CONCEPT' status=AlignmentStatus.MATCH_FUZZY text='In-memory computation' char_span=(0, 21)\n",
      "WARNING:absl:Prompt alignment: non-exact match: [example#0] class='TOPIC' status=AlignmentStatus.MATCH_LESSER text='In-Memory Computation and Computer Clusters' char_span=(0, 21)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå Extraction failed: Gemini API error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-pro'}, 'quotaValue': '50'}]}, {'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '2s'}]}}\n",
      "Failed to process document 'BDA 4-5.docx': 'dict' object has no attribute 'extractions'\n",
      "Original text length: 6490\n",
      "After preprocessing length: 6367\n",
      "Preprocessing removed: 123 characters\n",
      "\n",
      "First 200 chars of cleaned text:\n",
      "Bigdata analysis 3-5 data reduction\n",
      "Hello everyone, I am Haiying Che, from  Institute of Data Science and knowledge Engineering\n",
      "School of Computer Science, in Beijing Institute of Technology , in this...\n",
      "üîÑ Using custom OpenAI endpoint: https://api.xiaocaseai.com/v1\n",
      "üìã Model: gemini-2.5-pro\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Prompt alignment: FAILED to align: [example#0] class='SUMMARY' status=None text='In-memory computation uses cluster RAM for calculations, avoiding disk access for better performance.'\n",
      "WARNING:absl:Prompt alignment: non-exact match: [example#0] class='CONCEPT' status=AlignmentStatus.MATCH_FUZZY text='In-memory computation' char_span=(0, 21)\n",
      "WARNING:absl:Prompt alignment: non-exact match: [example#0] class='TOPIC' status=AlignmentStatus.MATCH_LESSER text='In-Memory Computation and Computer Clusters' char_span=(0, 21)\n",
      "WARNING:absl:Prompt alignment: FAILED to align: [example#0] class='SUMMARY' status=None text='In-memory computation uses cluster RAM for calculations, avoiding disk access for better performance.'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå Extraction failed: Gemini API error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-pro'}, 'quotaValue': '50'}]}, {'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '0s'}]}}\n",
      "Failed to process document 'Bigdata analysis 3-5.docx': 'dict' object has no attribute 'extractions'\n",
      "Original text length: 6151\n",
      "After preprocessing length: 6066\n",
      "Preprocessing removed: 85 characters\n",
      "\n",
      "First 200 chars of cleaned text:\n",
      "Hello everyone, I am Haiying Che, from Institute of Data Science and knowledge Engineering\n",
      "School of Computer Science, in Beijing Institute of Technology, \n",
      "in this session, we discuss Stream computing...\n",
      "üîÑ Using custom OpenAI endpoint: https://api.xiaocaseai.com/v1\n",
      "üìã Model: gemini-2.5-pro\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Prompt alignment: non-exact match: [example#0] class='CONCEPT' status=AlignmentStatus.MATCH_FUZZY text='In-memory computation' char_span=(0, 21)\n",
      "WARNING:absl:Prompt alignment: non-exact match: [example#0] class='TOPIC' status=AlignmentStatus.MATCH_LESSER text='In-Memory Computation and Computer Clusters' char_span=(0, 21)\n",
      "WARNING:absl:Prompt alignment: FAILED to align: [example#0] class='SUMMARY' status=None text='In-memory computation uses cluster RAM for calculations, avoiding disk access for better performance.'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå Extraction failed: Gemini API error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-pro'}, 'quotaValue': '50'}]}, {'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '58s'}]}}\n",
      "Failed to process document 'BDA5-4.docx': 'dict' object has no attribute 'extractions'\n",
      "Original text length: 7333\n",
      "After preprocessing length: 7209\n",
      "Preprocessing removed: 124 characters\n",
      "\n",
      "First 200 chars of cleaned text:\n",
      "Hello everyone, I am Haiying Che, from Institute of Data Science and knowledge Engineering\n",
      "School of Computer Science, in Beijing Institute of Technology, in this session, we will discuss Internal dat...\n",
      "üîÑ Using custom OpenAI endpoint: https://api.xiaocaseai.com/v1\n",
      "üìã Model: gemini-2.5-pro\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Prompt alignment: non-exact match: [example#0] class='CONCEPT' status=AlignmentStatus.MATCH_FUZZY text='In-memory computation' char_span=(0, 21)\n",
      "WARNING:absl:Prompt alignment: non-exact match: [example#0] class='TOPIC' status=AlignmentStatus.MATCH_LESSER text='In-Memory Computation and Computer Clusters' char_span=(0, 21)\n",
      "WARNING:absl:Prompt alignment: FAILED to align: [example#0] class='SUMMARY' status=None text='In-memory computation uses cluster RAM for calculations, avoiding disk access for better performance.'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå Extraction failed: Gemini API error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-pro'}, 'quotaValue': '50'}]}, {'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '56s'}]}}\n",
      "Failed to process document 'transcript BD 2-2 internal data acquisition.docx': 'dict' object has no attribute 'extractions'\n",
      "Original text length: 6946\n",
      "After preprocessing length: 6785\n",
      "Preprocessing removed: 161 characters\n",
      "\n",
      "First 200 chars of cleaned text:\n",
      "Hello everyone, I am Haiying Che, from Institute of Data Science and knowledge Engineering\n",
      "School of Computer Science, in Beijing Institute of Technology, \n",
      "in this session, we discuss Massively Parall...\n",
      "üîÑ Using custom OpenAI endpoint: https://api.xiaocaseai.com/v1\n",
      "üìã Model: gemini-2.5-pro\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Prompt alignment: non-exact match: [example#0] class='CONCEPT' status=AlignmentStatus.MATCH_FUZZY text='In-memory computation' char_span=(0, 21)\n",
      "WARNING:absl:Prompt alignment: non-exact match: [example#0] class='TOPIC' status=AlignmentStatus.MATCH_LESSER text='In-Memory Computation and Computer Clusters' char_span=(0, 21)\n",
      "WARNING:absl:Prompt alignment: FAILED to align: [example#0] class='SUMMARY' status=None text='In-memory computation uses cluster RAM for calculations, avoiding disk access for better performance.'\n",
      "WARNING:absl:Prompt alignment: non-exact match: [example#0] class='CONCEPT' status=AlignmentStatus.MATCH_FUZZY text='In-memory computation' char_span=(0, 21)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå Extraction failed: Gemini API error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-pro', 'location': 'global'}, 'quotaValue': '50'}]}, {'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '54s'}]}}\n",
      "Failed to process document 'BDA5-5.docx': 'dict' object has no attribute 'extractions'\n",
      "Original text length: 5820\n",
      "After preprocessing length: 5737\n",
      "Preprocessing removed: 83 characters\n",
      "\n",
      "First 200 chars of cleaned text:\n",
      "Hello everyone, I am Haiying Che, from Institute of Data Science and knowledge Engineering\n",
      "School of Computer Science, in Beijing Institute of Technology, \n",
      "in this session, we discuss about NoSQL Data...\n",
      "üîÑ Using custom OpenAI endpoint: https://api.xiaocaseai.com/v1\n",
      "üìã Model: gemini-2.5-pro\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Prompt alignment: non-exact match: [example#0] class='TOPIC' status=AlignmentStatus.MATCH_LESSER text='In-Memory Computation and Computer Clusters' char_span=(0, 21)\n",
      "WARNING:absl:Prompt alignment: FAILED to align: [example#0] class='SUMMARY' status=None text='In-memory computation uses cluster RAM for calculations, avoiding disk access for better performance.'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå Extraction failed: Gemini API error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-pro'}, 'quotaValue': '50'}]}, {'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '52s'}]}}\n",
      "Failed to process document 'BDA 4-4.docx': 'dict' object has no attribute 'extractions'\n",
      "Original text length: 4540\n",
      "After preprocessing length: 4453\n",
      "Preprocessing removed: 87 characters\n",
      "\n",
      "First 200 chars of cleaned text:\n",
      "Hello everyone, I am Haiying Che, from Institute of Data Science and knowledge Engineering\n",
      "School of Computer Science, in Beijing Institute of Technology\n",
      "In this chapter, we introduced some useful pla...\n",
      "üîÑ Using custom OpenAI endpoint: https://api.xiaocaseai.com/v1\n",
      "üìã Model: gemini-2.5-pro\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Prompt alignment: non-exact match: [example#0] class='CONCEPT' status=AlignmentStatus.MATCH_FUZZY text='In-memory computation' char_span=(0, 21)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå Extraction failed: Gemini API error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-pro', 'location': 'global'}, 'quotaValue': '50'}]}, {'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '50s'}]}}\n",
      "Failed to process document 'BDA 6-5.docx': 'dict' object has no attribute 'extractions'\n",
      "‚úÖ Successfully extracted concepts with preprocessing + LLM compression\n",
      "Saved knowledge graph for 'BDA 6-3.docx' to 'outputs/BDA 6-3.json'\n",
      "‚úÖ Successfully extracted concepts with preprocessing + LLM compression\n",
      "Saved knowledge graph for 'BDA5-8.docx' to 'outputs/BDA5-8.json'\n",
      "All documents have been processed.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "from collections import defaultdict\n",
    "import networkx as nx\n",
    "from services.extraction import ExtractionService\n",
    "from utils.doc_utils import load_docx_documents\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.documents import Document\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import langextract as lx\n",
    "\n",
    "_ = load_dotenv()\n",
    "\n",
    "def process_document(doc: Document):\n",
    "    \"\"\"\n",
    "    Processes a single document to extract concepts.\n",
    "    \"\"\"\n",
    "    extraction_service = ExtractionService(documents=[doc])\n",
    "    result = extraction_service.compress_and_extract_concepts()\n",
    "    return result\n",
    "\n",
    "# --- Main Loop ---\n",
    "output_dir = \"outputs\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "documents = load_docx_documents(\"unstructured_script\")\n",
    "results = []\n",
    "\n",
    "# Use ThreadPoolExecutor to process documents in parallel\n",
    "with ThreadPoolExecutor(max_workers=4) as executor:\n",
    "    results = list(executor.map(process_document, documents))\n",
    "\n",
    "# Filter out failed results (which are dicts) and keep successful ones\n",
    "successful_results = [res for res in results if hasattr(res, 'extractions')]\n",
    "\n",
    "# Save successful results to a JSONL file\n",
    "jsonl_path = os.path.join(output_dir, \"extraction_results.jsonl\")\n",
    "lx.io.save_annotated_documents(successful_results, output_name=jsonl_path)\n",
    "\n",
    "print(f\"Saved {len(successful_results)} successful extractions to '{jsonl_path}'\")\n",
    "\n",
    "# --- Now, let's process the saved JSONs into individual graph files as before ---\n",
    "\n",
    "def create_graph_from_extraction(result: lx.data.AnnotatedDocument):\n",
    "    # Post-process the extractions for consolidated and cleaned output\n",
    "    topics = [extraction.extraction_text for extraction in result.extractions if extraction.extraction_class == 'TOPIC']\n",
    "    summaries = [extraction.extraction_text for extraction in result.extractions if extraction.extraction_class == 'SUMMARY']\n",
    "    concepts = [extraction for extraction in result.extractions if extraction.extraction_class == 'CONCEPT']\n",
    "\n",
    "    # --- 1. Consolidate Topic and Summary ---\n",
    "    final_topic = topics[0] if topics else \"No Topic Found\"\n",
    "    final_summary = \" \".join(summaries)\n",
    "\n",
    "    # --- 2. Advanced Concept Deduplication and Merging ---\n",
    "    def normalize_concept_text(text):\n",
    "        \"\"\"Normalizes text for better grouping of concepts.\"\"\"\n",
    "        text = text.lower()\n",
    "        text = re.sub(r'\\(.*\\)', '', text).strip()\n",
    "        if text.endswith('s'):\n",
    "            text = text[:-1]\n",
    "        text = re.sub(r'\\s+', '', text)\n",
    "        return text\n",
    "\n",
    "    merged_concepts = defaultdict(lambda: {'definitions': set(), 'original_names': set()})\n",
    "\n",
    "    for concept in concepts:\n",
    "        normalized_name = normalize_concept_text(concept.extraction_text)\n",
    "        definition = concept.attributes.get('definition')\n",
    "        if definition:\n",
    "            merged_concepts[normalized_name]['definitions'].add(definition)\n",
    "        merged_concepts[normalized_name]['original_names'].add(concept.extraction_text)\n",
    "\n",
    "    # --- 3. Build Knowledge Graph ---\n",
    "    G = nx.DiGraph()\n",
    "\n",
    "    if final_topic != \"No Topic Found\":\n",
    "        G.add_node(final_topic, type='Topic', summary=final_summary)\n",
    "\n",
    "        for normalized_name, data in merged_concepts.items():\n",
    "            display_name = max(data['original_names'], key=len)\n",
    "            full_definition = \" | \".join(sorted(list(data['definitions'])))\n",
    "            G.add_node(display_name, type='Concept', definition=full_definition)\n",
    "            G.add_edge(display_name, final_topic, relation='is_concept_in')\n",
    "            \n",
    "    return G\n",
    "\n",
    "for result in successful_results:\n",
    "    try:\n",
    "        graph = create_graph_from_extraction(result)\n",
    "        \n",
    "        # Get the original filename and create a JSON filename\n",
    "        # The source might be in the document metadata if it was processed that way\n",
    "        original_filename = os.path.basename(result.documents[0].metadata.get(\"source\", \"unknown.docx\"))\n",
    "        json_filename = os.path.splitext(original_filename)[0] + \".json\"\n",
    "        output_path = os.path.join(output_dir, json_filename)\n",
    "        \n",
    "        # Convert graph to a serializable format and save as JSON\n",
    "        graph_data = nx.node_link_data(graph)\n",
    "        \n",
    "        with open(output_path, 'w') as f:\n",
    "            json.dump(graph_data, f, indent=4)\n",
    "            \n",
    "        print(f\"Saved knowledge graph for '{original_filename}' to '{output_path}'\")\n",
    "    except Exception as e:\n",
    "        original_filename = os.path.basename(result.documents[0].metadata.get(\"source\", \"unknown.docx\"))\n",
    "        print(f\"Failed to create or save graph for document '{original_filename}': {e}\")\n",
    "\n",
    "print(\"All documents have been processed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94724a46",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'successful_results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43msuccessful_results\u001b[49m\n",
      "\u001b[31mNameError\u001b[39m: name 'successful_results' is not defined"
     ]
    }
   ],
   "source": [
    "successful_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b127ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import langextract as lx\n",
    "import os\n",
    "\n",
    "def generate_visualization(jsonl_path, output_html_path):\n",
    "    \"\"\"\n",
    "    Generates an interactive HTML visualization from a JSONL file of extractions.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(jsonl_path):\n",
    "        print(f\"Error: JSONL file not found at '{jsonl_path}'\")\n",
    "        return\n",
    "\n",
    "    print(f\"Generating visualization from '{jsonl_path}'...\")\n",
    "    \n",
    "    # Generate the visualization from the file\n",
    "    html_content = lx.visualize(jsonl_path)\n",
    "    \n",
    "    with open(output_html_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        if hasattr(html_content, 'data'):\n",
    "            f.write(html_content.data)  # For Jupyter/Colab environments\n",
    "        else:\n",
    "            f.write(html_content)\n",
    "            \n",
    "    print(f\"Successfully saved visualization to '{output_html_path}'\")\n",
    "\n",
    "# --- Generate Visualization ---\n",
    "# Define the path to the JSONL file created in the previous cell\n",
    "jsonl_file = os.path.join(\"outputs\", \"extraction_results.jsonl\")\n",
    "output_html_file = \"visualization.html\"\n",
    "\n",
    "generate_visualization(jsonl_file, output_html_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "knowledge_graph_builder",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
